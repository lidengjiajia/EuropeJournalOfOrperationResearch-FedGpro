"""
è”é‚¦å­¦ä¹ æ¶ˆèå®éªŒæ‰¹é‡è¿è¡Œè„šæœ¬ (ä¼˜åŒ–ç‰ˆ)
ç‰¹æ€§:
- å¹¶å‘æ‰§è¡Œ: æ¯ä¸ªGPUåŒæ—¶è¿è¡Œ2ä¸ªå®éªŒ
- æ™ºèƒ½æ£€æµ‹: æ‰“å°ç¼ºå¤±çš„å®éªŒæ–‡ä»¶
- ç®€åŒ–æ—¥å¿—: æ¯20è½®æ‰“å°ä¸€æ¬¡è¿›åº¦
- å®æ—¶ç›‘æ§: æ˜¾ç¤ºæ¯ä¸ªå®éªŒçš„è¿›åº¦
"""

import os
import sys
import time
import subprocess
import threading
from datetime import datetime
from pathlib import Path
from queue import Queue, Empty
from typing import Dict, List
import re

BASE_DIR = Path(__file__).parent.resolve()
sys.path.insert(0, str(BASE_DIR / 'system'))

# =============================================================================
# é…ç½®å¸¸é‡
# =============================================================================

DATASETS = ['Uci', 'Xinwang']
HETEROGENEITY_TYPES = {'feature': 'ç‰¹å¾å¼‚è´¨æ€§', 'label': 'æ ‡ç­¾å¼‚è´¨æ€§',
                       'quantity': 'æ ·æœ¬æ•°é‡å¼‚è´¨æ€§', 'iid': 'IIDå‡åŒ€åˆ†å¸ƒ'}

GLOBAL_ROUNDS = 100
LOCAL_EPOCHS = 5

# GPUè‡ªåŠ¨æ£€æµ‹
try:
    import torch
    gpu_count = torch.cuda.device_count()
    if gpu_count > 0:
        GPU_IDS = list(range(gpu_count))
        print(f"æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
        for i in range(gpu_count):
            print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
    else:
        GPU_IDS = [0]
        print("æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPU")
except:
    GPU_IDS = [0]
    print("æ— æ³•æ£€æµ‹GPUï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

SLOTS_PER_GPU = 2

# è¶…å‚æ•°é…ç½®
HYPERPARAMETERS = {
    'Uci': {
        'feature': {'batch_size': 64, 'learning_rate': 0.005, 'num_clients': 10},
        'label': {'batch_size': 64, 'learning_rate': 0.007, 'num_clients': 10},
        'quantity': {'batch_size': 64, 'learning_rate': 0.007, 'num_clients': 10},
        'iid': {'batch_size': 64, 'learning_rate': 0.007, 'num_clients': 10},
    },
    'Xinwang': {
        'feature': {'batch_size': 128, 'learning_rate': 0.006, 'num_clients': 10},
        'label': {'batch_size': 128, 'learning_rate': 0.006, 'num_clients': 10},
        'quantity': {'batch_size': 128, 'learning_rate': 0.006, 'num_clients': 10},
        'iid': {'batch_size': 128, 'learning_rate': 0.006, 'num_clients': 10},
    },
}

# æ¶ˆèé…ç½®
# æ ¹æ®è®ºæ–‡å›¾5-9è®¾è®¡æ¶ˆèå®éªŒï¼š
# å›¾5: ç”Ÿæˆæ•°æ®ä½œç”¨ã€åŸå‹ä½œç”¨ã€å…ƒå¯å‘å¼ç®—æ³•ä½œç”¨
# å›¾6: éšç§é¢„ç®—ï¼ˆä¸åŒÎµå€¼å¯¹æ¯” + Hybridç­–ç•¥ï¼‰
# å›¾7: æ³›åŒ–èƒ½åŠ›ï¼ˆæ–°å®¢æˆ·ç«¯æµ‹è¯• - reserved_clientsï¼‰
# å›¾8: å®¢æˆ·ç«¯æ•°ç›®å½±å“ï¼ˆ5, 6, 7, 8, 9, 10ä¸ªå®¢æˆ·ç«¯ï¼‰
# å›¾9: è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆlambda_proto, lambda_kl, latent_dim, proto_momentum, phase_transition_threshold, gwo_alpha_decayï¼‰

ABLATION_CONFIGS = {
    # ========== å›¾5: ç»„ä»¶æ¶ˆèï¼ˆç”Ÿæˆæ•°æ®ã€åŸå‹ã€ä¸åŒPhase2èšåˆç®—æ³•ï¼‰ ==========
    # å®Œæ•´æ¨¡å‹ï¼ˆbaselineï¼ŒPhase2ä½¿ç”¨FedAvgï¼‰
    'Full_Model': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'fedavg',      # Phase2ä½¿ç”¨FedAvg
        'fedgpro_lambda_proto': '0.3',       # ä¼˜åŒ–åçš„åŸå‹æŸå¤±æƒé‡
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50'
    },
    
    # æ— VAEç”Ÿæˆæ•°æ®ï¼ˆå›¾5a: æµ‹è¯•ç”Ÿæˆæ•°æ®ä½œç”¨ï¼‰
    'No_VAE_Generation': {
        'fedgpro_use_vae': 'False',          # ç¦ç”¨VAEç”Ÿæˆè™šæ‹Ÿæ•°æ®
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'fedavg',
        'fedgpro_lambda_proto': '0.3',
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50'
    },
    
    # æ— åŸå‹å­¦ä¹ ï¼ˆå›¾5b: æµ‹è¯•åŸå‹ä½œç”¨ï¼‰
    'No_Prototype': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'False',    # ç¦ç”¨åŸå‹å­¦ä¹ æŸå¤±
        'fedgpro_phase2_agg': 'fedavg',
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50'
    },
    
    # Phase2ä½¿ç”¨FedProxï¼ˆå›¾5c: æµ‹è¯•ä¸åŒèšåˆç®—æ³•ï¼‰
    'Phase2_FedProx': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'fedprox',
        'mu': '0.1',                         # FedProxéœ€è¦muå‚æ•°
        'fedgpro_lambda_proto': '0.3',
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50'
    },
    
    # Phase2ä½¿ç”¨Scaffoldï¼ˆå›¾5d: æµ‹è¯•Scaffoldèšåˆç®—æ³•ï¼‰
    'Phase2_Scaffold': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'scaffold',
        'fedgpro_lambda_proto': '0.3',
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50'
    },
    
    # ========== å›¾6a: éšç§é¢„ç®—æ¶ˆèï¼ˆ3ä¸ªÎµå€¼ï¼Œå‡ä½¿ç”¨å¸¸è§„åŠ å¯†ï¼‰ ==========
    
    # Îµ=1.0ï¼ˆä¸¥æ ¼éšç§ä¿æŠ¤ï¼‰
    'Privacy_Epsilon_1.0': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'fedavg',
        'fedgpro_lambda_proto': '0.3',
        'fedgpro_epsilon': '1.0',            # éšç§é¢„ç®—=1.0
        'fedgpro_noise_type': 'laplace',
        'fedgpro_use_iadp': 'False',         # å¸¸è§„åŠ å¯†
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50'
    },
    
    # Îµ=5.0ï¼ˆä¸­ç­‰éšç§ä¿æŠ¤ï¼‰
    'Privacy_Epsilon_5.0': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'fedavg',
        'fedgpro_lambda_proto': '0.3',
        'fedgpro_epsilon': '5.0',            # éšç§é¢„ç®—=5.0
        'fedgpro_noise_type': 'laplace',
        'fedgpro_use_iadp': 'False',         # å¸¸è§„åŠ å¯†
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50'
    },
    
    # Îµ=10.0ï¼ˆå®½æ¾éšç§ä¿æŠ¤ï¼‰
    'Privacy_Epsilon_10.0': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'fedavg',
        'fedgpro_lambda_proto': '0.3',
        'fedgpro_epsilon': '10.0',           # éšç§é¢„ç®—=10.0
        'fedgpro_noise_type': 'laplace',
        'fedgpro_use_iadp': 'False',         # å¸¸è§„åŠ å¯†
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50'
    },
    
    # ========== å›¾6b: åŸºäºç‰¹å¾é‡è¦æ€§çš„è‡ªé€‚åº”åŠ å¯†ï¼ˆÎµ=10ï¼Œ3ç§ç­–ç•¥ï¼‰ ==========
    
    # ç­–ç•¥1: å¸¸è§„åŠ å¯†ï¼ˆä¼ ç»ŸDPï¼Œå‡åŒ€å™ªå£°ï¼Œä½œä¸ºbaselineï¼‰
    'Privacy_Conventional': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'fedavg',
        'fedgpro_lambda_proto': '0.3',
        'fedgpro_epsilon': '10.0',           # éšç§é¢„ç®—=10
        'fedgpro_noise_type': 'laplace',
        'fedgpro_use_iadp': 'False',         # ä¸ä½¿ç”¨è‡ªé€‚åº”åŠ å¯†
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50'
    },
    
    # ç­–ç•¥2: æ•ˆç”¨ä¼˜å…ˆï¼ˆåŸºäºç‰¹å¾é‡è¦æ€§æ’åºï¼Œé‡è¦ç‰¹å¾ä½å™ªå£°ï¼‰
    # ä½¿ç”¨VAEå¯¹æ¯”æŸå¤±åº¦é‡ç‰¹å¾é‡è¦æ€§ï¼šå¯¹åˆ†ç±»æœ‰ç”¨çš„ç‰¹å¾å…·æœ‰é«˜åˆ¤åˆ«æ€§
    'Privacy_Utility_First': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'fedavg',
        'fedgpro_lambda_proto': '0.3',
        'fedgpro_epsilon': '10.0',           # éšç§é¢„ç®—=10
        'fedgpro_noise_type': 'laplace',
        'fedgpro_use_iadp': 'True',          # ä½¿ç”¨è‡ªé€‚åº”DP
        'fedgpro_iadp_alpha': '0.3',
        'fedgpro_iadp_importance_method': 'vae_contrast',  # ä½¿ç”¨VAEå¯¹æ¯”æŸå¤±
        'fedgpro_iadp_privacy_priority': 'False',  # æ•ˆç”¨ä¼˜å…ˆ
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50'
    },
    
    # ç­–ç•¥3: éšç§ä¼˜å…ˆï¼ˆåŸºäºç‰¹å¾é‡è¦æ€§æ’åºï¼Œé‡è¦ç‰¹å¾é«˜å™ªå£°ï¼‰
    # ä½¿ç”¨VAEå¯¹æ¯”æŸå¤±åº¦é‡ç‰¹å¾é‡è¦æ€§ï¼šé«˜åˆ¤åˆ«æ€§ç‰¹å¾æ·»åŠ æ›´å¤šå™ªå£°ä¿æŠ¤éšç§
    'Privacy_Privacy_First': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'fedavg',
        'fedgpro_lambda_proto': '0.3',
        'fedgpro_epsilon': '10.0',           # éšç§é¢„ç®—=10
        'fedgpro_noise_type': 'laplace',
        'fedgpro_use_iadp': 'True',          # ä½¿ç”¨è‡ªé€‚åº”DP
        'fedgpro_iadp_alpha': '0.3',
        'fedgpro_iadp_importance_method': 'vae_contrast',  # ä½¿ç”¨VAEå¯¹æ¯”æŸå¤±
        'fedgpro_iadp_privacy_priority': 'True',  # éšç§ä¼˜å…ˆ
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50'
    },
    
        # ========== å›¾7: æ³›åŒ–èƒ½åŠ›ï¼ˆæ–°å®¢æˆ·ç«¯æµ‹è¯•ï¼‰ ==========
    # ä¿ç•™20%å®¢æˆ·ç«¯æµ‹è¯•æ³›åŒ–èƒ½åŠ›
    'Generalization_Reserve_2': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'fedavg',
        'fedgpro_lambda_proto': '0.3',
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50',
        'reserved_clients': '8,9'            # ä¿ç•™å®¢æˆ·ç«¯8,9ç”¨äºæ³›åŒ–æµ‹è¯•ï¼ˆ20%ï¼‰
    },
    
    # ä¿ç•™30%å®¢æˆ·ç«¯æµ‹è¯•æ³›åŒ–èƒ½åŠ›
    'Generalization_Reserve_3': {
        'fedgpro_use_vae': 'True',
        'fedgpro_use_prototype': 'True',
        'fedgpro_phase2_agg': 'fedavg',
        'fedgpro_lambda_proto': '0.3',
        'fedgpro_phase_transition_threshold': '0.70',
        'fedgpro_phase2_rounds': '50',
        'reserved_clients': '7,8,9'          # ä¿ç•™å®¢æˆ·ç«¯7,8,9ç”¨äºæ³›åŒ–æµ‹è¯•ï¼ˆ30%ï¼‰
    },
}

# =============================================================================
# å…¨å±€çŠ¶æ€
# =============================================================================

progress_lock = threading.Lock()
gpu_status = {}
completed_count = 0
failed_count = 0
total_experiments = 0

for gpu_id in GPU_IDS:
    for slot_id in range(SLOTS_PER_GPU):
        gpu_status[(gpu_id, slot_id)] = None

# =============================================================================
# å·¥å…·å‡½æ•°
# =============================================================================

def _ts():
    return datetime.now().strftime('%H:%M:%S')

def get_algorithm_name_for_config(config_name):
    """æ ¹æ®æ¶ˆèé…ç½®è·å–å®é™…çš„ç®—æ³•åç§°
    
    servergpro.pyä¼šåœ¨save_resultsæ—¶ä½¿ç”¨self.original_algorithmï¼Œ
    è¿™ä¸ªå€¼åœ¨__init__æ—¶å°±ä»args.algorithmå¤åˆ¶è¿‡æ¥
    æ‰€ä»¥ï¼Œæ— è®ºfedgpro_phase2_aggæ˜¯ä»€ä¹ˆï¼Œä¿å­˜çš„ç›®å½•åéƒ½åŸºäºä¼ å…¥çš„ç®—æ³•å
    
    å› æ­¤ï¼Œå¦‚æœbuild_commandä¼ çš„æ˜¯'FedGpro'ï¼Œç»“æœç›®å½•å°±ä¼šæ˜¯ FedGpro
    å¦‚æœä¼ çš„æ˜¯'FedGpro-FedAvg'ï¼Œç»“æœç›®å½•å°±ä¼šæ˜¯ FedGpro-FedAvg
    """
    # è¿”å›build_commandä¸­ä¼ é€’çš„ç®—æ³•å
    return 'FedGpro'

def check_missing_experiments():
    """æ£€æŸ¥ç¼ºå¤±çš„å®éªŒæ–‡ä»¶"""
    print("\n" + "="*80)
    print("æ£€æŸ¥ç¼ºå¤±çš„æ¶ˆèå®éªŒæ–‡ä»¶...")
    print("="*80)
    
    missing = []
    for dataset in DATASETS:
        for hetero in HETEROGENEITY_TYPES.keys():
            for config_name in ABLATION_CONFIGS.keys():
                # æ–°çš„ç›®å½•ç»“æ„: æ¯ä¸ªå®éªŒé…ç½®ä¸€ä¸ªç‹¬ç«‹ç›®å½•
                # ç›®å½•åæ ¼å¼: {dataset}_FedGpro_Ablation_{config_name}_{hetero}
                # æ³¨æ„: servergpro.pyåœ¨save_resultsæ—¶ä½¿ç”¨self.original_algorithmï¼ˆåˆå§‹å€¼ï¼‰ï¼Œ
                # æ— è®ºfedgpro_phase2_aggæ˜¯ä»€ä¹ˆï¼Œæ‰€ä»¥ç›®å½•åæ€»æ˜¯åŸºäºä¼ å…¥çš„ç®—æ³•å'FedGpro'
                algo_name = get_algorithm_name_for_config(config_name)
                results_dir = BASE_DIR / 'system' / 'results' / f"{dataset}_{algo_name}_Ablation_{config_name}_{hetero}"
                # æ–‡ä»¶åæ ¼å¼: {dataset}_FedGpro_Ablation_{config_name}_{hetero}_*.h5
                file_prefix = f"{dataset}_{algo_name}_Ablation_{config_name}_{hetero}"
                
                if not results_dir.exists():
                    missing.append((dataset, hetero, config_name, 0))
                    continue
                
                # æŸ¥æ‰¾å®é™…çš„æ–‡ä»¶æ¨¡å¼
                completed_files = list(results_dir.glob(f"{file_prefix}_*.h5"))
                completed = len(completed_files)
                
                if completed < 5:
                    missing.append((dataset, hetero, config_name, completed))
    
    if missing:
        print(f"\nç¼ºå¤±æ¶ˆèå®éªŒæ•°: {len(missing)}")
        print(f"{'æ•°æ®é›†':<10} {'å¼‚è´¨æ€§':<10} {'é…ç½®':<20} {'å·²å®Œæˆ/éœ€è¦'}")
        print("-" * 80)
        for dataset, hetero, config, completed in missing:
            print(f"{dataset:<10} {hetero:<10} {config:<20} {completed}/5")
    else:
        print("\nâœ… æ‰€æœ‰æ¶ˆèå®éªŒå‡å·²å®Œæˆï¼")
    
    print("="*80 + "\n")
    return missing

def build_command(dataset, hetero_type, config_name, gpu_id):
    """æ„å»ºè¿è¡Œå‘½ä»¤"""
    params = HYPERPARAMETERS[dataset][hetero_type]
    config = ABLATION_CONFIGS[config_name]
    
    # æ–°çš„ç›®å½•ç»“æ„: ç®€æ´æ ¼å¼
    # ğŸ”¥ å…³é”®ä¿®å¤: ä¼ å…¥ 'FedGpro' è€Œä¸æ˜¯ 'FedGpro-FedAvg'
    # servergpro.pyä¼šåœ¨save_resultsæ—¶ä½¿ç”¨self.original_algorithmï¼ˆåˆå§‹å€¼ï¼‰ï¼Œ
    # æ‰€ä»¥å¦‚æœä¼ 'FedGpro'ï¼Œä¿å­˜çš„ç›®å½•å°±æ˜¯ FedGpro_xxxï¼Œä¸ä¼šåŒ…å«FedAvg/FedProxç­‰
    goal_name = f'Ablation_{config_name}_{hetero_type}'
    save_folder = f'system/models/{dataset}_FedGpro_Ablation_{config_name}_{hetero_type}'
    
    cmd = [
        'python', '-u', 'system/main.py',
        '-data', dataset, '-m', 'credit', '-algo', 'FedGpro',
        '-did', str(gpu_id), '-gr', str(GLOBAL_ROUNDS),
        '-nc', str(params['num_clients']),
        '-ls', str(LOCAL_EPOCHS),
        '-lr', str(params['learning_rate']),
        '-lbs', str(params['batch_size']),
        '-t', '5',
        '-go', goal_name,
        '-sfn', save_folder,
    ]
    
    for key, value in config.items():
        cmd.extend([f'--{key}', str(value)])
    
    return cmd

# =============================================================================
# Workerçº¿ç¨‹
# =============================================================================

def worker_thread(gpu_id, slot_id, task_queue, results_list, results_lock):
    """Workerçº¿ç¨‹"""
    global completed_count, failed_count
    
    while True:
        try:
            task = task_queue.get(timeout=1)
            if task is None:
                break
            
            dataset, hetero, config_name, exp_id = task
            
            with progress_lock:
                gpu_status[(gpu_id, slot_id)] = {
                    'dataset': dataset, 'hetero': hetero, 'config': config_name,
                    'exp_id': exp_id, 'start_time': time.time(), 'last_round': 0
                }
            
            print(f"[{_ts()}] ğŸš€ GPU{gpu_id}-æ§½ä½{slot_id}: {dataset}-{hetero}-{config_name}")
            
            cmd = build_command(dataset, hetero, config_name, gpu_id)
            start_time = time.time()
            success = False
            
            try:
                # åˆ›å»ºlogsç›®å½•
                logs_dir = BASE_DIR / 'logs'
                logs_dir.mkdir(exist_ok=True)
                log_file_path = logs_dir / f"Ablation_{config_name}_{dataset}_{hetero}.log"
                
                # stderr=subprocess.STDOUT å°†stderråˆå¹¶åˆ°stdout
                process = subprocess.Popen(
                    cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                    text=True, encoding='utf-8', errors='replace',
                    bufsize=1, universal_newlines=True
                )
                
                # æ‰“å¼€æ—¥å¿—æ–‡ä»¶å¹¶å®æ—¶å†™å…¥
                with open(log_file_path, 'w', encoding='utf-8') as log_file:
                    last_printed_round = -1  # è®°å½•ä¸Šæ¬¡æ‰“å°çš„roundï¼Œé¿å…é‡å¤
                    for line in process.stdout:
                        # å†™å…¥æ—¥å¿—æ–‡ä»¶
                        log_file.write(line)
                        log_file.flush()
                        
                        line = line.strip()
                        if not line:
                            continue
                        
                        # å¢å¼ºæ­£åˆ™ï¼šåŒ¹é… "Round 5", "Round number: 5", "Round 5 |", "----- Round 5 -----"
                        match = re.search(r'Round[:\s]+(?:number[:\s]+)?(\d+)', line, re.IGNORECASE)
                        if match:
                            round_num = int(match.group(1))
                            with progress_lock:
                                if (gpu_id, slot_id) in gpu_status and gpu_status[(gpu_id, slot_id)]:
                                    gpu_status[(gpu_id, slot_id)]['last_round'] = round_num
                            
                            # æ’é™¤round 0ï¼Œä¸”é¿å…é‡å¤æ‰“å°åŒä¸€è½®
                            if round_num > 0 and round_num % 20 == 0 and round_num != last_printed_round:
                                last_printed_round = round_num
                                elapsed_min = (time.time() - start_time) / 60
                                print(f"  [{_ts()}] {dataset}-{hetero}-{config_name} | Round {round_num}/{GLOBAL_ROUNDS} | {elapsed_min:.1f}åˆ†é’Ÿ")
                
                returncode = process.wait(timeout=7200)
                elapsed = time.time() - start_time
                
                if returncode == 0:
                    success = True
                    with progress_lock:
                        completed_count += 1
                    print(f"[{_ts()}] âœ… {dataset}-{hetero}-{config_name} å®Œæˆ ({elapsed/60:.1f}åˆ†é’Ÿ)")
                else:
                    with progress_lock:
                        failed_count += 1
                    print(f"[{_ts()}] âŒ {dataset}-{hetero}-{config_name} å¤±è´¥")
            
            except subprocess.TimeoutExpired:
                process.kill()
                elapsed = time.time() - start_time
                with progress_lock:
                    failed_count += 1
                print(f"[{_ts()}] â±ï¸ {dataset}-{hetero}-{config_name} è¶…æ—¶ ({elapsed/60:.1f}åˆ†é’Ÿ)")
            except Exception as e:
                elapsed = time.time() - start_time
                with progress_lock:
                    failed_count += 1
                print(f"[{_ts()}] ğŸ’¥ {dataset}-{hetero}-{config_name} å¼‚å¸¸: {str(e)}")
                import traceback
                print(f"  è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            
            with progress_lock:
                gpu_status[(gpu_id, slot_id)] = None
            
            with results_lock:
                results_list.append({
                    'dataset': dataset, 'hetero': hetero, 'config': config_name,
                    'success': success, 'elapsed': elapsed
                })
            
            task_queue.task_done()
        
        except Empty:
            continue

# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================

def run_experiments():
    """è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ"""
    global total_experiments
    
    print("\n" + "="*80)
    print("è”é‚¦å­¦ä¹ æ¶ˆèå®éªŒæ‰¹é‡è¿è¡Œ (ä¼˜åŒ–ç‰ˆ)")
    print("="*80)
    print(f"GPUé…ç½®: {len(GPU_IDS)}ä¸ªGPU Ã— {SLOTS_PER_GPU}æ§½ä½ = {len(GPU_IDS) * SLOTS_PER_GPU}å¹¶å‘")
    print(f"æ•°æ®é›†: {', '.join(DATASETS)}")
    print(f"æ¶ˆèé…ç½®: {', '.join(ABLATION_CONFIGS.keys())}")
    print("="*80)
    
    missing = check_missing_experiments()
    
    if not missing:
        print("æ‰€æœ‰æ¶ˆèå®éªŒå·²å®Œæˆï¼Œæ— éœ€è¿è¡Œï¼")
        return
    
    task_queue = Queue()
    exp_id = 0
    for dataset, hetero, config_name, completed in missing:
        task_queue.put((dataset, hetero, config_name, exp_id))
        exp_id += 1
    
    total_experiments = exp_id
    print(f"\néœ€è¦è¿è¡Œçš„æ¶ˆèå®éªŒæ•°: {total_experiments}\n")
    
    threads = []
    results_list = []
    results_lock = threading.Lock()
    
    for gpu_id in GPU_IDS:
        for slot_id in range(SLOTS_PER_GPU):
            t = threading.Thread(
                target=worker_thread,
                args=(gpu_id, slot_id, task_queue, results_list, results_lock),
                daemon=True
            )
            t.start()
            threads.append(t)
    
    start_time = time.time()
    while True:
        time.sleep(10)
        
        with progress_lock:
            running = sum(1 for s in gpu_status.values() if s is not None)
            comp = completed_count
            fail = failed_count
            remain = total_experiments - comp - fail
        
        if remain == 0 and running == 0:
            break
        
        print(f"\n[{_ts()}] è¿›åº¦: å®Œæˆ{comp} | å¤±è´¥{fail} | è¿è¡Œä¸­{running} | å‰©ä½™{remain}")
        
        with progress_lock:
            for (gpu_id, slot_id), info in gpu_status.items():
                if info:
                    elapsed_min = (time.time() - info['start_time']) / 60
                    r = info.get('last_round', 0)
                    print(f"  GPU{gpu_id}-æ§½ä½{slot_id}: {info['dataset']}-{info['hetero']}-{info['config']} | Round {r}/{GLOBAL_ROUNDS} | {elapsed_min:.1f}åˆ†é’Ÿ")
    
    for gpu_id in GPU_IDS:
        for slot_id in range(SLOTS_PER_GPU):
            task_queue.put(None)
    
    for t in threads:
        t.join()
    
    total_time = time.time() - start_time
    print("\n" + "="*80)
    print("æ¶ˆèå®éªŒå®Œæˆï¼")
    print(f"æ€»è€—æ—¶: {total_time/3600:.2f}å°æ—¶")
    print(f"å®Œæˆ: {completed_count}/{total_experiments}")
    print(f"å¤±è´¥: {failed_count}/{total_experiments}")
    print(f"æˆåŠŸç‡: {completed_count/total_experiments*100:.1f}%")
    print("="*80 + "\n")

if __name__ == '__main__':
    run_experiments()
