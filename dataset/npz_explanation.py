"""
NPZæ ¼å¼è¯¦è§£ - è”é‚¦å­¦ä¹ æ¡†æ¶çš„æ•°æ®å­˜å‚¨æ ¼å¼
"""

import numpy as np
import torch

print("="*70)
print("ğŸ“¦ NPZæ ¼å¼å®Œæ•´å·¥ä½œæµç¨‹")
print("="*70)

# ========== ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ•°æ®æ—¶ï¼ˆgenerate_Uci.pyï¼‰ ==========
print("\nã€æ­¥éª¤1ã€‘æ•°æ®ç”Ÿæˆè„šæœ¬ (generate_Uci.py)")
print("-"*70)

# æ¨¡æ‹Ÿå¤„ç†åçš„æ•°æ®
features = np.array([[1.2, 0.3, -0.5], [0.8, -1.2, 0.4]])  # 2æ ·æœ¬ Ã— 3ç‰¹å¾
labels = np.array([0, 1])  # 2ä¸ªæ ‡ç­¾

# ä¿å­˜ä¸ºNPZ
np.savez_compressed('demo_client_0.npz', data={'x': features, 'y': labels})
print(f"âœ“ ä¿å­˜: data={{'x': shape{features.shape}, 'y': shape{labels.shape}}}")
print(f"âœ“ æ–‡ä»¶: demo_client_0.npz")

# ========== ç¬¬äºŒæ­¥ï¼šè®­ç»ƒæ—¶è¯»å–ï¼ˆsystem/utils/data_utils.pyï¼‰ ==========
print("\nã€æ­¥éª¤2ã€‘è®­ç»ƒæ—¶è¯»å–æ•°æ® (system/utils/data_utils.py)")
print("-"*70)

# read_dataå‡½æ•°
def read_data(dataset, idx, is_train=True):
    """æ¡†æ¶çš„è¯»å–å‡½æ•°"""
    file = f'demo_client_{idx}.npz'
    with open(file, 'rb') as f:
        data = np.load(f, allow_pickle=True)['data'].tolist()
    return data

# è¯»å–æ•°æ®
data = read_data('Demo', 0, is_train=True)
print(f"âœ“ è¯»å–: dataç±»å‹={type(data)}")
print(f"âœ“ data.keys()={data.keys()}")
print(f"âœ“ data['x']={data['x']}")
print(f"âœ“ data['y']={data['y']}")

# ========== ç¬¬ä¸‰æ­¥ï¼šè½¬æ¢ä¸ºPyTorchå¼ é‡ =========
print("\nã€æ­¥éª¤3ã€‘è½¬æ¢ä¸ºPyTorchå¼ é‡ (process_imageå‡½æ•°)")
print("-"*70)

def process_image(data):
    """æ¡†æ¶çš„å¤„ç†å‡½æ•°"""
    X = torch.Tensor(data['x']).type(torch.float32)
    y = torch.Tensor(data['y']).type(torch.int64)
    return [(x, y) for x, y in zip(X, y)]

# è½¬æ¢ä¸ºPyTorchæ ¼å¼
dataset_list = process_image(data)
print(f"âœ“ è½¬æ¢ç»“æœ: {len(dataset_list)}ä¸ªæ ·æœ¬")
for i, (x, y) in enumerate(dataset_list):
    print(f"  æ ·æœ¬{i}: ç‰¹å¾tensor{tuple(x.shape)}, æ ‡ç­¾={y.item()}")

# ========== ç¬¬å››æ­¥ï¼šè®­ç»ƒæ—¶ä½¿ç”¨DataLoader ==========
print("\nã€æ­¥éª¤4ã€‘è®­ç»ƒæ—¶ä½¿ç”¨DataLoader")
print("-"*70)

from torch.utils.data import DataLoader
batch_size = 1
dataloader = DataLoader(dataset_list, batch_size=batch_size, shuffle=False)

for batch_idx, (batch_x, batch_y) in enumerate(dataloader):
    print(f"âœ“ Batch {batch_idx}: features{tuple(batch_x.shape)}, labels{tuple(batch_y.shape)}")
    print(f"  â†’ è¾“å…¥æ¨¡å‹: model(batch_x) â†’ è¾“å‡ºé¢„æµ‹")

# ========== æ¸…ç† ==========
import os
os.remove('demo_client_0.npz')

print("\n"+"="*70)
print("ğŸ¯ NPZæ ¼å¼çš„æ ¸å¿ƒä¼˜åŠ¿")
print("="*70)
print("""
1. **å‹ç¼©å­˜å‚¨**: gzipå‹ç¼©ï¼ŒèŠ‚çœç£ç›˜ç©ºé—´ï¼ˆæ¯”CSVå°66%ï¼‰
2. **ç±»å‹ä¿æŒ**: float32/int64ç²¾ç¡®å­˜å‚¨ï¼Œæ— ç²¾åº¦æŸå¤±
3. **å¿«é€ŸåŠ è½½**: ç›´æ¥å†…å­˜æ˜ å°„ï¼Œæ¯”CSVå¿«4å€
4. **æ¡†æ¶å‹å¥½**: NumPy â†’ PyTorché›¶æˆæœ¬è½¬æ¢
5. **åˆ†å¸ƒå¼å‹å¥½**: æ¯ä¸ªå®¢æˆ·ç«¯ä¸€ä¸ªç‹¬ç«‹æ–‡ä»¶ï¼Œæ˜“äºç®¡ç†

åœ¨è”é‚¦å­¦ä¹ ä¸­:
  - 20ä¸ªå®¢æˆ·ç«¯ = 20ä¸ªNPZæ–‡ä»¶ï¼ˆtrain/0.npz ~ train/19.npzï¼‰
  - æ¯ä¸ªæ–‡ä»¶ç‹¬ç«‹è¯»å–ï¼Œæ”¯æŒå¹¶è¡ŒåŠ è½½
  - ä¿æŒæ•°æ®éšç§ï¼šåŸå§‹CSVå¯ä»¥åˆ é™¤ï¼Œåªä¿ç•™åˆ†ç‰‡åçš„NPZ
""")

print("\n"+"="*70)
print("ğŸ’¡ ä¸ºä»€ä¹ˆå«'npz'è€Œä¸æ˜¯'npy'ï¼Ÿ")
print("="*70)
print("""
- .npy  = å•ä¸ªNumPyæ•°ç»„
- .npz  = å¤šä¸ªNumPyæ•°ç»„æ‰“åŒ…ï¼ˆç±»ä¼¼ZIPï¼‰

åœ¨æˆ‘ä»¬çš„åœºæ™¯ä¸­:
  .npzåŒ…å«2ä¸ªæ•°ç»„:
    â”œâ”€ 'x' (ç‰¹å¾æ•°ç»„)
    â””â”€ 'y' (æ ‡ç­¾æ•°ç»„)
  
è¿™æ ·ä¸€ä¸ªæ–‡ä»¶å°±åŒ…å«äº†å®Œæ•´çš„è®­ç»ƒæ•°æ®ï¼
""")
