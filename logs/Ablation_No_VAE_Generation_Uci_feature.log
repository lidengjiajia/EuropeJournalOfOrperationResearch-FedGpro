Warning: FedPAC requires cvxpy. Install with: pip install cvxpy
Warning: MemReporter requires calmsize. Install with: pip install calmsize
==================================================
goal = Ablation_No_VAE_Generation_feature
device = cuda
device_id = 0
dataset = Uci
num_classes = 10
model = credit
batch_size = 64
local_learning_rate = 0.005
learning_rate_decay = False
learning_rate_decay_gamma = 0.99
global_rounds = 100
top_cnt = 100
local_epochs = 5
algorithm = FedGpro
join_ratio = 1.0
random_join_ratio = False
num_clients = 10
prev = 0
times = 5
eval_gap = 1
save_folder_name = system/models/Uci_FedGpro_Ablation_No_VAE_Generation_feature
auto_break = False
dlg_eval = False
dlg_gap = 100
batch_num_per_client = 2
num_new_clients = 0
fine_tuning_epoch_new = 0
feature_dim = 512
vocab_size = 80
max_len = 200
few_shot = 0
client_drop_rate = 0.0
train_slow_rate = 0.0
send_slow_rate = 0.0
time_select = False
time_threthold = 10000
beta = 0.0
lamda = 1.0
mu = 0.0
K = 5
p_learning_rate = 0.01
M = 5
itk = 4000
alphaK = 1.0
sigma = 1.0
alpha = 1.0
plocal_epochs = 1
tau = 1.0
fine_tuning_epochs = 10
dr_learning_rate = 0.0
L = 1.0
noise_dim = 512
generator_learning_rate = 0.005
hidden_dim = 512
server_epochs = 1000
localize_feature_extractor = False
server_learning_rate = 1.0
eta = 1.0
rand_percent = 80
layer_idx = 2
mentee_learning_rate = 0.005
T_start = 0.95
T_end = 0.98
momentum = 0.1
kl_weight = 0.0
first_stage_bound = 0
fedcross_alpha = 0.99
collaberative_model_select_strategy = 1
fedgpro_phase = 1
fedgpro_use_vae = False
fedgpro_use_prototype = True
fedgpro_epsilon = None
fedgpro_noise_type = None
fedgpro_delta = 1e-05
fedgpro_adaptive_noise = False
fedgpro_adaptive_strategy = balanced
fedgpro_utility_weight = 1.0
fedgpro_use_iadp = False
fedgpro_iadp_alpha = 0.3
fedgpro_iadp_importance_method = vae_contrast
fedgpro_iadp_importance_momentum = 0.9
fedgpro_iadp_privacy_priority = False
fedgpro_lambda_cls = 10.0
fedgpro_lambda_recon = 1.0
fedgpro_lambda_kl = 0.1
fedgpro_lambda_proto = 0.3
fedgpro_proto_momentum = 0.95
fedgpro_latent_dim = None
fedgpro_vae_lr = 0.001
fedgpro_proto_align_lr = 0.001
fedgpro_threshold_min = 0.6
fedgpro_phase_transition_threshold = 0.7
fedgpro_phase2_agg = fedavg
fedgpro_phase2_rounds = 50
reserved_clients = []
gwo_alpha_decay = 0.015
pso_w_max = 0.9
pso_w_min = 0.4
pso_c1 = 2.0
pso_c2 = 2.0
pso_v_max = 0.5
cs_f_max = 2.0
cs_f_min = 0.1
cs_AP_max = 0.3
cs_AP_min = 0.1
==================================================

============= Running time: 0th =============
Creating server and clients ...
Warning: Credit dataset Uci should have 2 classes. Auto-correcting from 10 to 2.
Auto-selected UciCreditNet for dataset Uci
UciCreditNet(
  (layers): Sequential(
    (0): Linear(in_features=23, out_features=32, bias=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.4, inplace=False)
    (4): Linear(in_features=32, out_features=16, bias=True)
    (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.2, inplace=False)
  )
  (fc): Linear(in_features=16, out_features=2, bias=True)
)
  Client 0: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 1: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 2: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 3: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 4: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 5: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 6: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 7: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 8: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 9: Personalization enabled (mu=0.0, plocal_epochs=1)

============================================================
FedGpro: Federated Global Prototype Learning
============================================================
Join ratio / total clients: 1.0 / 10

Phase 1 Parameters (Max 20 rounds):
  Minimum threshold: 0.6
  Threshold formula:
    ACC(t-1) = (best_acc(t-1) + avg_acc(t-1)) / 2
    threshold(r) = ACC(t-1),                                       if r <= 9
    threshold(r) = max(0.66, ACC(t-1)*(1-0.05*floor((r-10)/5))), if r >= 10
  Training stages:
    - Round 1-10: Forced training (no early stop check, ensure VAE quality)
    - Round 11+: Early stop check + dynamic threshold with time decay
  Phase transition: 70% clients qualified OR 25 rounds reached

Phase 2 Parameters:
  Aggregation: fedavg
  Supported algorithms: fedavg, fedprox, fedscaffold
============================================================

Finished creating server and clients.

[Phase 1] Statistical Collection (Round 0)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.6600
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7823
  Client 9 meets threshold! Generating virtual data...
  Client 9: Privacy disabled, skipping baseline VAE training.
  Client 9: Skipped virtual data generation (ratio=1.0)
  Client 9: No noise added (privacy disabled).
  Client 1 meets threshold! Generating virtual data...
  Client 1: Privacy disabled, skipping baseline VAE training.
  Client 1: Skipped virtual data generation (ratio=1.0)
  Client 1: No noise added (privacy disabled).
  Client 8 meets threshold! Generating virtual data...
  Client 8: Privacy disabled, skipping baseline VAE training.
  Client 8: Skipped virtual data generation (ratio=1.0)
  Client 8: No noise added (privacy disabled).
  Client 6 meets threshold! Generating virtual data...
  Client 6: Privacy disabled, skipping baseline VAE training.
  Client 6: Skipped virtual data generation (ratio=1.0)
  Client 6: No noise added (privacy disabled).
  Client 4 meets threshold! Generating virtual data...
  Client 4: Privacy disabled, skipping baseline VAE training.
  Client 4: Skipped virtual data generation (ratio=1.0)
  Client 4: No noise added (privacy disabled).
  Client 3 meets threshold! Generating virtual data...
  Client 3: Privacy disabled, skipping baseline VAE training.
  Client 3: Skipped virtual data generation (ratio=1.0)
  Client 3: No noise added (privacy disabled).
  Client 0 meets threshold! Generating virtual data...
  Client 0: Privacy disabled, skipping baseline VAE training.
  Client 0: Skipped virtual data generation (ratio=1.0)
  Client 0: No noise added (privacy disabled).
  Client 2 meets threshold! Generating virtual data...
  Client 2: Privacy disabled, skipping baseline VAE training.
  Client 2: Skipped virtual data generation (ratio=1.0)
  Client 2: No noise added (privacy disabled).
  Client 7 meets threshold! Generating virtual data...
  Client 7: Privacy disabled, skipping baseline VAE training.
  Client 7: Skipped virtual data generation (ratio=1.0)
  Client 7: No noise added (privacy disabled).
  Newly qualified clients: [9, 1, 8, 6, 4, 3, 0, 2, 7]
  Total qualified clients: 9/10
  Virtual data pool size: 0

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 0):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 1: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 0 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4829
Averaged Test Accuracy: 0.7823
Averaged Test AUC: 0.7073
Averaged Test Precision: 0.7349
Averaged Test Recall: 0.7823
Averaged Test F1-Score: 0.7332
Std Test Accuracy: 0.0541
Std Test AUC: 0.0736
------------------------------------------------------------
Round 0 time cost: 5.32s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 1)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8145
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7843

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 2: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 1 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4679
Averaged Test Accuracy: 0.7843
Averaged Test AUC: 0.7210
Averaged Test Precision: 0.7564
Averaged Test Recall: 0.7843
Averaged Test F1-Score: 0.7303
Std Test Accuracy: 0.0489
Std Test AUC: 0.0699
------------------------------------------------------------
Round 1 time cost: 4.77s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 2)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8141
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7863

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 3: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 2 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4599
Averaged Test Accuracy: 0.7863
Averaged Test AUC: 0.7303
Averaged Test Precision: 0.7383
Averaged Test Recall: 0.7863
Averaged Test F1-Score: 0.7347
Std Test Accuracy: 0.0465
Std Test AUC: 0.0678
------------------------------------------------------------
Round 2 time cost: 4.93s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 3)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8151
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7887

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 4: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 3 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4551
Averaged Test Accuracy: 0.7887
Averaged Test AUC: 0.7347
Averaged Test Precision: 0.7634
Averaged Test Recall: 0.7887
Averaged Test F1-Score: 0.7393
Std Test Accuracy: 0.0454
Std Test AUC: 0.0656
------------------------------------------------------------
Round 3 time cost: 4.95s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 4)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8163
  Best client accuracy (ACC(t)): 0.8427
  Global average accuracy (ACC(t)): 0.7917

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 5: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 4 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4507
Averaged Test Accuracy: 0.7917
Averaged Test AUC: 0.7406
Averaged Test Precision: 0.7566
Averaged Test Recall: 0.7917
Averaged Test F1-Score: 0.7451
Std Test Accuracy: 0.0389
Std Test AUC: 0.0643
------------------------------------------------------------
Round 4 time cost: 4.76s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8172
  Best client accuracy (ACC(t)): 0.8427
  Global average accuracy (ACC(t)): 0.7915

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 5):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 6: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 5 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4500
Averaged Test Accuracy: 0.7915
Averaged Test AUC: 0.7409
Averaged Test Precision: 0.7759
Averaged Test Recall: 0.7915
Averaged Test F1-Score: 0.7446
Std Test Accuracy: 0.0419
Std Test AUC: 0.0627
------------------------------------------------------------
Round 5 time cost: 4.97s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 6)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8171
  Best client accuracy (ACC(t)): 0.8427
  Global average accuracy (ACC(t)): 0.7941

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 7: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 6 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4457
Averaged Test Accuracy: 0.7941
Averaged Test AUC: 0.7449
Averaged Test Precision: 0.7864
Averaged Test Recall: 0.7941
Averaged Test F1-Score: 0.7519
Std Test Accuracy: 0.0411
Std Test AUC: 0.0636
------------------------------------------------------------
Round 6 time cost: 4.95s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 7)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8184
  Best client accuracy (ACC(t)): 0.8427
  Global average accuracy (ACC(t)): 0.7948

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 8: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 7 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4436
Averaged Test Accuracy: 0.7948
Averaged Test AUC: 0.7475
Averaged Test Precision: 0.7886
Averaged Test Recall: 0.7948
Averaged Test F1-Score: 0.7542
Std Test Accuracy: 0.0425
Std Test AUC: 0.0615
------------------------------------------------------------
Round 7 time cost: 4.64s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 8)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8187
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7951

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 9: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 8 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4420
Averaged Test Accuracy: 0.7951
Averaged Test AUC: 0.7473
Averaged Test Precision: 0.7875
Averaged Test Recall: 0.7951
Averaged Test F1-Score: 0.7552
Std Test Accuracy: 0.0417
Std Test AUC: 0.0619
------------------------------------------------------------
Round 8 time cost: 4.90s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 9)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8202
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7981

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 10: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 9 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4402
Averaged Test Accuracy: 0.7981
Averaged Test AUC: 0.7492
Averaged Test Precision: 0.7889
Averaged Test Recall: 0.7981
Averaged Test F1-Score: 0.7607
Std Test Accuracy: 0.0409
Std Test AUC: 0.0627
------------------------------------------------------------
Round 9 time cost: 4.72s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 10)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 11: ˥�� 0% (��0��)
    Base: 0.8217 �� Decayed: 0.8217 �� Final: 0.8217
  Current threshold (based on ACC(t-1)): 0.8217
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7989

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 10):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 11: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 10 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4388
Averaged Test Accuracy: 0.7989
Averaged Test AUC: 0.7515
Averaged Test Precision: 0.7905
Averaged Test Recall: 0.7989
Averaged Test F1-Score: 0.7632
Std Test Accuracy: 0.0435
Std Test AUC: 0.0601
------------------------------------------------------------
Round 10 time cost: 5.04s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 11)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8221
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7985

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 12: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 11 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4377
Averaged Test Accuracy: 0.7985
Averaged Test AUC: 0.7535
Averaged Test Precision: 0.7916
Averaged Test Recall: 0.7985
Averaged Test F1-Score: 0.7634
Std Test Accuracy: 0.0446
Std Test AUC: 0.0580
------------------------------------------------------------
Round 11 time cost: 4.88s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 12)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8219
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7987

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 13: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 12 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4374
Averaged Test Accuracy: 0.7987
Averaged Test AUC: 0.7526
Averaged Test Precision: 0.7943
Averaged Test Recall: 0.7987
Averaged Test F1-Score: 0.7616
Std Test Accuracy: 0.0427
Std Test AUC: 0.0577
------------------------------------------------------------
Round 12 time cost: 4.54s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 13)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8220
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7973

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 14: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 13 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4365
Averaged Test Accuracy: 0.7973
Averaged Test AUC: 0.7529
Averaged Test Precision: 0.7902
Averaged Test Recall: 0.7973
Averaged Test F1-Score: 0.7606
Std Test Accuracy: 0.0437
Std Test AUC: 0.0583
------------------------------------------------------------
Round 13 time cost: 4.82s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 14)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8213
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7989

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 15: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 14 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4353
Averaged Test Accuracy: 0.7989
Averaged Test AUC: 0.7542
Averaged Test Precision: 0.7926
Averaged Test Recall: 0.7989
Averaged Test F1-Score: 0.7629
Std Test Accuracy: 0.0423
Std Test AUC: 0.0573
------------------------------------------------------------
Round 14 time cost: 5.09s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 15)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 16: ˥�� 5% (��1��)
    Base: 0.8221 �� Decayed: 0.7810 �� Final: 0.7810
  Current threshold (based on ACC(t-1)): 0.7810
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7973

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 15):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 16: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 15 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4348
Averaged Test Accuracy: 0.7973
Averaged Test AUC: 0.7543
Averaged Test Precision: 0.7902
Averaged Test Recall: 0.7973
Averaged Test F1-Score: 0.7610
Std Test Accuracy: 0.0442
Std Test AUC: 0.0581
------------------------------------------------------------
Round 15 time cost: 4.85s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 16)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7803
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7989

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 17: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 16 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4347
Averaged Test Accuracy: 0.7989
Averaged Test AUC: 0.7540
Averaged Test Precision: 0.7922
Averaged Test Recall: 0.7989
Averaged Test F1-Score: 0.7633
Std Test Accuracy: 0.0430
Std Test AUC: 0.0598
------------------------------------------------------------
Round 16 time cost: 5.10s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 17)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7810
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.8000

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 18: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 17 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4327
Averaged Test Accuracy: 0.8000
Averaged Test AUC: 0.7550
Averaged Test Precision: 0.7930
Averaged Test Recall: 0.8000
Averaged Test F1-Score: 0.7669
Std Test Accuracy: 0.0455
Std Test AUC: 0.0581
------------------------------------------------------------
Round 17 time cost: 4.88s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 18)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7815
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7984

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 19: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 18 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4319
Averaged Test Accuracy: 0.7984
Averaged Test AUC: 0.7562
Averaged Test Precision: 0.7920
Averaged Test Recall: 0.7984
Averaged Test F1-Score: 0.7629
Std Test Accuracy: 0.0450
Std Test AUC: 0.0574
------------------------------------------------------------
Round 18 time cost: 4.99s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 19)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7814
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.8005

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 20: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 19 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4310
Averaged Test Accuracy: 0.8005
Averaged Test AUC: 0.7567
Averaged Test Precision: 0.7946
Averaged Test Recall: 0.8005
Averaged Test F1-Score: 0.7672
Std Test Accuracy: 0.0439
Std Test AUC: 0.0578
------------------------------------------------------------
Round 19 time cost: 4.99s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 20)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 21: ˥�� 10% (��2��)
    Base: 0.8229 �� Decayed: 0.7406 �� Final: 0.7406
  Current threshold (based on ACC(t-1)): 0.7406
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7996

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 20):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 21: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 20 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4313
Averaged Test Accuracy: 0.7996
Averaged Test AUC: 0.7564
Averaged Test Precision: 0.7927
Averaged Test Recall: 0.7996
Averaged Test F1-Score: 0.7663
Std Test Accuracy: 0.0451
Std Test AUC: 0.0561
------------------------------------------------------------
Round 20 time cost: 4.69s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 21)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7402
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.8003

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 22: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 21 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4301
Averaged Test Accuracy: 0.8003
Averaged Test AUC: 0.7565
Averaged Test Precision: 0.7923
Averaged Test Recall: 0.8003
Averaged Test F1-Score: 0.7679
Std Test Accuracy: 0.0448
Std Test AUC: 0.0567
------------------------------------------------------------
Round 21 time cost: 5.05s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 22)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7405
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.8016

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 23: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 22 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4297
Averaged Test Accuracy: 0.8016
Averaged Test AUC: 0.7575
Averaged Test Precision: 0.7961
Averaged Test Recall: 0.8016
Averaged Test F1-Score: 0.7701
Std Test Accuracy: 0.0446
Std Test AUC: 0.0556
------------------------------------------------------------
Round 22 time cost: 4.91s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 23)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7417
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.8009

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 24: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 23 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4309
Averaged Test Accuracy: 0.8009
Averaged Test AUC: 0.7572
Averaged Test Precision: 0.7958
Averaged Test Recall: 0.8009
Averaged Test F1-Score: 0.7684
Std Test Accuracy: 0.0450
Std Test AUC: 0.0562
------------------------------------------------------------
Round 23 time cost: 4.91s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 24)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7414
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.8013

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 25: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 24 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4283
Averaged Test Accuracy: 0.8013
Averaged Test AUC: 0.7576
Averaged Test Precision: 0.7961
Averaged Test Recall: 0.8013
Averaged Test F1-Score: 0.7701
Std Test Accuracy: 0.0465
Std Test AUC: 0.0544
------------------------------------------------------------
Round 24 time cost: 5.25s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 25)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 26: ˥�� 15% (��3��)
    Base: 0.8240 �� Decayed: 0.7004 �� Final: 0.7004
  Current threshold (based on ACC(t-1)): 0.7004
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.8001
  Client 5 meets threshold! Generating virtual data...
  Client 5: Privacy disabled, skipping baseline VAE training.
  Client 5: Skipped virtual data generation (ratio=1.0)
  Client 5: No noise added (privacy disabled).
  Newly qualified clients: [5]
  Total qualified clients: 10/10
  Virtual data pool size: 0

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 25):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 26: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 25 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4288
Averaged Test Accuracy: 0.8001
Averaged Test AUC: 0.7573
Averaged Test Precision: 0.7929
Averaged Test Recall: 0.8001
Averaged Test F1-Score: 0.7668
Std Test Accuracy: 0.0440
Std Test AUC: 0.0565
------------------------------------------------------------
Round 25 time cost: 4.79s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 26)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.6993
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.8017

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 27: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 26 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4274
Averaged Test Accuracy: 0.8017
Averaged Test AUC: 0.7583
Averaged Test Precision: 0.7936
Averaged Test Recall: 0.8017
Averaged Test F1-Score: 0.7706
Std Test Accuracy: 0.0463
Std Test AUC: 0.0557
------------------------------------------------------------
Round 26 time cost: 4.92s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 27)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7006
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7997

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 28: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 27 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4277
Averaged Test Accuracy: 0.7997
Averaged Test AUC: 0.7581
Averaged Test Precision: 0.7910
Averaged Test Recall: 0.7997
Averaged Test F1-Score: 0.7667
Std Test Accuracy: 0.0451
Std Test AUC: 0.0555
------------------------------------------------------------
Round 27 time cost: 4.81s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 28)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.6992
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.8009

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 29: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 28 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4274
Averaged Test Accuracy: 0.8009
Averaged Test AUC: 0.7575
Averaged Test Precision: 0.7944
Averaged Test Recall: 0.8009
Averaged Test F1-Score: 0.7694
Std Test Accuracy: 0.0458
Std Test AUC: 0.0549
------------------------------------------------------------
Round 28 time cost: 4.60s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 29)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7002
  Best client accuracy (ACC(t)): 0.8480
  Global average accuracy (ACC(t)): 0.8012

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 30: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 29 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4263
Averaged Test Accuracy: 0.8012
Averaged Test AUC: 0.7582
Averaged Test Precision: 0.7957
Averaged Test Recall: 0.8012
Averaged Test F1-Score: 0.7699
Std Test Accuracy: 0.0460
Std Test AUC: 0.0554
------------------------------------------------------------
Round 29 time cost: 5.15s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 30)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 7] ��ͣ��� (��ǰ׼ȷ��: 0.7293)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6802
       ��29��: 0.7360 >= 0.6802 [+]
       ��30��: 0.7307 >= 0.6802 [+]
       ��31��: 0.7293 >= 0.6802 [+]
    [+] ����(3): �������ȶ� (0.0067 <= 0.0200)
       ���3��: ['0.7360', '0.7307', '0.7293']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 7 reached early stopping criteria (Round 31):
    - Accuracy: 0.7293 (threshold: 0.7002)
    - Fluctuation: 0.0067 (last 3 rounds)
    - History: ['0.736', '0.731', '0.729']
  [Virtual Data] Generating and locking virtual data for client 7...
  [Mentor Mode] Client 7 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 7 early stopped at round 30
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 1] ��ͣ��� (��ǰ׼ȷ��: 0.8360)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6802
       ��29��: 0.8413 >= 0.6802 [+]
       ��30��: 0.8480 >= 0.6802 [+]
       ��31��: 0.8360 >= 0.6802 [+]
    [+] ����(3): �������ȶ� (0.0120 <= 0.0200)
       ���3��: ['0.8413', '0.8480', '0.8360']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 1 reached early stopping criteria (Round 31):
    - Accuracy: 0.8360 (threshold: 0.7002)
    - Fluctuation: 0.0120 (last 3 rounds)
    - History: ['0.841', '0.848', '0.836']
  [Virtual Data] Generating and locking virtual data for client 1...
  [Mentor Mode] Client 1 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 1 early stopped at round 30
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 3] ��ͣ��� (��ǰ׼ȷ��: 0.7867)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6802
       ��29��: 0.7827 >= 0.6802 [+]
       ��30��: 0.7787 >= 0.6802 [+]
       ��31��: 0.7867 >= 0.6802 [+]
    [+] ����(3): �������ȶ� (0.0080 <= 0.0200)
       ���3��: ['0.7827', '0.7787', '0.7867']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 3 reached early stopping criteria (Round 31):
    - Accuracy: 0.7867 (threshold: 0.7002)
    - Fluctuation: 0.0080 (last 3 rounds)
    - History: ['0.783', '0.779', '0.787']
  [Virtual Data] Generating and locking virtual data for client 3...
  [Mentor Mode] Client 3 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 3 early stopped at round 30
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 5] ��ͣ��� (��ǰ׼ȷ��: 0.7173)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6802
       ��29��: 0.7080 >= 0.6802 [+]
       ��30��: 0.7147 >= 0.6802 [+]
       ��31��: 0.7173 >= 0.6802 [+]
    [+] ����(3): �������ȶ� (0.0093 <= 0.0200)
       ���3��: ['0.7080', '0.7147', '0.7173']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 5 reached early stopping criteria (Round 31):
    - Accuracy: 0.7173 (threshold: 0.7002)
    - Fluctuation: 0.0093 (last 3 rounds)
    - History: ['0.708', '0.715', '0.717']
  [Virtual Data] Generating and locking virtual data for client 5...
  [Mentor Mode] Client 5 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 5 early stopped at round 30
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 4] ��ͣ��� (��ǰ׼ȷ��: 0.8333)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6802
       ��29��: 0.8320 >= 0.6802 [+]
       ��30��: 0.8320 >= 0.6802 [+]
       ��31��: 0.8333 >= 0.6802 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.8320', '0.8320', '0.8333']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 4 reached early stopping criteria (Round 31):
    - Accuracy: 0.8333 (threshold: 0.7002)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.832', '0.832', '0.833']
  [Virtual Data] Generating and locking virtual data for client 4...
  [Mentor Mode] Client 4 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 4 early stopped at round 30
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 0] ��ͣ��� (��ǰ׼ȷ��: 0.8373)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6802
       ��29��: 0.8347 >= 0.6802 [+]
       ��30��: 0.8333 >= 0.6802 [+]
       ��31��: 0.8373 >= 0.6802 [+]
    [+] ����(3): �������ȶ� (0.0040 <= 0.0200)
       ���3��: ['0.8347', '0.8333', '0.8373']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 0 reached early stopping criteria (Round 31):
    - Accuracy: 0.8373 (threshold: 0.7002)
    - Fluctuation: 0.0040 (last 3 rounds)
    - History: ['0.835', '0.833', '0.837']
  [Virtual Data] Generating and locking virtual data for client 0...
  [Mentor Mode] Client 0 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 0 early stopped at round 30
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 2] ��ͣ��� (��ǰ׼ȷ��: 0.7880)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6802
       ��29��: 0.7867 >= 0.6802 [+]
       ��30��: 0.7853 >= 0.6802 [+]
       ��31��: 0.7880 >= 0.6802 [+]
    [+] ����(3): �������ȶ� (0.0027 <= 0.0200)
       ���3��: ['0.7867', '0.7853', '0.7880']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 2 reached early stopping criteria (Round 31):
    - Accuracy: 0.7880 (threshold: 0.7002)
    - Fluctuation: 0.0027 (last 3 rounds)
    - History: ['0.787', '0.785', '0.788']
  [Virtual Data] Generating and locking virtual data for client 2...
  [Mentor Mode] Client 2 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 2 early stopped at round 30
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 9] ��ͣ��� (��ǰ׼ȷ��: 0.8493)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6802
       ��29��: 0.8427 >= 0.6802 [+]
       ��30��: 0.8413 >= 0.6802 [+]
       ��31��: 0.8493 >= 0.6802 [+]
    [+] ����(3): �������ȶ� (0.0080 <= 0.0200)
       ���3��: ['0.8427', '0.8413', '0.8493']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 9 reached early stopping criteria (Round 31):
    - Accuracy: 0.8493 (threshold: 0.7002)
    - Fluctuation: 0.0080 (last 3 rounds)
    - History: ['0.843', '0.841', '0.849']
  [Virtual Data] Generating and locking virtual data for client 9...
  [Mentor Mode] Client 9 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 9 early stopped at round 30
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 8] ��ͣ��� (��ǰ׼ȷ��: 0.7973)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6802
       ��29��: 0.7987 >= 0.6802 [+]
       ��30��: 0.8000 >= 0.6802 [+]
       ��31��: 0.7973 >= 0.6802 [+]
    [+] ����(3): �������ȶ� (0.0027 <= 0.0200)
       ���3��: ['0.7987', '0.8000', '0.7973']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 8 reached early stopping criteria (Round 31):
    - Accuracy: 0.7973 (threshold: 0.7002)
    - Fluctuation: 0.0027 (last 3 rounds)
    - History: ['0.799', '0.800', '0.797']
  [Virtual Data] Generating and locking virtual data for client 8...
  [Mentor Mode] Client 8 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 8 early stopped at round 30
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 6] ��ͣ��� (��ǰ׼ȷ��: 0.8467)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6802
       ��29��: 0.8467 >= 0.6802 [+]
       ��30��: 0.8480 >= 0.6802 [+]
       ��31��: 0.8467 >= 0.6802 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.8467', '0.8480', '0.8467']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 6 reached early stopping criteria (Round 31):
    - Accuracy: 0.8467 (threshold: 0.7002)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.847', '0.848', '0.847']
  [Virtual Data] Generating and locking virtual data for client 6...
  [Mentor Mode] Client 6 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 6 early stopped at round 30
  [Threshold Decay] Round 31: ˥�� 20% (��4��)
    Base: 0.8246 �� Decayed: 0.6597 �� Final: 0.6600
  Current threshold (based on ACC(t-1)): 0.6600
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8021

  [Adaptive Decay] Ȩ��˥���������� (Round 31):
  ��ǰȫ��׼ȷ��: 0.8021
  ˥��ǿ�Ȧ�: 0.5
    Client 7: ��31�ִ��
      ���ʱ׼ȷ��: 0.8021
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 1: ��31�ִ��
      ���ʱ׼ȷ��: 0.8021
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 3: ��31�ִ��
      ���ʱ׼ȷ��: 0.8021
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 5: ��31�ִ��
      ���ʱ׼ȷ��: 0.8021
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 4: ��31�ִ��
      ���ʱ׼ȷ��: 0.8021
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 0: ��31�ִ��
      ���ʱ׼ȷ��: 0.8021
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 2: ��31�ִ��
      ���ʱ׼ȷ��: 0.8021
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 9: ��31�ִ��
      ���ʱ׼ȷ��: 0.8021
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 8: ��31�ִ��
      ���ʱ׼ȷ��: 0.8021
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 6: ��31�ִ��
      ���ʱ׼ȷ��: 0.8021
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
  Early-stopped clients: 10/10
  Active training clients: 0

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 30):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 1   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 2   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 3   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 4   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 5   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 6   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 7   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 8   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 9   2250        1.0000        2250.00         0.1000          ��ͣ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  [Adaptive Decay] Prototype aggregation weights: C0=1.000 C1=1.000 C2=1.000 C3=1.000 C4=1.000 ... (10 total)
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

================================================================================
[Phase Transition Check] Round 31 (Phase 1: ���50��)
================================================================================
���Ҫ��: 7/10 �ͻ��� (70%)
��ǰ״̬: 10/10 �ͻ��˴��

�ͻ�����ϸ״̬:

[+] �Ѵ��ͻ��� (10��):
  Client 9: 0.8493 [+]
  Client 6: 0.8467 [+]
  Client 0: 0.8373 [+]
  Client 1: 0.8360 [+]
  Client 4: 0.8333 [+]
  Client 8: 0.7973 [+]
  Client 2: 0.7880 [+]
  Client 3: 0.7867 [+]
  Client 7: 0.7293 [+]
  Client 5: 0.7173 [+]

��ǰ��ֵ: 0.6600
ƽ��׼ȷ��: 0.8021
���׼ȷ��: 0.8493
================================================================================

[>>] Phase Transition Triggered! (70% Threshold Strategy)
   Qualified clients: 10/10
   Required: 7 (70%)
   Remaining: 0 clients will join dynamically in Phase 2
   Phase 1 completed: 31 rounds (min: 30, max: 50)
================================================================================


============================================================
PHASE TRANSITION: Phase 1 �� Phase 2
============================================================
Virtual data pool size: 0
Phase 2 Algorithm: FEDAVG
Phase 2 Max Rounds: 50
============================================================

  [Algorithm Name] Updated: FedGpro �� FedGpro-FedAvg
  Client 0: Phase 2 (already contributed virtual data)
  Client 1: Phase 2 (already contributed virtual data)
  Client 2: Phase 2 (already contributed virtual data)
  Client 3: Phase 2 (already contributed virtual data)
  Client 4: Phase 2 (already contributed virtual data)
  Client 5: Phase 2 (already contributed virtual data)
  Client 6: Phase 2 (already contributed virtual data)
  Client 7: Phase 2 (already contributed virtual data)
  Client 8: Phase 2 (already contributed virtual data)
  Client 9: Phase 2 (already contributed virtual data)
[OK] Phase 2 initialized successfully!
   Algorithm: FEDAVG
   All clients enter Phase 2: 10 (100%)
   - Already contributed virtual data: 10 (100%)
   - Can still contribute (until round 20): 0 (0%)
   Virtual data pool size: 0 samples
   Phase 1 will continue in parallel until round 20


============================================================
Round 30 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 1.6007
Averaged Test Accuracy (Personalized): 0.5695
Averaged Test AUC (Personalized): 0.5146
Std Test Accuracy (Personalized): 0.1021
Std Test AUC (Personalized): 0.0830

Evaluate global model (Reference only)
Averaged Train Loss: 0.4258
Averaged Test Accuracy: 0.8021
Averaged Test AUC: 0.7583
Averaged Test Precision: 0.7935
Averaged Test Recall: 0.8021
Averaged Test F1-Score: 0.7708
Std Test Accuracy: 0.0453
Std Test AUC: 0.0555
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 30 time cost: 5.26s
------------------------------------------------------------

[Phase 2 - Round 31] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 31 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.8409
Averaged Test Accuracy (Personalized): 0.6272
Averaged Test AUC (Personalized): 0.5117
Std Test Accuracy (Personalized): 0.0570
Std Test AUC (Personalized): 0.0804

Evaluate global model (Reference only)
Averaged Train Loss: 0.7203
Averaged Test Accuracy: 0.6888
Averaged Test AUC: 0.5532
Averaged Test Precision: 0.6702
Averaged Test Recall: 0.6888
Averaged Test F1-Score: 0.6781
Std Test Accuracy: 0.0619
Std Test AUC: 0.0934
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 31 time cost: 4.79s
------------------------------------------------------------

[Phase 2 - Round 32] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 32 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.7214
Averaged Test Accuracy (Personalized): 0.6856
Averaged Test AUC (Personalized): 0.5585
Std Test Accuracy (Personalized): 0.0544
Std Test AUC (Personalized): 0.0988

Evaluate global model (Reference only)
Averaged Train Loss: 0.6383
Averaged Test Accuracy: 0.7367
Averaged Test AUC: 0.6005
Averaged Test Precision: 0.6955
Averaged Test Recall: 0.7367
Averaged Test F1-Score: 0.7086
Std Test Accuracy: 0.0659
Std Test AUC: 0.0931
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 32 time cost: 5.17s
------------------------------------------------------------

[Phase 2 - Round 33] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 33 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.6646
Averaged Test Accuracy (Personalized): 0.7293
Averaged Test AUC (Personalized): 0.5881
Std Test Accuracy (Personalized): 0.0558
Std Test AUC (Personalized): 0.1002

Evaluate global model (Reference only)
Averaged Train Loss: 0.5911
Averaged Test Accuracy: 0.7573
Averaged Test AUC: 0.6330
Averaged Test Precision: 0.7158
Averaged Test Recall: 0.7573
Averaged Test F1-Score: 0.7237
Std Test Accuracy: 0.0592
Std Test AUC: 0.0887
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 33 time cost: 4.68s
------------------------------------------------------------

[Phase 2 - Round 34] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 34 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.6218
Averaged Test Accuracy (Personalized): 0.7459
Averaged Test AUC (Personalized): 0.6104
Std Test Accuracy (Personalized): 0.0612
Std Test AUC (Personalized): 0.0993

Evaluate global model (Reference only)
Averaged Train Loss: 0.5686
Averaged Test Accuracy: 0.7635
Averaged Test AUC: 0.6520
Averaged Test Precision: 0.7244
Averaged Test Recall: 0.7635
Averaged Test F1-Score: 0.7265
Std Test Accuracy: 0.0602
Std Test AUC: 0.0841
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 34 time cost: 4.86s
------------------------------------------------------------

[Phase 2 - Round 35] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 35 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.6015
Averaged Test Accuracy (Personalized): 0.7585
Averaged Test AUC (Personalized): 0.6268
Std Test Accuracy (Personalized): 0.0561
Std Test AUC (Personalized): 0.0995

Evaluate global model (Reference only)
Averaged Train Loss: 0.5497
Averaged Test Accuracy: 0.7701
Averaged Test AUC: 0.6674
Averaged Test Precision: 0.7339
Averaged Test Recall: 0.7701
Averaged Test F1-Score: 0.7322
Std Test Accuracy: 0.0548
Std Test AUC: 0.0800
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 35 time cost: 4.75s
------------------------------------------------------------

[Phase 2 - Round 36] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 36 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5854
Averaged Test Accuracy (Personalized): 0.7648
Averaged Test AUC (Personalized): 0.6398
Std Test Accuracy (Personalized): 0.0543
Std Test AUC (Personalized): 0.0919

Evaluate global model (Reference only)
Averaged Train Loss: 0.5357
Averaged Test Accuracy: 0.7757
Averaged Test AUC: 0.6759
Averaged Test Precision: 0.7441
Averaged Test Recall: 0.7757
Averaged Test F1-Score: 0.7369
Std Test Accuracy: 0.0524
Std Test AUC: 0.0787
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 36 time cost: 4.51s
------------------------------------------------------------

[Phase 2 - Round 37] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 37 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5707
Averaged Test Accuracy (Personalized): 0.7673
Averaged Test AUC (Personalized): 0.6507
Std Test Accuracy (Personalized): 0.0550
Std Test AUC (Personalized): 0.0902

Evaluate global model (Reference only)
Averaged Train Loss: 0.5221
Averaged Test Accuracy: 0.7728
Averaged Test AUC: 0.6838
Averaged Test Precision: 0.7408
Averaged Test Recall: 0.7728
Averaged Test F1-Score: 0.7296
Std Test Accuracy: 0.0549
Std Test AUC: 0.0772
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 37 time cost: 5.35s
------------------------------------------------------------

[Phase 2 - Round 38] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 38 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5611
Averaged Test Accuracy (Personalized): 0.7696
Averaged Test AUC (Personalized): 0.6585
Std Test Accuracy (Personalized): 0.0541
Std Test AUC (Personalized): 0.0876

Evaluate global model (Reference only)
Averaged Train Loss: 0.5152
Averaged Test Accuracy: 0.7728
Averaged Test AUC: 0.6868
Averaged Test Precision: 0.7454
Averaged Test Recall: 0.7728
Averaged Test F1-Score: 0.7254
Std Test Accuracy: 0.0587
Std Test AUC: 0.0758
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 38 time cost: 4.53s
------------------------------------------------------------

[Phase 2 - Round 39] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 39 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5525
Averaged Test Accuracy (Personalized): 0.7724
Averaged Test AUC (Personalized): 0.6670
Std Test Accuracy (Personalized): 0.0536
Std Test AUC (Personalized): 0.0831

Evaluate global model (Reference only)
Averaged Train Loss: 0.5100
Averaged Test Accuracy: 0.7727
Averaged Test AUC: 0.6908
Averaged Test Precision: 0.7505
Averaged Test Recall: 0.7727
Averaged Test F1-Score: 0.7237
Std Test Accuracy: 0.0602
Std Test AUC: 0.0776
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 39 time cost: 4.96s
------------------------------------------------------------

[Phase 2 - Round 40] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 40 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5412
Averaged Test Accuracy (Personalized): 0.7763
Averaged Test AUC (Personalized): 0.6720
Std Test Accuracy (Personalized): 0.0524
Std Test AUC (Personalized): 0.0822

Evaluate global model (Reference only)
Averaged Train Loss: 0.5065
Averaged Test Accuracy: 0.7712
Averaged Test AUC: 0.6925
Averaged Test Precision: 0.7500
Averaged Test Recall: 0.7712
Averaged Test F1-Score: 0.7198
Std Test Accuracy: 0.0606
Std Test AUC: 0.0765
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 40 time cost: 4.95s
------------------------------------------------------------

[Phase 2 - Round 41] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 41 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5394
Averaged Test Accuracy (Personalized): 0.7781
Averaged Test AUC (Personalized): 0.6756
Std Test Accuracy (Personalized): 0.0490
Std Test AUC (Personalized): 0.0805

Evaluate global model (Reference only)
Averaged Train Loss: 0.5031
Averaged Test Accuracy: 0.7708
Averaged Test AUC: 0.6946
Averaged Test Precision: 0.7615
Averaged Test Recall: 0.7708
Averaged Test F1-Score: 0.7173
Std Test Accuracy: 0.0628
Std Test AUC: 0.0764
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 41 time cost: 4.78s
------------------------------------------------------------

[Phase 2 - Round 42] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 42 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5303
Averaged Test Accuracy (Personalized): 0.7771
Averaged Test AUC (Personalized): 0.6806
Std Test Accuracy (Personalized): 0.0501
Std Test AUC (Personalized): 0.0796

Evaluate global model (Reference only)
Averaged Train Loss: 0.5004
Averaged Test Accuracy: 0.7677
Averaged Test AUC: 0.6949
Averaged Test Precision: 0.7504
Averaged Test Recall: 0.7677
Averaged Test F1-Score: 0.7107
Std Test Accuracy: 0.0643
Std Test AUC: 0.0763
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 42 time cost: 5.10s
------------------------------------------------------------

[Phase 2 - Round 43] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 43 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5276
Averaged Test Accuracy (Personalized): 0.7799
Averaged Test AUC (Personalized): 0.6848
Std Test Accuracy (Personalized): 0.0475
Std Test AUC (Personalized): 0.0770

Evaluate global model (Reference only)
Averaged Train Loss: 0.4979
Averaged Test Accuracy: 0.7657
Averaged Test AUC: 0.6990
Averaged Test Precision: 0.7553
Averaged Test Recall: 0.7657
Averaged Test F1-Score: 0.7057
Std Test Accuracy: 0.0662
Std Test AUC: 0.0757
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 43 time cost: 4.89s
------------------------------------------------------------

[Phase 2 - Round 44] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 44 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5223
Averaged Test Accuracy (Personalized): 0.7804
Averaged Test AUC (Personalized): 0.6891
Std Test Accuracy (Personalized): 0.0484
Std Test AUC (Personalized): 0.0756

Evaluate global model (Reference only)
Averaged Train Loss: 0.4970
Averaged Test Accuracy: 0.7636
Averaged Test AUC: 0.6967
Averaged Test Precision: 0.7643
Averaged Test Recall: 0.7636
Averaged Test F1-Score: 0.7004
Std Test Accuracy: 0.0703
Std Test AUC: 0.0773
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 44 time cost: 4.82s
------------------------------------------------------------

[Phase 2 - Round 45] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 45 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5153
Averaged Test Accuracy (Personalized): 0.7808
Averaged Test AUC (Personalized): 0.6902
Std Test Accuracy (Personalized): 0.0490
Std Test AUC (Personalized): 0.0747

Evaluate global model (Reference only)
Averaged Train Loss: 0.4949
Averaged Test Accuracy: 0.7648
Averaged Test AUC: 0.7040
Averaged Test Precision: 0.7448
Averaged Test Recall: 0.7648
Averaged Test F1-Score: 0.7024
Std Test Accuracy: 0.0686
Std Test AUC: 0.0744
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 45 time cost: 5.28s
------------------------------------------------------------

[Phase 2 - Round 46] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 46 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5127
Averaged Test Accuracy (Personalized): 0.7813
Averaged Test AUC (Personalized): 0.6942
Std Test Accuracy (Personalized): 0.0458
Std Test AUC (Personalized): 0.0746

Evaluate global model (Reference only)
Averaged Train Loss: 0.4948
Averaged Test Accuracy: 0.7593
Averaged Test AUC: 0.7022
Averaged Test Precision: 0.7468
Averaged Test Recall: 0.7593
Averaged Test F1-Score: 0.6930
Std Test Accuracy: 0.0739
Std Test AUC: 0.0758
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 46 time cost: 4.95s
------------------------------------------------------------

[Phase 2 - Round 47] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 47 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5100
Averaged Test Accuracy (Personalized): 0.7817
Averaged Test AUC (Personalized): 0.6969
Std Test Accuracy (Personalized): 0.0476
Std Test AUC (Personalized): 0.0720

Evaluate global model (Reference only)
Averaged Train Loss: 0.4919
Averaged Test Accuracy: 0.7637
Averaged Test AUC: 0.7050
Averaged Test Precision: 0.7508
Averaged Test Recall: 0.7637
Averaged Test F1-Score: 0.7004
Std Test Accuracy: 0.0701
Std Test AUC: 0.0738
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 47 time cost: 5.15s
------------------------------------------------------------

[Phase 2 - Round 48] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 48 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5064
Averaged Test Accuracy (Personalized): 0.7840
Averaged Test AUC (Personalized): 0.6995
Std Test Accuracy (Personalized): 0.0454
Std Test AUC (Personalized): 0.0718

Evaluate global model (Reference only)
Averaged Train Loss: 0.4927
Averaged Test Accuracy: 0.7599
Averaged Test AUC: 0.7087
Averaged Test Precision: 0.7547
Averaged Test Recall: 0.7599
Averaged Test F1-Score: 0.6913
Std Test Accuracy: 0.0746
Std Test AUC: 0.0729
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 48 time cost: 5.42s
------------------------------------------------------------

[Phase 2 - Round 49] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 49 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5047
Averaged Test Accuracy (Personalized): 0.7832
Averaged Test AUC (Personalized): 0.7008
Std Test Accuracy (Personalized): 0.0465
Std Test AUC (Personalized): 0.0715

Evaluate global model (Reference only)
Averaged Train Loss: 0.4909
Averaged Test Accuracy: 0.7595
Averaged Test AUC: 0.7095
Averaged Test Precision: 0.7416
Averaged Test Recall: 0.7595
Averaged Test F1-Score: 0.6916
Std Test Accuracy: 0.0742
Std Test AUC: 0.0736
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 49 time cost: 4.07s
------------------------------------------------------------

[Phase 2 - Round 50] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 50 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5045
Averaged Test Accuracy (Personalized): 0.7848
Averaged Test AUC (Personalized): 0.7020
Std Test Accuracy (Personalized): 0.0456
Std Test AUC (Personalized): 0.0714

Evaluate global model (Reference only)
Averaged Train Loss: 0.4914
Averaged Test Accuracy: 0.7592
Averaged Test AUC: 0.7103
Averaged Test Precision: 0.7523
Averaged Test Recall: 0.7592
Averaged Test F1-Score: 0.6907
Std Test Accuracy: 0.0752
Std Test AUC: 0.0731
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 50 time cost: 4.53s
------------------------------------------------------------

[Phase 2 - Round 51] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 51 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4996
Averaged Test Accuracy (Personalized): 0.7853
Averaged Test AUC (Personalized): 0.7027
Std Test Accuracy (Personalized): 0.0466
Std Test AUC (Personalized): 0.0725

Evaluate global model (Reference only)
Averaged Train Loss: 0.4907
Averaged Test Accuracy: 0.7572
Averaged Test AUC: 0.7140
Averaged Test Precision: 0.7697
Averaged Test Recall: 0.7572
Averaged Test F1-Score: 0.6871
Std Test Accuracy: 0.0776
Std Test AUC: 0.0721
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 51 time cost: 4.22s
------------------------------------------------------------

[Phase 2 - Round 52] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 52 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4974
Averaged Test Accuracy (Personalized): 0.7840
Averaged Test AUC (Personalized): 0.7058
Std Test Accuracy (Personalized): 0.0449
Std Test AUC (Personalized): 0.0699

Evaluate global model (Reference only)
Averaged Train Loss: 0.4879
Averaged Test Accuracy: 0.7612
Averaged Test AUC: 0.7164
Averaged Test Precision: 0.7713
Averaged Test Recall: 0.7612
Averaged Test F1-Score: 0.6954
Std Test Accuracy: 0.0727
Std Test AUC: 0.0716
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 52 time cost: 4.08s
------------------------------------------------------------

[Phase 2 - Round 53] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 53 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4974
Averaged Test Accuracy (Personalized): 0.7844
Averaged Test AUC (Personalized): 0.7060
Std Test Accuracy (Personalized): 0.0475
Std Test AUC (Personalized): 0.0718

Evaluate global model (Reference only)
Averaged Train Loss: 0.4888
Averaged Test Accuracy: 0.7591
Averaged Test AUC: 0.7134
Averaged Test Precision: 0.7518
Averaged Test Recall: 0.7591
Averaged Test F1-Score: 0.6911
Std Test Accuracy: 0.0746
Std Test AUC: 0.0726
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 53 time cost: 4.56s
------------------------------------------------------------

[Phase 2 - Round 54] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 54 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4933
Averaged Test Accuracy (Personalized): 0.7856
Averaged Test AUC (Personalized): 0.7082
Std Test Accuracy (Personalized): 0.0467
Std Test AUC (Personalized): 0.0703

Evaluate global model (Reference only)
Averaged Train Loss: 0.4876
Averaged Test Accuracy: 0.7580
Averaged Test AUC: 0.7182
Averaged Test Precision: 0.7497
Averaged Test Recall: 0.7580
Averaged Test F1-Score: 0.6883
Std Test Accuracy: 0.0753
Std Test AUC: 0.0709
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 54 time cost: 4.38s
------------------------------------------------------------

[Phase 2 - Round 55] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 55 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4924
Averaged Test Accuracy (Personalized): 0.7840
Averaged Test AUC (Personalized): 0.7091
Std Test Accuracy (Personalized): 0.0485
Std Test AUC (Personalized): 0.0703

Evaluate global model (Reference only)
Averaged Train Loss: 0.4873
Averaged Test Accuracy: 0.7585
Averaged Test AUC: 0.7204
Averaged Test Precision: 0.7611
Averaged Test Recall: 0.7585
Averaged Test F1-Score: 0.6901
Std Test Accuracy: 0.0758
Std Test AUC: 0.0702
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 55 time cost: 4.24s
------------------------------------------------------------

[Phase 2 - Round 56] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 56 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4926
Averaged Test Accuracy (Personalized): 0.7843
Averaged Test AUC (Personalized): 0.7047
Std Test Accuracy (Personalized): 0.0492
Std Test AUC (Personalized): 0.0715

Evaluate global model (Reference only)
Averaged Train Loss: 0.4865
Averaged Test Accuracy: 0.7573
Averaged Test AUC: 0.7207
Averaged Test Precision: 0.7512
Averaged Test Recall: 0.7573
Averaged Test F1-Score: 0.6871
Std Test Accuracy: 0.0770
Std Test AUC: 0.0698
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 56 time cost: 4.36s
------------------------------------------------------------

[Phase 2 - Round 57] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 57 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4911
Averaged Test Accuracy (Personalized): 0.7857
Averaged Test AUC (Personalized): 0.7099
Std Test Accuracy (Personalized): 0.0469
Std Test AUC (Personalized): 0.0716

Evaluate global model (Reference only)
Averaged Train Loss: 0.4875
Averaged Test Accuracy: 0.7564
Averaged Test AUC: 0.7221
Averaged Test Precision: 0.7525
Averaged Test Recall: 0.7564
Averaged Test F1-Score: 0.6855
Std Test Accuracy: 0.0787
Std Test AUC: 0.0699
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 57 time cost: 4.57s
------------------------------------------------------------

[Phase 2 - Round 58] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 58 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4902
Averaged Test Accuracy (Personalized): 0.7841
Averaged Test AUC (Personalized): 0.7080
Std Test Accuracy (Personalized): 0.0477
Std Test AUC (Personalized): 0.0726

Evaluate global model (Reference only)
Averaged Train Loss: 0.4853
Averaged Test Accuracy: 0.7585
Averaged Test AUC: 0.7213
Averaged Test Precision: 0.7679
Averaged Test Recall: 0.7585
Averaged Test F1-Score: 0.6892
Std Test Accuracy: 0.0746
Std Test AUC: 0.0697
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 58 time cost: 4.55s
------------------------------------------------------------

[Phase 2 - Round 59] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 59 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4863
Averaged Test Accuracy (Personalized): 0.7859
Averaged Test AUC (Personalized): 0.7132
Std Test Accuracy (Personalized): 0.0471
Std Test AUC (Personalized): 0.0684

Evaluate global model (Reference only)
Averaged Train Loss: 0.4848
Averaged Test Accuracy: 0.7600
Averaged Test AUC: 0.7231
Averaged Test Precision: 0.7719
Averaged Test Recall: 0.7600
Averaged Test F1-Score: 0.6915
Std Test Accuracy: 0.0741
Std Test AUC: 0.0690
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 59 time cost: 4.64s
------------------------------------------------------------

[Phase 2 - Round 60] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 60 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4855
Averaged Test Accuracy (Personalized): 0.7868
Averaged Test AUC (Personalized): 0.7121
Std Test Accuracy (Personalized): 0.0468
Std Test AUC (Personalized): 0.0695

Evaluate global model (Reference only)
Averaged Train Loss: 0.4835
Averaged Test Accuracy: 0.7593
Averaged Test AUC: 0.7233
Averaged Test Precision: 0.7332
Averaged Test Recall: 0.7593
Averaged Test F1-Score: 0.6908
Std Test Accuracy: 0.0740
Std Test AUC: 0.0708
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 60 time cost: 4.29s
------------------------------------------------------------

[Phase 2 - Round 61] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 61 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4853
Averaged Test Accuracy (Personalized): 0.7864
Averaged Test AUC (Personalized): 0.7133
Std Test Accuracy (Personalized): 0.0495
Std Test AUC (Personalized): 0.0694

Evaluate global model (Reference only)
Averaged Train Loss: 0.4834
Averaged Test Accuracy: 0.7615
Averaged Test AUC: 0.7246
Averaged Test Precision: 0.7703
Averaged Test Recall: 0.7615
Averaged Test F1-Score: 0.6940
Std Test Accuracy: 0.0725
Std Test AUC: 0.0690
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 61 time cost: 4.43s
------------------------------------------------------------

[Phase 2 - Round 62] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 62 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4851
Averaged Test Accuracy (Personalized): 0.7847
Averaged Test AUC (Personalized): 0.7133
Std Test Accuracy (Personalized): 0.0478
Std Test AUC (Personalized): 0.0708

Evaluate global model (Reference only)
Averaged Train Loss: 0.4841
Averaged Test Accuracy: 0.7593
Averaged Test AUC: 0.7240
Averaged Test Precision: 0.7326
Averaged Test Recall: 0.7593
Averaged Test F1-Score: 0.6912
Std Test Accuracy: 0.0748
Std Test AUC: 0.0699
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 62 time cost: 4.61s
------------------------------------------------------------

[Phase 2 - Round 63] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 63 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4818
Averaged Test Accuracy (Personalized): 0.7857
Averaged Test AUC (Personalized): 0.7157
Std Test Accuracy (Personalized): 0.0494
Std Test AUC (Personalized): 0.0695

Evaluate global model (Reference only)
Averaged Train Loss: 0.4834
Averaged Test Accuracy: 0.7587
Averaged Test AUC: 0.7243
Averaged Test Precision: 0.7286
Averaged Test Recall: 0.7587
Averaged Test F1-Score: 0.6883
Std Test Accuracy: 0.0745
Std Test AUC: 0.0689
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 63 time cost: 4.23s
------------------------------------------------------------

[Phase 2 - Round 64] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 64 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4826
Averaged Test Accuracy (Personalized): 0.7868
Averaged Test AUC (Personalized): 0.7139
Std Test Accuracy (Personalized): 0.0470
Std Test AUC (Personalized): 0.0695

Evaluate global model (Reference only)
Averaged Train Loss: 0.4803
Averaged Test Accuracy: 0.7639
Averaged Test AUC: 0.7269
Averaged Test Precision: 0.7586
Averaged Test Recall: 0.7639
Averaged Test F1-Score: 0.6979
Std Test Accuracy: 0.0714
Std Test AUC: 0.0686
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 64 time cost: 4.30s
------------------------------------------------------------

[Phase 2 - Round 65] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 65 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4815
Averaged Test Accuracy (Personalized): 0.7840
Averaged Test AUC (Personalized): 0.7144
Std Test Accuracy (Personalized): 0.0500
Std Test AUC (Personalized): 0.0694

Evaluate global model (Reference only)
Averaged Train Loss: 0.4812
Averaged Test Accuracy: 0.7637
Averaged Test AUC: 0.7263
Averaged Test Precision: 0.7771
Averaged Test Recall: 0.7637
Averaged Test F1-Score: 0.6977
Std Test Accuracy: 0.0715
Std Test AUC: 0.0684
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 65 time cost: 4.31s
------------------------------------------------------------

[Phase 2 - Round 66] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 66 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4826
Averaged Test Accuracy (Personalized): 0.7852
Averaged Test AUC (Personalized): 0.7156
Std Test Accuracy (Personalized): 0.0486
Std Test AUC (Personalized): 0.0665

Evaluate global model (Reference only)
Averaged Train Loss: 0.4809
Averaged Test Accuracy: 0.7648
Averaged Test AUC: 0.7262
Averaged Test Precision: 0.7621
Averaged Test Recall: 0.7648
Averaged Test F1-Score: 0.7002
Std Test Accuracy: 0.0709
Std Test AUC: 0.0695
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 66 time cost: 4.20s
------------------------------------------------------------

[Phase 2 - Round 67] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 67 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4820
Averaged Test Accuracy (Personalized): 0.7860
Averaged Test AUC (Personalized): 0.7154
Std Test Accuracy (Personalized): 0.0484
Std Test AUC (Personalized): 0.0674

Evaluate global model (Reference only)
Averaged Train Loss: 0.4796
Averaged Test Accuracy: 0.7623
Averaged Test AUC: 0.7282
Averaged Test Precision: 0.7536
Averaged Test Recall: 0.7623
Averaged Test F1-Score: 0.6951
Std Test Accuracy: 0.0729
Std Test AUC: 0.0681
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 67 time cost: 4.28s
------------------------------------------------------------

[Phase 2 - Round 68] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 68 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4803
Averaged Test Accuracy (Personalized): 0.7849
Averaged Test AUC (Personalized): 0.7138
Std Test Accuracy (Personalized): 0.0480
Std Test AUC (Personalized): 0.0683

Evaluate global model (Reference only)
Averaged Train Loss: 0.4799
Averaged Test Accuracy: 0.7641
Averaged Test AUC: 0.7291
Averaged Test Precision: 0.7791
Averaged Test Recall: 0.7641
Averaged Test F1-Score: 0.6995
Std Test Accuracy: 0.0727
Std Test AUC: 0.0702
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 68 time cost: 4.45s
------------------------------------------------------------

[Phase 2 - Round 69] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 69 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4793
Averaged Test Accuracy (Personalized): 0.7844
Averaged Test AUC (Personalized): 0.7165
Std Test Accuracy (Personalized): 0.0501
Std Test AUC (Personalized): 0.0670

Evaluate global model (Reference only)
Averaged Train Loss: 0.4793
Averaged Test Accuracy: 0.7627
Averaged Test AUC: 0.7280
Averaged Test Precision: 0.7749
Averaged Test Recall: 0.7627
Averaged Test F1-Score: 0.6964
Std Test Accuracy: 0.0746
Std Test AUC: 0.0690
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 69 time cost: 4.35s
------------------------------------------------------------

[Phase 2 - Round 70] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 70 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4779
Averaged Test Accuracy (Personalized): 0.7845
Averaged Test AUC (Personalized): 0.7160
Std Test Accuracy (Personalized): 0.0508
Std Test AUC (Personalized): 0.0699

Evaluate global model (Reference only)
Averaged Train Loss: 0.4788
Averaged Test Accuracy: 0.7648
Averaged Test AUC: 0.7286
Averaged Test Precision: 0.7548
Averaged Test Recall: 0.7648
Averaged Test F1-Score: 0.6998
Std Test Accuracy: 0.0722
Std Test AUC: 0.0690
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 70 time cost: 4.44s
------------------------------------------------------------

[Phase 2 - Round 71] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 71 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4781
Averaged Test Accuracy (Personalized): 0.7843
Averaged Test AUC (Personalized): 0.7144
Std Test Accuracy (Personalized): 0.0503
Std Test AUC (Personalized): 0.0689

Evaluate global model (Reference only)
Averaged Train Loss: 0.4779
Averaged Test Accuracy: 0.7669
Averaged Test AUC: 0.7284
Averaged Test Precision: 0.7756
Averaged Test Recall: 0.7669
Averaged Test F1-Score: 0.7053
Std Test Accuracy: 0.0709
Std Test AUC: 0.0696
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 71 time cost: 4.39s
------------------------------------------------------------

[Phase 2 - Round 72] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 72 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4783
Averaged Test Accuracy (Personalized): 0.7832
Averaged Test AUC (Personalized): 0.7167
Std Test Accuracy (Personalized): 0.0521
Std Test AUC (Personalized): 0.0680

Evaluate global model (Reference only)
Averaged Train Loss: 0.4780
Averaged Test Accuracy: 0.7653
Averaged Test AUC: 0.7284
Averaged Test Precision: 0.7772
Averaged Test Recall: 0.7653
Averaged Test F1-Score: 0.7011
Std Test Accuracy: 0.0724
Std Test AUC: 0.0690
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 72 time cost: 4.09s
------------------------------------------------------------

[Phase 2 - Round 73] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 73 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4769
Averaged Test Accuracy (Personalized): 0.7847
Averaged Test AUC (Personalized): 0.7165
Std Test Accuracy (Personalized): 0.0476
Std Test AUC (Personalized): 0.0681

Evaluate global model (Reference only)
Averaged Train Loss: 0.4771
Averaged Test Accuracy: 0.7651
Averaged Test AUC: 0.7296
Averaged Test Precision: 0.7771
Averaged Test Recall: 0.7651
Averaged Test F1-Score: 0.7020
Std Test Accuracy: 0.0720
Std Test AUC: 0.0689
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 73 time cost: 4.30s
------------------------------------------------------------

[Phase 2 - Round 74] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 74 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4770
Averaged Test Accuracy (Personalized): 0.7836
Averaged Test AUC (Personalized): 0.7182
Std Test Accuracy (Personalized): 0.0507
Std Test AUC (Personalized): 0.0688

Evaluate global model (Reference only)
Averaged Train Loss: 0.4754
Averaged Test Accuracy: 0.7693
Averaged Test AUC: 0.7300
Averaged Test Precision: 0.7811
Averaged Test Recall: 0.7693
Averaged Test F1-Score: 0.7070
Std Test Accuracy: 0.0663
Std Test AUC: 0.0688
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 74 time cost: 4.28s
------------------------------------------------------------

[Phase 2 - Round 75] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 75 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4769
Averaged Test Accuracy (Personalized): 0.7835
Averaged Test AUC (Personalized): 0.7151
Std Test Accuracy (Personalized): 0.0518
Std Test AUC (Personalized): 0.0680

Evaluate global model (Reference only)
Averaged Train Loss: 0.4747
Averaged Test Accuracy: 0.7700
Averaged Test AUC: 0.7321
Averaged Test Precision: 0.7826
Averaged Test Recall: 0.7700
Averaged Test F1-Score: 0.7094
Std Test Accuracy: 0.0695
Std Test AUC: 0.0682
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 75 time cost: 4.33s
------------------------------------------------------------

[Phase 2 - Round 76] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 76 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4759
Averaged Test Accuracy (Personalized): 0.7833
Averaged Test AUC (Personalized): 0.7184
Std Test Accuracy (Personalized): 0.0537
Std Test AUC (Personalized): 0.0687

Evaluate global model (Reference only)
Averaged Train Loss: 0.4748
Averaged Test Accuracy: 0.7676
Averaged Test AUC: 0.7315
Averaged Test Precision: 0.7780
Averaged Test Recall: 0.7676
Averaged Test F1-Score: 0.7060
Std Test Accuracy: 0.0703
Std Test AUC: 0.0690
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 76 time cost: 4.47s
------------------------------------------------------------

[Phase 2 - Round 77] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 77 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4754
Averaged Test Accuracy (Personalized): 0.7823
Averaged Test AUC (Personalized): 0.7196
Std Test Accuracy (Personalized): 0.0545
Std Test AUC (Personalized): 0.0659

Evaluate global model (Reference only)
Averaged Train Loss: 0.4736
Averaged Test Accuracy: 0.7703
Averaged Test AUC: 0.7328
Averaged Test Precision: 0.7800
Averaged Test Recall: 0.7703
Averaged Test F1-Score: 0.7097
Std Test Accuracy: 0.0680
Std Test AUC: 0.0675
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 77 time cost: 4.45s
------------------------------------------------------------

[Phase 2 - Round 78] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 78 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4750
Averaged Test Accuracy (Personalized): 0.7840
Averaged Test AUC (Personalized): 0.7181
Std Test Accuracy (Personalized): 0.0510
Std Test AUC (Personalized): 0.0683

Evaluate global model (Reference only)
Averaged Train Loss: 0.4721
Averaged Test Accuracy: 0.7729
Averaged Test AUC: 0.7326
Averaged Test Precision: 0.7791
Averaged Test Recall: 0.7729
Averaged Test F1-Score: 0.7143
Std Test Accuracy: 0.0654
Std Test AUC: 0.0677
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 78 time cost: 4.46s
------------------------------------------------------------

[Phase 2 - Round 79] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 79 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4749
Averaged Test Accuracy (Personalized): 0.7831
Averaged Test AUC (Personalized): 0.7180
Std Test Accuracy (Personalized): 0.0529
Std Test AUC (Personalized): 0.0679

Evaluate global model (Reference only)
Averaged Train Loss: 0.4712
Averaged Test Accuracy: 0.7715
Averaged Test AUC: 0.7342
Averaged Test Precision: 0.7806
Averaged Test Recall: 0.7715
Averaged Test F1-Score: 0.7118
Std Test Accuracy: 0.0660
Std Test AUC: 0.0673
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 79 time cost: 4.46s
------------------------------------------------------------

[Phase 2 - Round 80] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 80 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4739
Averaged Test Accuracy (Personalized): 0.7839
Averaged Test AUC (Personalized): 0.7190
Std Test Accuracy (Personalized): 0.0520
Std Test AUC (Personalized): 0.0686

Evaluate global model (Reference only)
Averaged Train Loss: 0.4697
Averaged Test Accuracy: 0.7733
Averaged Test AUC: 0.7348
Averaged Test Precision: 0.7816
Averaged Test Recall: 0.7733
Averaged Test F1-Score: 0.7182
Std Test Accuracy: 0.0655
Std Test AUC: 0.0672
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 80 time cost: 4.19s
------------------------------------------------------------

============================================================
Phase 2 completed: 50/50 rounds
============================================================


============================================================
Final Evaluation - Round 81 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4741
Averaged Test Accuracy (Personalized): 0.7839
Averaged Test AUC (Personalized): 0.7190
Std Test Accuracy (Personalized): 0.0520
Std Test AUC (Personalized): 0.0686

Evaluate global model (Reference)
Averaged Train Loss: 0.4704
Averaged Test Accuracy: 0.7733
Averaged Test AUC: 0.7348
Averaged Test Precision: 0.7816
Averaged Test Recall: 0.7733
Averaged Test F1-Score: 0.7182
Std Test Accuracy: 0.0655
Std Test AUC: 0.0672

Best accuracy:
0.8017333333333333

Average time cost:
4.694329085946083

[FedGpro] Saving results...
  rs_test_acc entries: 82
  rs_test_auc entries: 82
  rs_train_loss entries: 82
  Saving to: system\results\Uci_FedGpro_Ablation_No_VAE_Generation_feature\Uci_FedGpro_Ablation_No_VAE_Generation_feature_0.h5
  [+] Saved h5 file successfully
  Saving CSV to: system\results\Uci_FedGpro_Ablation_No_VAE_Generation_feature\Uci_FedGpro_Ablation_No_VAE_Generation_feature_0_training_process.csv
  [+] Saved CSV file successfully
  [+] Saved npy files successfully

============= Running time: 1th =============
Creating server and clients ...
Auto-selected UciCreditNet for dataset Uci
UciCreditNet(
  (layers): Sequential(
    (0): Linear(in_features=23, out_features=32, bias=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.4, inplace=False)
    (4): Linear(in_features=32, out_features=16, bias=True)
    (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.2, inplace=False)
  )
  (fc): Linear(in_features=16, out_features=2, bias=True)
)
  Client 0: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 1: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 2: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 3: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 4: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 5: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 6: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 7: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 8: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 9: Personalization enabled (mu=0.0, plocal_epochs=1)

============================================================
FedGpro: Federated Global Prototype Learning
============================================================
Join ratio / total clients: 1.0 / 10

Phase 1 Parameters (Max 20 rounds):
  Minimum threshold: 0.6
  Threshold formula:
    ACC(t-1) = (best_acc(t-1) + avg_acc(t-1)) / 2
    threshold(r) = ACC(t-1),                                       if r <= 9
    threshold(r) = max(0.66, ACC(t-1)*(1-0.05*floor((r-10)/5))), if r >= 10
  Training stages:
    - Round 1-10: Forced training (no early stop check, ensure VAE quality)
    - Round 11+: Early stop check + dynamic threshold with time decay
  Phase transition: 70% clients qualified OR 25 rounds reached

Phase 2 Parameters:
  Aggregation: fedavg
  Supported algorithms: fedavg, fedprox, fedscaffold
============================================================

Finished creating server and clients.

[Phase 1] Statistical Collection (Round 0)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.6600
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7805
  Client 0 meets threshold! Generating virtual data...
  Client 0: Privacy disabled, skipping baseline VAE training.
  Client 0: Skipped virtual data generation (ratio=1.0)
  Client 0: No noise added (privacy disabled).
  Client 9 meets threshold! Generating virtual data...
  Client 9: Privacy disabled, skipping baseline VAE training.
  Client 9: Skipped virtual data generation (ratio=1.0)
  Client 9: No noise added (privacy disabled).
  Client 6 meets threshold! Generating virtual data...
  Client 6: Privacy disabled, skipping baseline VAE training.
  Client 6: Skipped virtual data generation (ratio=1.0)
  Client 6: No noise added (privacy disabled).
  Client 4 meets threshold! Generating virtual data...
  Client 4: Privacy disabled, skipping baseline VAE training.
  Client 4: Skipped virtual data generation (ratio=1.0)
  Client 4: No noise added (privacy disabled).
  Client 3 meets threshold! Generating virtual data...
  Client 3: Privacy disabled, skipping baseline VAE training.
  Client 3: Skipped virtual data generation (ratio=1.0)
  Client 3: No noise added (privacy disabled).
  Client 8 meets threshold! Generating virtual data...
  Client 8: Privacy disabled, skipping baseline VAE training.
  Client 8: Skipped virtual data generation (ratio=1.0)
  Client 8: No noise added (privacy disabled).
  Client 7 meets threshold! Generating virtual data...
  Client 7: Privacy disabled, skipping baseline VAE training.
  Client 7: Skipped virtual data generation (ratio=1.0)
  Client 7: No noise added (privacy disabled).
  Client 2 meets threshold! Generating virtual data...
  Client 2: Privacy disabled, skipping baseline VAE training.
  Client 2: Skipped virtual data generation (ratio=1.0)
  Client 2: No noise added (privacy disabled).
  Client 1 meets threshold! Generating virtual data...
  Client 1: Privacy disabled, skipping baseline VAE training.
  Client 1: Skipped virtual data generation (ratio=1.0)
  Client 1: No noise added (privacy disabled).
  Client 5 meets threshold! Generating virtual data...
  Client 5: Privacy disabled, skipping baseline VAE training.
  Client 5: Skipped virtual data generation (ratio=1.0)
  Client 5: No noise added (privacy disabled).
  Newly qualified clients: [0, 9, 6, 4, 3, 8, 7, 2, 1, 5]
  Total qualified clients: 10/10
  Virtual data pool size: 0

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 0):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 1: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 0 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4895
Averaged Test Accuracy: 0.7805
Averaged Test AUC: 0.6925
Averaged Test Precision: 0.7579
Averaged Test Recall: 0.7805
Averaged Test F1-Score: 0.7280
Std Test Accuracy: 0.0504
Std Test AUC: 0.0777
------------------------------------------------------------
Round 0 time cost: 4.41s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 1)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8129
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7880

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 2: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 1 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4700
Averaged Test Accuracy: 0.7880
Averaged Test AUC: 0.7175
Averaged Test Precision: 0.7840
Averaged Test Recall: 0.7880
Averaged Test F1-Score: 0.7374
Std Test Accuracy: 0.0466
Std Test AUC: 0.0783
------------------------------------------------------------
Round 1 time cost: 4.33s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 2)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8160
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7899

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 3: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 2 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4639
Averaged Test Accuracy: 0.7899
Averaged Test AUC: 0.7239
Averaged Test Precision: 0.7863
Averaged Test Recall: 0.7899
Averaged Test F1-Score: 0.7424
Std Test Accuracy: 0.0451
Std Test AUC: 0.0751
------------------------------------------------------------
Round 2 time cost: 4.42s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 3)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8176
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.7904

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 4: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 3 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4595
Averaged Test Accuracy: 0.7904
Averaged Test AUC: 0.7283
Averaged Test Precision: 0.7892
Averaged Test Recall: 0.7904
Averaged Test F1-Score: 0.7452
Std Test Accuracy: 0.0459
Std Test AUC: 0.0726
------------------------------------------------------------
Round 3 time cost: 4.42s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 4)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8205
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7916

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 5: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 4 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4558
Averaged Test Accuracy: 0.7916
Averaged Test AUC: 0.7320
Averaged Test Precision: 0.7888
Averaged Test Recall: 0.7916
Averaged Test F1-Score: 0.7477
Std Test Accuracy: 0.0486
Std Test AUC: 0.0709
------------------------------------------------------------
Round 4 time cost: 4.03s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8185
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.7953

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 5):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 6: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 5 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4523
Averaged Test Accuracy: 0.7953
Averaged Test AUC: 0.7363
Averaged Test Precision: 0.7910
Averaged Test Recall: 0.7953
Averaged Test F1-Score: 0.7554
Std Test Accuracy: 0.0462
Std Test AUC: 0.0680
------------------------------------------------------------
Round 5 time cost: 4.49s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 6)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8223
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.7939

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 7: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 6 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4501
Averaged Test Accuracy: 0.7939
Averaged Test AUC: 0.7382
Averaged Test Precision: 0.7876
Averaged Test Recall: 0.7939
Averaged Test F1-Score: 0.7544
Std Test Accuracy: 0.0464
Std Test AUC: 0.0669
------------------------------------------------------------
Round 6 time cost: 4.50s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 7)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8216
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.7943

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 8: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 7 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4486
Averaged Test Accuracy: 0.7943
Averaged Test AUC: 0.7396
Averaged Test Precision: 0.7864
Averaged Test Recall: 0.7943
Averaged Test F1-Score: 0.7568
Std Test Accuracy: 0.0466
Std Test AUC: 0.0655
------------------------------------------------------------
Round 7 time cost: 4.08s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 8)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8218
  Best client accuracy (ACC(t)): 0.8480
  Global average accuracy (ACC(t)): 0.7964

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 9: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 8 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4465
Averaged Test Accuracy: 0.7964
Averaged Test AUC: 0.7418
Averaged Test Precision: 0.7876
Averaged Test Recall: 0.7964
Averaged Test F1-Score: 0.7618
Std Test Accuracy: 0.0474
Std Test AUC: 0.0651
------------------------------------------------------------
Round 8 time cost: 4.46s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 9)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8222
  Best client accuracy (ACC(t)): 0.8480
  Global average accuracy (ACC(t)): 0.7963

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 10: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 9 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4454
Averaged Test Accuracy: 0.7963
Averaged Test AUC: 0.7431
Averaged Test Precision: 0.7917
Averaged Test Recall: 0.7963
Averaged Test F1-Score: 0.7588
Std Test Accuracy: 0.0451
Std Test AUC: 0.0640
------------------------------------------------------------
Round 9 time cost: 4.54s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 10)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 11: ˥�� 0% (��0��)
    Base: 0.8221 �� Decayed: 0.8221 �� Final: 0.8221
  Current threshold (based on ACC(t-1)): 0.8221
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.7969

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 10):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 11: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 10 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4439
Averaged Test Accuracy: 0.7969
Averaged Test AUC: 0.7429
Averaged Test Precision: 0.7881
Averaged Test Recall: 0.7969
Averaged Test F1-Score: 0.7614
Std Test Accuracy: 0.0455
Std Test AUC: 0.0647
------------------------------------------------------------
Round 10 time cost: 4.13s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 11)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8231
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.7995

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 12: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 11 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4430
Averaged Test Accuracy: 0.7995
Averaged Test AUC: 0.7461
Averaged Test Precision: 0.7925
Averaged Test Recall: 0.7995
Averaged Test F1-Score: 0.7662
Std Test Accuracy: 0.0457
Std Test AUC: 0.0629
------------------------------------------------------------
Round 11 time cost: 4.49s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 12)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8251
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8011

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 13: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 12 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4407
Averaged Test Accuracy: 0.8011
Averaged Test AUC: 0.7454
Averaged Test Precision: 0.7925
Averaged Test Recall: 0.8011
Averaged Test F1-Score: 0.7706
Std Test Accuracy: 0.0449
Std Test AUC: 0.0632
------------------------------------------------------------
Round 12 time cost: 4.42s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 13)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8265
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7995

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 14: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 13 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4410
Averaged Test Accuracy: 0.7995
Averaged Test AUC: 0.7456
Averaged Test Precision: 0.7927
Averaged Test Recall: 0.7995
Averaged Test F1-Score: 0.7656
Std Test Accuracy: 0.0435
Std Test AUC: 0.0624
------------------------------------------------------------
Round 13 time cost: 4.36s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 14)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8231
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8000

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 15: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 14 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4402
Averaged Test Accuracy: 0.8000
Averaged Test AUC: 0.7458
Averaged Test Precision: 0.7910
Averaged Test Recall: 0.8000
Averaged Test F1-Score: 0.7682
Std Test Accuracy: 0.0443
Std Test AUC: 0.0631
------------------------------------------------------------
Round 14 time cost: 4.62s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 15)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 16: ˥�� 5% (��1��)
    Base: 0.8253 �� Decayed: 0.7841 �� Final: 0.7841
  Current threshold (based on ACC(t-1)): 0.7841
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.8004

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 15):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 16: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 15 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4400
Averaged Test Accuracy: 0.8004
Averaged Test AUC: 0.7452
Averaged Test Precision: 0.7916
Averaged Test Recall: 0.8004
Averaged Test F1-Score: 0.7678
Std Test Accuracy: 0.0437
Std Test AUC: 0.0643
------------------------------------------------------------
Round 15 time cost: 4.16s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 16)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7824
  Best client accuracy (ACC(t)): 0.8573
  Global average accuracy (ACC(t)): 0.8021

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 17: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 16 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4388
Averaged Test Accuracy: 0.8021
Averaged Test AUC: 0.7474
Averaged Test Precision: 0.7970
Averaged Test Recall: 0.8021
Averaged Test F1-Score: 0.7711
Std Test Accuracy: 0.0460
Std Test AUC: 0.0639
------------------------------------------------------------
Round 16 time cost: 4.27s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 17)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7882
  Best client accuracy (ACC(t)): 0.8480
  Global average accuracy (ACC(t)): 0.8021

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 18: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 17 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4382
Averaged Test Accuracy: 0.8021
Averaged Test AUC: 0.7491
Averaged Test Precision: 0.7933
Averaged Test Recall: 0.8021
Averaged Test F1-Score: 0.7716
Std Test Accuracy: 0.0455
Std Test AUC: 0.0614
------------------------------------------------------------
Round 17 time cost: 4.83s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 18)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7838
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8009

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 19: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 18 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4365
Averaged Test Accuracy: 0.8009
Averaged Test AUC: 0.7496
Averaged Test Precision: 0.7924
Averaged Test Recall: 0.8009
Averaged Test F1-Score: 0.7724
Std Test Accuracy: 0.0484
Std Test AUC: 0.0616
------------------------------------------------------------
Round 18 time cost: 4.55s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 19)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7851
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8021

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 20: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 19 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4364
Averaged Test Accuracy: 0.8021
Averaged Test AUC: 0.7502
Averaged Test Precision: 0.7935
Averaged Test Recall: 0.8021
Averaged Test F1-Score: 0.7730
Std Test Accuracy: 0.0467
Std Test AUC: 0.0605
------------------------------------------------------------
Round 19 time cost: 4.25s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 20)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 21: ˥�� 10% (��2��)
    Base: 0.8257 �� Decayed: 0.7432 �� Final: 0.7432
  Current threshold (based on ACC(t-1)): 0.7432
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8023

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 20):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 21: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 20 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4362
Averaged Test Accuracy: 0.8023
Averaged Test AUC: 0.7512
Averaged Test Precision: 0.7938
Averaged Test Recall: 0.8023
Averaged Test F1-Score: 0.7736
Std Test Accuracy: 0.0458
Std Test AUC: 0.0598
------------------------------------------------------------
Round 20 time cost: 4.44s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 21)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7444
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8019

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 22: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 21 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4350
Averaged Test Accuracy: 0.8019
Averaged Test AUC: 0.7527
Averaged Test Precision: 0.7966
Averaged Test Recall: 0.8019
Averaged Test F1-Score: 0.7725
Std Test Accuracy: 0.0473
Std Test AUC: 0.0576
------------------------------------------------------------
Round 21 time cost: 4.32s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 22)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7430
  Best client accuracy (ACC(t)): 0.8547
  Global average accuracy (ACC(t)): 0.8037

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 23: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 22 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4342
Averaged Test Accuracy: 0.8037
Averaged Test AUC: 0.7517
Averaged Test Precision: 0.7949
Averaged Test Recall: 0.8037
Averaged Test F1-Score: 0.7775
Std Test Accuracy: 0.0486
Std Test AUC: 0.0591
------------------------------------------------------------
Round 22 time cost: 4.52s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 23)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7463
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8027

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 24: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 23 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4346
Averaged Test Accuracy: 0.8027
Averaged Test AUC: 0.7543
Averaged Test Precision: 0.7940
Averaged Test Recall: 0.8027
Averaged Test F1-Score: 0.7754
Std Test Accuracy: 0.0472
Std Test AUC: 0.0575
------------------------------------------------------------
Round 23 time cost: 4.44s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 24)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7440
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8021

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 25: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 24 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4333
Averaged Test Accuracy: 0.8021
Averaged Test AUC: 0.7539
Averaged Test Precision: 0.7930
Averaged Test Recall: 0.8021
Averaged Test F1-Score: 0.7742
Std Test Accuracy: 0.0461
Std Test AUC: 0.0571
------------------------------------------------------------
Round 24 time cost: 4.24s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 25)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 26: ˥�� 15% (��3��)
    Base: 0.8271 �� Decayed: 0.7030 �� Final: 0.7030
  Current threshold (based on ACC(t-1)): 0.7030
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8035

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 25):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 26: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 25 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4329
Averaged Test Accuracy: 0.8035
Averaged Test AUC: 0.7528
Averaged Test Precision: 0.7940
Averaged Test Recall: 0.8035
Averaged Test F1-Score: 0.7766
Std Test Accuracy: 0.0479
Std Test AUC: 0.0581
------------------------------------------------------------
Round 25 time cost: 4.43s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 26)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7024
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8039

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 27: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 26 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4322
Averaged Test Accuracy: 0.8039
Averaged Test AUC: 0.7533
Averaged Test Precision: 0.7962
Averaged Test Recall: 0.8039
Averaged Test F1-Score: 0.7771
Std Test Accuracy: 0.0482
Std Test AUC: 0.0582
------------------------------------------------------------
Round 26 time cost: 4.51s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 27)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7037
  Best client accuracy (ACC(t)): 0.8533
  Global average accuracy (ACC(t)): 0.8036

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 28: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 27 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4317
Averaged Test Accuracy: 0.8036
Averaged Test AUC: 0.7526
Averaged Test Precision: 0.7943
Averaged Test Recall: 0.8036
Averaged Test F1-Score: 0.7771
Std Test Accuracy: 0.0474
Std Test AUC: 0.0596
------------------------------------------------------------
Round 27 time cost: 4.43s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 28)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7042
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8031

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 29: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 28 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4317
Averaged Test Accuracy: 0.8031
Averaged Test AUC: 0.7526
Averaged Test Precision: 0.7958
Averaged Test Recall: 0.8031
Averaged Test F1-Score: 0.7761
Std Test Accuracy: 0.0475
Std Test AUC: 0.0599
------------------------------------------------------------
Round 28 time cost: 4.41s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 29)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7034
  Best client accuracy (ACC(t)): 0.8533
  Global average accuracy (ACC(t)): 0.8037

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 30: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 29 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4304
Averaged Test Accuracy: 0.8037
Averaged Test AUC: 0.7545
Averaged Test Precision: 0.7966
Averaged Test Recall: 0.8037
Averaged Test F1-Score: 0.7762
Std Test Accuracy: 0.0477
Std Test AUC: 0.0585
------------------------------------------------------------
Round 29 time cost: 4.29s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 30)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 4] ��ͣ��� (��ǰ׼ȷ��: 0.8387)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6834
       ��29��: 0.8320 >= 0.6834 [+]
       ��30��: 0.8347 >= 0.6834 [+]
       ��31��: 0.8387 >= 0.6834 [+]
    [+] ����(3): �������ȶ� (0.0067 <= 0.0200)
       ���3��: ['0.8320', '0.8347', '0.8387']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 4 reached early stopping criteria (Round 31):
    - Accuracy: 0.8387 (threshold: 0.7034)
    - Fluctuation: 0.0067 (last 3 rounds)
    - History: ['0.832', '0.835', '0.839']
  [Virtual Data] Generating and locking virtual data for client 4...
  [Mentor Mode] Client 4 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 4 early stopped at round 30
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 6] ��ͣ��� (��ǰ׼ȷ��: 0.8520)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6834
       ��29��: 0.8520 >= 0.6834 [+]
       ��30��: 0.8533 >= 0.6834 [+]
       ��31��: 0.8520 >= 0.6834 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.8520', '0.8533', '0.8520']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 6 reached early stopping criteria (Round 31):
    - Accuracy: 0.8520 (threshold: 0.7034)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.852', '0.853', '0.852']
  [Virtual Data] Generating and locking virtual data for client 6...
  [Mentor Mode] Client 6 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 6 early stopped at round 30
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 8] ��ͣ��� (��ǰ׼ȷ��: 0.7987)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6834
       ��29��: 0.8000 >= 0.6834 [+]
       ��30��: 0.7987 >= 0.6834 [+]
       ��31��: 0.7987 >= 0.6834 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.8000', '0.7987', '0.7987']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 8 reached early stopping criteria (Round 31):
    - Accuracy: 0.7987 (threshold: 0.7034)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.800', '0.799', '0.799']
  [Virtual Data] Generating and locking virtual data for client 8...
  [Mentor Mode] Client 8 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 8 early stopped at round 30
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 1] ��ͣ��� (��ǰ׼ȷ��: 0.8493)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6834
       ��29��: 0.8413 >= 0.6834 [+]
       ��30��: 0.8440 >= 0.6834 [+]
       ��31��: 0.8493 >= 0.6834 [+]
    [+] ����(3): �������ȶ� (0.0080 <= 0.0200)
       ���3��: ['0.8413', '0.8440', '0.8493']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 1 reached early stopping criteria (Round 31):
    - Accuracy: 0.8493 (threshold: 0.7034)
    - Fluctuation: 0.0080 (last 3 rounds)
    - History: ['0.841', '0.844', '0.849']
  [Virtual Data] Generating and locking virtual data for client 1...
  [Mentor Mode] Client 1 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 1 early stopped at round 30
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 7] ��ͣ��� (��ǰ׼ȷ��: 0.7307)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6834
       ��29��: 0.7307 >= 0.6834 [+]
       ��30��: 0.7333 >= 0.6834 [+]
       ��31��: 0.7307 >= 0.6834 [+]
    [+] ����(3): �������ȶ� (0.0027 <= 0.0200)
       ���3��: ['0.7307', '0.7333', '0.7307']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 7 reached early stopping criteria (Round 31):
    - Accuracy: 0.7307 (threshold: 0.7034)
    - Fluctuation: 0.0027 (last 3 rounds)
    - History: ['0.731', '0.733', '0.731']
  [Virtual Data] Generating and locking virtual data for client 7...
  [Mentor Mode] Client 7 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 7 early stopped at round 30
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 3] ��ͣ��� (��ǰ׼ȷ��: 0.7800)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6834
       ��29��: 0.7787 >= 0.6834 [+]
       ��30��: 0.7773 >= 0.6834 [+]
       ��31��: 0.7800 >= 0.6834 [+]
    [+] ����(3): �������ȶ� (0.0027 <= 0.0200)
       ���3��: ['0.7787', '0.7773', '0.7800']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 3 reached early stopping criteria (Round 31):
    - Accuracy: 0.7800 (threshold: 0.7034)
    - Fluctuation: 0.0027 (last 3 rounds)
    - History: ['0.779', '0.777', '0.780']
  [Virtual Data] Generating and locking virtual data for client 3...
  [Mentor Mode] Client 3 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 3 early stopped at round 30
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 9] ��ͣ��� (��ǰ׼ȷ��: 0.8547)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6834
       ��29��: 0.8507 >= 0.6834 [+]
       ��30��: 0.8507 >= 0.6834 [+]
       ��31��: 0.8547 >= 0.6834 [+]
    [+] ����(3): �������ȶ� (0.0040 <= 0.0200)
       ���3��: ['0.8507', '0.8507', '0.8547']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 9 reached early stopping criteria (Round 31):
    - Accuracy: 0.8547 (threshold: 0.7034)
    - Fluctuation: 0.0040 (last 3 rounds)
    - History: ['0.851', '0.851', '0.855']
  [Virtual Data] Generating and locking virtual data for client 9...
  [Mentor Mode] Client 9 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 9 early stopped at round 30
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 5] ��ͣ��� (��ǰ׼ȷ��: 0.7160)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6834
       ��29��: 0.7173 >= 0.6834 [+]
       ��30��: 0.7173 >= 0.6834 [+]
       ��31��: 0.7160 >= 0.6834 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.7173', '0.7173', '0.7160']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 5 reached early stopping criteria (Round 31):
    - Accuracy: 0.7160 (threshold: 0.7034)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.717', '0.717', '0.716']
  [Virtual Data] Generating and locking virtual data for client 5...
  [Mentor Mode] Client 5 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 5 early stopped at round 30
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 0] ��ͣ��� (��ǰ׼ȷ��: 0.8453)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6834
       ��29��: 0.8467 >= 0.6834 [+]
       ��30��: 0.8467 >= 0.6834 [+]
       ��31��: 0.8453 >= 0.6834 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.8467', '0.8467', '0.8453']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 0 reached early stopping criteria (Round 31):
    - Accuracy: 0.8453 (threshold: 0.7034)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.847', '0.847', '0.845']
  [Virtual Data] Generating and locking virtual data for client 0...
  [Mentor Mode] Client 0 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 0 early stopped at round 30
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 2] ��ͣ��� (��ǰ׼ȷ��: 0.7827)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6834
       ��29��: 0.7813 >= 0.6834 [+]
       ��30��: 0.7813 >= 0.6834 [+]
       ��31��: 0.7827 >= 0.6834 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.7813', '0.7813', '0.7827']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 2 reached early stopping criteria (Round 31):
    - Accuracy: 0.7827 (threshold: 0.7034)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.781', '0.781', '0.783']
  [Virtual Data] Generating and locking virtual data for client 2...
  [Mentor Mode] Client 2 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 2 early stopped at round 30
  [Threshold Decay] Round 31: ˥�� 20% (��4��)
    Base: 0.8285 �� Decayed: 0.6628 �� Final: 0.6628
  Current threshold (based on ACC(t-1)): 0.6628
  Best client accuracy (ACC(t)): 0.8547
  Global average accuracy (ACC(t)): 0.8048

  [Adaptive Decay] Ȩ��˥���������� (Round 31):
  ��ǰȫ��׼ȷ��: 0.8048
  ˥��ǿ�Ȧ�: 0.5
    Client 4: ��31�ִ��
      ���ʱ׼ȷ��: 0.8048
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 6: ��31�ִ��
      ���ʱ׼ȷ��: 0.8048
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 8: ��31�ִ��
      ���ʱ׼ȷ��: 0.8048
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 1: ��31�ִ��
      ���ʱ׼ȷ��: 0.8048
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 7: ��31�ִ��
      ���ʱ׼ȷ��: 0.8048
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 3: ��31�ִ��
      ���ʱ׼ȷ��: 0.8048
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 9: ��31�ִ��
      ���ʱ׼ȷ��: 0.8048
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 5: ��31�ִ��
      ���ʱ׼ȷ��: 0.8048
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 0: ��31�ִ��
      ���ʱ׼ȷ��: 0.8048
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 2: ��31�ִ��
      ���ʱ׼ȷ��: 0.8048
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
  Early-stopped clients: 10/10
  Active training clients: 0

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 30):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 1   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 2   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 3   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 4   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 5   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 6   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 7   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 8   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 9   2250        1.0000        2250.00         0.1000          ��ͣ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  [Adaptive Decay] Prototype aggregation weights: C0=1.000 C1=1.000 C2=1.000 C3=1.000 C4=1.000 ... (10 total)
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

================================================================================
[Phase Transition Check] Round 31 (Phase 1: ���50��)
================================================================================
���Ҫ��: 7/10 �ͻ��� (70%)
��ǰ״̬: 10/10 �ͻ��˴��

�ͻ�����ϸ״̬:

[+] �Ѵ��ͻ��� (10��):
  Client 9: 0.8547 [+]
  Client 6: 0.8520 [+]
  Client 1: 0.8493 [+]
  Client 0: 0.8453 [+]
  Client 4: 0.8387 [+]
  Client 8: 0.7987 [+]
  Client 2: 0.7827 [+]
  Client 3: 0.7800 [+]
  Client 7: 0.7307 [+]
  Client 5: 0.7160 [+]

��ǰ��ֵ: 0.6628
ƽ��׼ȷ��: 0.8048
���׼ȷ��: 0.8547
================================================================================

[>>] Phase Transition Triggered! (70% Threshold Strategy)
   Qualified clients: 10/10
   Required: 7 (70%)
   Remaining: 0 clients will join dynamically in Phase 2
   Phase 1 completed: 31 rounds (min: 30, max: 50)
================================================================================


============================================================
PHASE TRANSITION: Phase 1 �� Phase 2
============================================================
Virtual data pool size: 0
Phase 2 Algorithm: FEDAVG
Phase 2 Max Rounds: 50
============================================================

  [Algorithm Name] Updated: FedGpro �� FedGpro-FedAvg
  Client 0: Phase 2 (already contributed virtual data)
  Client 1: Phase 2 (already contributed virtual data)
  Client 2: Phase 2 (already contributed virtual data)
  Client 3: Phase 2 (already contributed virtual data)
  Client 4: Phase 2 (already contributed virtual data)
  Client 5: Phase 2 (already contributed virtual data)
  Client 6: Phase 2 (already contributed virtual data)
  Client 7: Phase 2 (already contributed virtual data)
  Client 8: Phase 2 (already contributed virtual data)
  Client 9: Phase 2 (already contributed virtual data)
[OK] Phase 2 initialized successfully!
   Algorithm: FEDAVG
   All clients enter Phase 2: 10 (100%)
   - Already contributed virtual data: 10 (100%)
   - Can still contribute (until round 20): 0 (0%)
   Virtual data pool size: 0 samples
   Phase 1 will continue in parallel until round 20


============================================================
Round 30 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 5.6831
Averaged Test Accuracy (Personalized): 0.3271
Averaged Test AUC (Personalized): 0.6104
Std Test Accuracy (Personalized): 0.1058
Std Test AUC (Personalized): 0.0590

Evaluate global model (Reference only)
Averaged Train Loss: 0.4293
Averaged Test Accuracy: 0.8048
Averaged Test AUC: 0.7548
Averaged Test Precision: 0.7959
Averaged Test Recall: 0.8048
Averaged Test F1-Score: 0.7802
Std Test Accuracy: 0.0490
Std Test AUC: 0.0575
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 30 time cost: 4.73s
------------------------------------------------------------

[Phase 2 - Round 31] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 31 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 1.1151
Averaged Test Accuracy (Personalized): 0.5276
Averaged Test AUC (Personalized): 0.6379
Std Test Accuracy (Personalized): 0.0469
Std Test AUC (Personalized): 0.0680

Evaluate global model (Reference only)
Averaged Train Loss: 0.8814
Averaged Test Accuracy: 0.6165
Averaged Test AUC: 0.6430
Averaged Test Precision: 0.7161
Averaged Test Recall: 0.6165
Averaged Test F1-Score: 0.6437
Std Test Accuracy: 0.0418
Std Test AUC: 0.0678
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 31 time cost: 4.52s
------------------------------------------------------------

[Phase 2 - Round 32] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 32 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.7711
Averaged Test Accuracy (Personalized): 0.6633
Averaged Test AUC (Personalized): 0.6424
Std Test Accuracy (Personalized): 0.0281
Std Test AUC (Personalized): 0.0686

Evaluate global model (Reference only)
Averaged Train Loss: 0.5762
Averaged Test Accuracy: 0.7539
Averaged Test AUC: 0.6378
Averaged Test Precision: 0.7215
Averaged Test Recall: 0.7539
Averaged Test F1-Score: 0.7281
Std Test Accuracy: 0.0545
Std Test AUC: 0.0631
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 32 time cost: 4.20s
------------------------------------------------------------

[Phase 2 - Round 33] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 33 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.6277
Averaged Test Accuracy (Personalized): 0.7352
Averaged Test AUC (Personalized): 0.6392
Std Test Accuracy (Personalized): 0.0459
Std Test AUC (Personalized): 0.0733

Evaluate global model (Reference only)
Averaged Train Loss: 0.5461
Averaged Test Accuracy: 0.7655
Averaged Test AUC: 0.6381
Averaged Test Precision: 0.7299
Averaged Test Recall: 0.7655
Averaged Test F1-Score: 0.7138
Std Test Accuracy: 0.0638
Std Test AUC: 0.0694
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 33 time cost: 4.51s
------------------------------------------------------------

[Phase 2 - Round 34] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 34 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5760
Averaged Test Accuracy (Personalized): 0.7612
Averaged Test AUC (Personalized): 0.6396
Std Test Accuracy (Personalized): 0.0485
Std Test AUC (Personalized): 0.0727

Evaluate global model (Reference only)
Averaged Train Loss: 0.5395
Averaged Test Accuracy: 0.7631
Averaged Test AUC: 0.6448
Averaged Test Precision: 0.7402
Averaged Test Recall: 0.7631
Averaged Test F1-Score: 0.7032
Std Test Accuracy: 0.0691
Std Test AUC: 0.0701
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 34 time cost: 4.45s
------------------------------------------------------------

[Phase 2 - Round 35] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 35 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5547
Averaged Test Accuracy (Personalized): 0.7708
Averaged Test AUC (Personalized): 0.6394
Std Test Accuracy (Personalized): 0.0573
Std Test AUC (Personalized): 0.0721

Evaluate global model (Reference only)
Averaged Train Loss: 0.5332
Averaged Test Accuracy: 0.7620
Averaged Test AUC: 0.6525
Averaged Test Precision: 0.7385
Averaged Test Recall: 0.7620
Averaged Test F1-Score: 0.6991
Std Test Accuracy: 0.0698
Std Test AUC: 0.0716
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 35 time cost: 4.28s
------------------------------------------------------------

[Phase 2 - Round 36] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 36 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5456
Averaged Test Accuracy (Personalized): 0.7688
Averaged Test AUC (Personalized): 0.6401
Std Test Accuracy (Personalized): 0.0614
Std Test AUC (Personalized): 0.0712

Evaluate global model (Reference only)
Averaged Train Loss: 0.5268
Averaged Test Accuracy: 0.7604
Averaged Test AUC: 0.6580
Averaged Test Precision: 0.7388
Averaged Test Recall: 0.7604
Averaged Test F1-Score: 0.6950
Std Test Accuracy: 0.0713
Std Test AUC: 0.0724
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 36 time cost: 4.44s
------------------------------------------------------------

[Phase 2 - Round 37] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 37 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5414
Averaged Test Accuracy (Personalized): 0.7724
Averaged Test AUC (Personalized): 0.6401
Std Test Accuracy (Personalized): 0.0575
Std Test AUC (Personalized): 0.0747

Evaluate global model (Reference only)
Averaged Train Loss: 0.5210
Averaged Test Accuracy: 0.7608
Averaged Test AUC: 0.6658
Averaged Test Precision: 0.7413
Averaged Test Recall: 0.7608
Averaged Test F1-Score: 0.6955
Std Test Accuracy: 0.0710
Std Test AUC: 0.0730
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 37 time cost: 4.40s
------------------------------------------------------------

[Phase 2 - Round 38] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 38 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5391
Averaged Test Accuracy (Personalized): 0.7681
Averaged Test AUC (Personalized): 0.6398
Std Test Accuracy (Personalized): 0.0626
Std Test AUC (Personalized): 0.0722

Evaluate global model (Reference only)
Averaged Train Loss: 0.5176
Averaged Test Accuracy: 0.7616
Averaged Test AUC: 0.6693
Averaged Test Precision: 0.7324
Averaged Test Recall: 0.7616
Averaged Test F1-Score: 0.6953
Std Test Accuracy: 0.0689
Std Test AUC: 0.0736
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 38 time cost: 4.44s
------------------------------------------------------------

[Phase 2 - Round 39] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 39 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5378
Averaged Test Accuracy (Personalized): 0.7687
Averaged Test AUC (Personalized): 0.6404
Std Test Accuracy (Personalized): 0.0624
Std Test AUC (Personalized): 0.0734

Evaluate global model (Reference only)
Averaged Train Loss: 0.5152
Averaged Test Accuracy: 0.7601
Averaged Test AUC: 0.6732
Averaged Test Precision: 0.7352
Averaged Test Recall: 0.7601
Averaged Test F1-Score: 0.6930
Std Test Accuracy: 0.0706
Std Test AUC: 0.0728
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 39 time cost: 4.59s
------------------------------------------------------------

[Phase 2 - Round 40] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 40 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5362
Averaged Test Accuracy (Personalized): 0.7680
Averaged Test AUC (Personalized): 0.6434
Std Test Accuracy (Personalized): 0.0617
Std Test AUC (Personalized): 0.0746

Evaluate global model (Reference only)
Averaged Train Loss: 0.5133
Averaged Test Accuracy: 0.7604
Averaged Test AUC: 0.6767
Averaged Test Precision: 0.7369
Averaged Test Recall: 0.7604
Averaged Test F1-Score: 0.6932
Std Test Accuracy: 0.0714
Std Test AUC: 0.0747
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 40 time cost: 4.29s
------------------------------------------------------------

[Phase 2 - Round 41] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 41 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5313
Averaged Test Accuracy (Personalized): 0.7684
Averaged Test AUC (Personalized): 0.6465
Std Test Accuracy (Personalized): 0.0610
Std Test AUC (Personalized): 0.0754

Evaluate global model (Reference only)
Averaged Train Loss: 0.5102
Averaged Test Accuracy: 0.7609
Averaged Test AUC: 0.6802
Averaged Test Precision: 0.7434
Averaged Test Recall: 0.7609
Averaged Test F1-Score: 0.6934
Std Test Accuracy: 0.0702
Std Test AUC: 0.0741
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 41 time cost: 4.24s
------------------------------------------------------------

[Phase 2 - Round 42] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 42 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5269
Averaged Test Accuracy (Personalized): 0.7697
Averaged Test AUC (Personalized): 0.6494
Std Test Accuracy (Personalized): 0.0609
Std Test AUC (Personalized): 0.0763

Evaluate global model (Reference only)
Averaged Train Loss: 0.5094
Averaged Test Accuracy: 0.7627
Averaged Test AUC: 0.6836
Averaged Test Precision: 0.7504
Averaged Test Recall: 0.7627
Averaged Test F1-Score: 0.6948
Std Test Accuracy: 0.0693
Std Test AUC: 0.0753
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 42 time cost: 4.51s
------------------------------------------------------------

[Phase 2 - Round 43] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 43 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5250
Averaged Test Accuracy (Personalized): 0.7715
Averaged Test AUC (Personalized): 0.6544
Std Test Accuracy (Personalized): 0.0581
Std Test AUC (Personalized): 0.0761

Evaluate global model (Reference only)
Averaged Train Loss: 0.5078
Averaged Test Accuracy: 0.7601
Averaged Test AUC: 0.6866
Averaged Test Precision: 0.7504
Averaged Test Recall: 0.7601
Averaged Test F1-Score: 0.6907
Std Test Accuracy: 0.0726
Std Test AUC: 0.0759
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 43 time cost: 4.32s
------------------------------------------------------------

[Phase 2 - Round 44] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 44 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5218
Averaged Test Accuracy (Personalized): 0.7721
Averaged Test AUC (Personalized): 0.6543
Std Test Accuracy (Personalized): 0.0570
Std Test AUC (Personalized): 0.0771

Evaluate global model (Reference only)
Averaged Train Loss: 0.5064
Averaged Test Accuracy: 0.7620
Averaged Test AUC: 0.6896
Averaged Test Precision: 0.7432
Averaged Test Recall: 0.7620
Averaged Test F1-Score: 0.6933
Std Test Accuracy: 0.0706
Std Test AUC: 0.0772
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 44 time cost: 4.46s
------------------------------------------------------------

[Phase 2 - Round 45] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 45 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5196
Averaged Test Accuracy (Personalized): 0.7723
Averaged Test AUC (Personalized): 0.6577
Std Test Accuracy (Personalized): 0.0573
Std Test AUC (Personalized): 0.0768

Evaluate global model (Reference only)
Averaged Train Loss: 0.5040
Averaged Test Accuracy: 0.7616
Averaged Test AUC: 0.6925
Averaged Test Precision: 0.7502
Averaged Test Recall: 0.7616
Averaged Test F1-Score: 0.6923
Std Test Accuracy: 0.0705
Std Test AUC: 0.0768
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 45 time cost: 4.45s
------------------------------------------------------------

[Phase 2 - Round 46] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 46 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5196
Averaged Test Accuracy (Personalized): 0.7720
Averaged Test AUC (Personalized): 0.6567
Std Test Accuracy (Personalized): 0.0579
Std Test AUC (Personalized): 0.0773

Evaluate global model (Reference only)
Averaged Train Loss: 0.5031
Averaged Test Accuracy: 0.7637
Averaged Test AUC: 0.6937
Averaged Test Precision: 0.7545
Averaged Test Recall: 0.7637
Averaged Test F1-Score: 0.6971
Std Test Accuracy: 0.0683
Std Test AUC: 0.0771
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 46 time cost: 4.29s
------------------------------------------------------------

[Phase 2 - Round 47] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 47 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5157
Averaged Test Accuracy (Personalized): 0.7743
Averaged Test AUC (Personalized): 0.6623
Std Test Accuracy (Personalized): 0.0558
Std Test AUC (Personalized): 0.0777

Evaluate global model (Reference only)
Averaged Train Loss: 0.5020
Averaged Test Accuracy: 0.7640
Averaged Test AUC: 0.6964
Averaged Test Precision: 0.7611
Averaged Test Recall: 0.7640
Averaged Test F1-Score: 0.6971
Std Test Accuracy: 0.0691
Std Test AUC: 0.0772
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 47 time cost: 4.39s
------------------------------------------------------------

[Phase 2 - Round 48] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 48 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5152
Averaged Test Accuracy (Personalized): 0.7708
Averaged Test AUC (Personalized): 0.6627
Std Test Accuracy (Personalized): 0.0609
Std Test AUC (Personalized): 0.0783

Evaluate global model (Reference only)
Averaged Train Loss: 0.4998
Averaged Test Accuracy: 0.7669
Averaged Test AUC: 0.6989
Averaged Test Precision: 0.7620
Averaged Test Recall: 0.7669
Averaged Test F1-Score: 0.7032
Std Test Accuracy: 0.0660
Std Test AUC: 0.0783
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 48 time cost: 4.46s
------------------------------------------------------------

[Phase 2 - Round 49] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 49 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5138
Averaged Test Accuracy (Personalized): 0.7725
Averaged Test AUC (Personalized): 0.6639
Std Test Accuracy (Personalized): 0.0582
Std Test AUC (Personalized): 0.0798

Evaluate global model (Reference only)
Averaged Train Loss: 0.4990
Averaged Test Accuracy: 0.7655
Averaged Test AUC: 0.7010
Averaged Test Precision: 0.7631
Averaged Test Recall: 0.7655
Averaged Test F1-Score: 0.7004
Std Test Accuracy: 0.0667
Std Test AUC: 0.0775
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 49 time cost: 4.42s
------------------------------------------------------------

[Phase 2 - Round 50] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 50 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5106
Averaged Test Accuracy (Personalized): 0.7728
Averaged Test AUC (Personalized): 0.6673
Std Test Accuracy (Personalized): 0.0585
Std Test AUC (Personalized): 0.0784

Evaluate global model (Reference only)
Averaged Train Loss: 0.4979
Averaged Test Accuracy: 0.7669
Averaged Test AUC: 0.7014
Averaged Test Precision: 0.7603
Averaged Test Recall: 0.7669
Averaged Test F1-Score: 0.7034
Std Test Accuracy: 0.0652
Std Test AUC: 0.0774
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 50 time cost: 4.44s
------------------------------------------------------------

[Phase 2 - Round 51] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 51 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5096
Averaged Test Accuracy (Personalized): 0.7740
Averaged Test AUC (Personalized): 0.6693
Std Test Accuracy (Personalized): 0.0590
Std Test AUC (Personalized): 0.0771

Evaluate global model (Reference only)
Averaged Train Loss: 0.4960
Averaged Test Accuracy: 0.7693
Averaged Test AUC: 0.7053
Averaged Test Precision: 0.7593
Averaged Test Recall: 0.7693
Averaged Test F1-Score: 0.7082
Std Test Accuracy: 0.0644
Std Test AUC: 0.0782
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 51 time cost: 4.41s
------------------------------------------------------------

[Phase 2 - Round 52] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 52 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5078
Averaged Test Accuracy (Personalized): 0.7739
Averaged Test AUC (Personalized): 0.6692
Std Test Accuracy (Personalized): 0.0572
Std Test AUC (Personalized): 0.0783

Evaluate global model (Reference only)
Averaged Train Loss: 0.4943
Averaged Test Accuracy: 0.7735
Averaged Test AUC: 0.7050
Averaged Test Precision: 0.7654
Averaged Test Recall: 0.7735
Averaged Test F1-Score: 0.7135
Std Test Accuracy: 0.0588
Std Test AUC: 0.0778
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 52 time cost: 4.44s
------------------------------------------------------------

[Phase 2 - Round 53] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 53 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5053
Averaged Test Accuracy (Personalized): 0.7744
Averaged Test AUC (Personalized): 0.6725
Std Test Accuracy (Personalized): 0.0584
Std Test AUC (Personalized): 0.0798

Evaluate global model (Reference only)
Averaged Train Loss: 0.4917
Averaged Test Accuracy: 0.7751
Averaged Test AUC: 0.7073
Averaged Test Precision: 0.7561
Averaged Test Recall: 0.7751
Averaged Test F1-Score: 0.7188
Std Test Accuracy: 0.0555
Std Test AUC: 0.0768
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 53 time cost: 4.54s
------------------------------------------------------------

[Phase 2 - Round 54] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 54 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5052
Averaged Test Accuracy (Personalized): 0.7755
Averaged Test AUC (Personalized): 0.6726
Std Test Accuracy (Personalized): 0.0559
Std Test AUC (Personalized): 0.0783

Evaluate global model (Reference only)
Averaged Train Loss: 0.4902
Averaged Test Accuracy: 0.7760
Averaged Test AUC: 0.7104
Averaged Test Precision: 0.7671
Averaged Test Recall: 0.7760
Averaged Test F1-Score: 0.7182
Std Test Accuracy: 0.0546
Std Test AUC: 0.0772
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 54 time cost: 4.61s
------------------------------------------------------------

[Phase 2 - Round 55] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 55 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5036
Averaged Test Accuracy (Personalized): 0.7737
Averaged Test AUC (Personalized): 0.6737
Std Test Accuracy (Personalized): 0.0577
Std Test AUC (Personalized): 0.0784

Evaluate global model (Reference only)
Averaged Train Loss: 0.4888
Averaged Test Accuracy: 0.7784
Averaged Test AUC: 0.7101
Averaged Test Precision: 0.7639
Averaged Test Recall: 0.7784
Averaged Test F1-Score: 0.7228
Std Test Accuracy: 0.0524
Std Test AUC: 0.0771
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 55 time cost: 4.37s
------------------------------------------------------------

[Phase 2 - Round 56] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 56 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5019
Averaged Test Accuracy (Personalized): 0.7753
Averaged Test AUC (Personalized): 0.6764
Std Test Accuracy (Personalized): 0.0560
Std Test AUC (Personalized): 0.0794

Evaluate global model (Reference only)
Averaged Train Loss: 0.4876
Averaged Test Accuracy: 0.7784
Averaged Test AUC: 0.7117
Averaged Test Precision: 0.7604
Averaged Test Recall: 0.7784
Averaged Test F1-Score: 0.7221
Std Test Accuracy: 0.0521
Std Test AUC: 0.0775
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 56 time cost: 4.62s
------------------------------------------------------------

[Phase 2 - Round 57] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 57 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5016
Averaged Test Accuracy (Personalized): 0.7741
Averaged Test AUC (Personalized): 0.6771
Std Test Accuracy (Personalized): 0.0575
Std Test AUC (Personalized): 0.0774

Evaluate global model (Reference only)
Averaged Train Loss: 0.4865
Averaged Test Accuracy: 0.7815
Averaged Test AUC: 0.7125
Averaged Test Precision: 0.7650
Averaged Test Recall: 0.7815
Averaged Test F1-Score: 0.7258
Std Test Accuracy: 0.0497
Std Test AUC: 0.0770
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 57 time cost: 4.46s
------------------------------------------------------------

[Phase 2 - Round 58] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 58 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4998
Averaged Test Accuracy (Personalized): 0.7779
Averaged Test AUC (Personalized): 0.6796
Std Test Accuracy (Personalized): 0.0533
Std Test AUC (Personalized): 0.0781

Evaluate global model (Reference only)
Averaged Train Loss: 0.4848
Averaged Test Accuracy: 0.7827
Averaged Test AUC: 0.7146
Averaged Test Precision: 0.7666
Averaged Test Recall: 0.7827
Averaged Test F1-Score: 0.7278
Std Test Accuracy: 0.0488
Std Test AUC: 0.0763
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 58 time cost: 4.33s
------------------------------------------------------------

[Phase 2 - Round 59] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 59 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4986
Averaged Test Accuracy (Personalized): 0.7764
Averaged Test AUC (Personalized): 0.6795
Std Test Accuracy (Personalized): 0.0551
Std Test AUC (Personalized): 0.0780

Evaluate global model (Reference only)
Averaged Train Loss: 0.4842
Averaged Test Accuracy: 0.7844
Averaged Test AUC: 0.7157
Averaged Test Precision: 0.7662
Averaged Test Recall: 0.7844
Averaged Test F1-Score: 0.7299
Std Test Accuracy: 0.0462
Std Test AUC: 0.0765
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 59 time cost: 4.52s
------------------------------------------------------------

[Phase 2 - Round 60] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 60 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4971
Averaged Test Accuracy (Personalized): 0.7761
Averaged Test AUC (Personalized): 0.6817
Std Test Accuracy (Personalized): 0.0556
Std Test AUC (Personalized): 0.0780

Evaluate global model (Reference only)
Averaged Train Loss: 0.4833
Averaged Test Accuracy: 0.7829
Averaged Test AUC: 0.7162
Averaged Test Precision: 0.7776
Averaged Test Recall: 0.7829
Averaged Test F1-Score: 0.7268
Std Test Accuracy: 0.0489
Std Test AUC: 0.0764
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 60 time cost: 4.42s
------------------------------------------------------------

[Phase 2 - Round 61] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 61 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4979
Averaged Test Accuracy (Personalized): 0.7759
Averaged Test AUC (Personalized): 0.6812
Std Test Accuracy (Personalized): 0.0565
Std Test AUC (Personalized): 0.0782

Evaluate global model (Reference only)
Averaged Train Loss: 0.4828
Averaged Test Accuracy: 0.7853
Averaged Test AUC: 0.7171
Averaged Test Precision: 0.7558
Averaged Test Recall: 0.7853
Averaged Test F1-Score: 0.7309
Std Test Accuracy: 0.0446
Std Test AUC: 0.0758
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 61 time cost: 4.48s
------------------------------------------------------------

[Phase 2 - Round 62] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 62 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4952
Averaged Test Accuracy (Personalized): 0.7781
Averaged Test AUC (Personalized): 0.6856
Std Test Accuracy (Personalized): 0.0544
Std Test AUC (Personalized): 0.0788

Evaluate global model (Reference only)
Averaged Train Loss: 0.4825
Averaged Test Accuracy: 0.7860
Averaged Test AUC: 0.7190
Averaged Test Precision: 0.7813
Averaged Test Recall: 0.7860
Averaged Test F1-Score: 0.7325
Std Test Accuracy: 0.0448
Std Test AUC: 0.0769
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 62 time cost: 4.62s
------------------------------------------------------------

[Phase 2 - Round 63] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 63 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4945
Averaged Test Accuracy (Personalized): 0.7776
Averaged Test AUC (Personalized): 0.6860
Std Test Accuracy (Personalized): 0.0544
Std Test AUC (Personalized): 0.0795

Evaluate global model (Reference only)
Averaged Train Loss: 0.4822
Averaged Test Accuracy: 0.7843
Averaged Test AUC: 0.7180
Averaged Test Precision: 0.7684
Averaged Test Recall: 0.7843
Averaged Test F1-Score: 0.7297
Std Test Accuracy: 0.0465
Std Test AUC: 0.0752
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 63 time cost: 4.06s
------------------------------------------------------------

[Phase 2 - Round 64] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 64 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4934
Averaged Test Accuracy (Personalized): 0.7789
Averaged Test AUC (Personalized): 0.6862
Std Test Accuracy (Personalized): 0.0537
Std Test AUC (Personalized): 0.0778

Evaluate global model (Reference only)
Averaged Train Loss: 0.4813
Averaged Test Accuracy: 0.7851
Averaged Test AUC: 0.7194
Averaged Test Precision: 0.7759
Averaged Test Recall: 0.7851
Averaged Test F1-Score: 0.7307
Std Test Accuracy: 0.0443
Std Test AUC: 0.0753
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 64 time cost: 4.49s
------------------------------------------------------------

[Phase 2 - Round 65] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 65 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4936
Averaged Test Accuracy (Personalized): 0.7792
Averaged Test AUC (Personalized): 0.6865
Std Test Accuracy (Personalized): 0.0521
Std Test AUC (Personalized): 0.0793

Evaluate global model (Reference only)
Averaged Train Loss: 0.4816
Averaged Test Accuracy: 0.7852
Averaged Test AUC: 0.7207
Averaged Test Precision: 0.7621
Averaged Test Recall: 0.7852
Averaged Test F1-Score: 0.7296
Std Test Accuracy: 0.0468
Std Test AUC: 0.0756
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 65 time cost: 4.52s
------------------------------------------------------------

[Phase 2 - Round 66] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 66 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4931
Averaged Test Accuracy (Personalized): 0.7784
Averaged Test AUC (Personalized): 0.6886
Std Test Accuracy (Personalized): 0.0535
Std Test AUC (Personalized): 0.0787

Evaluate global model (Reference only)
Averaged Train Loss: 0.4816
Averaged Test Accuracy: 0.7841
Averaged Test AUC: 0.7216
Averaged Test Precision: 0.7590
Averaged Test Recall: 0.7841
Averaged Test F1-Score: 0.7290
Std Test Accuracy: 0.0460
Std Test AUC: 0.0754
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 66 time cost: 4.39s
------------------------------------------------------------

[Phase 2 - Round 67] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 67 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4910
Averaged Test Accuracy (Personalized): 0.7797
Averaged Test AUC (Personalized): 0.6914
Std Test Accuracy (Personalized): 0.0514
Std Test AUC (Personalized): 0.0770

Evaluate global model (Reference only)
Averaged Train Loss: 0.4799
Averaged Test Accuracy: 0.7856
Averaged Test AUC: 0.7210
Averaged Test Precision: 0.7780
Averaged Test Recall: 0.7856
Averaged Test F1-Score: 0.7308
Std Test Accuracy: 0.0448
Std Test AUC: 0.0750
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 67 time cost: 4.36s
------------------------------------------------------------

[Phase 2 - Round 68] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 68 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4902
Averaged Test Accuracy (Personalized): 0.7805
Averaged Test AUC (Personalized): 0.6925
Std Test Accuracy (Personalized): 0.0514
Std Test AUC (Personalized): 0.0782

Evaluate global model (Reference only)
Averaged Train Loss: 0.4805
Averaged Test Accuracy: 0.7851
Averaged Test AUC: 0.7213
Averaged Test Precision: 0.7689
Averaged Test Recall: 0.7851
Averaged Test F1-Score: 0.7300
Std Test Accuracy: 0.0451
Std Test AUC: 0.0754
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 68 time cost: 4.44s
------------------------------------------------------------

[Phase 2 - Round 69] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 69 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4890
Averaged Test Accuracy (Personalized): 0.7796
Averaged Test AUC (Personalized): 0.6922
Std Test Accuracy (Personalized): 0.0524
Std Test AUC (Personalized): 0.0784

Evaluate global model (Reference only)
Averaged Train Loss: 0.4797
Averaged Test Accuracy: 0.7839
Averaged Test AUC: 0.7220
Averaged Test Precision: 0.7766
Averaged Test Recall: 0.7839
Averaged Test F1-Score: 0.7286
Std Test Accuracy: 0.0468
Std Test AUC: 0.0750
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 69 time cost: 4.39s
------------------------------------------------------------

[Phase 2 - Round 70] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 70 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4884
Averaged Test Accuracy (Personalized): 0.7795
Averaged Test AUC (Personalized): 0.6938
Std Test Accuracy (Personalized): 0.0537
Std Test AUC (Personalized): 0.0786

Evaluate global model (Reference only)
Averaged Train Loss: 0.4793
Averaged Test Accuracy: 0.7853
Averaged Test AUC: 0.7230
Averaged Test Precision: 0.7603
Averaged Test Recall: 0.7853
Averaged Test F1-Score: 0.7294
Std Test Accuracy: 0.0457
Std Test AUC: 0.0751
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 70 time cost: 4.63s
------------------------------------------------------------

[Phase 2 - Round 71] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 71 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4875
Averaged Test Accuracy (Personalized): 0.7807
Averaged Test AUC (Personalized): 0.6951
Std Test Accuracy (Personalized): 0.0517
Std Test AUC (Personalized): 0.0776

Evaluate global model (Reference only)
Averaged Train Loss: 0.4792
Averaged Test Accuracy: 0.7860
Averaged Test AUC: 0.7243
Averaged Test Precision: 0.7576
Averaged Test Recall: 0.7860
Averaged Test F1-Score: 0.7309
Std Test Accuracy: 0.0457
Std Test AUC: 0.0752
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 71 time cost: 4.40s
------------------------------------------------------------

[Phase 2 - Round 72] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 72 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4872
Averaged Test Accuracy (Personalized): 0.7800
Averaged Test AUC (Personalized): 0.6961
Std Test Accuracy (Personalized): 0.0529
Std Test AUC (Personalized): 0.0782

Evaluate global model (Reference only)
Averaged Train Loss: 0.4789
Averaged Test Accuracy: 0.7840
Averaged Test AUC: 0.7245
Averaged Test Precision: 0.7617
Averaged Test Recall: 0.7840
Averaged Test F1-Score: 0.7285
Std Test Accuracy: 0.0457
Std Test AUC: 0.0752
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 72 time cost: 4.39s
------------------------------------------------------------

[Phase 2 - Round 73] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 73 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4860
Averaged Test Accuracy (Personalized): 0.7817
Averaged Test AUC (Personalized): 0.6953
Std Test Accuracy (Personalized): 0.0505
Std Test AUC (Personalized): 0.0765

Evaluate global model (Reference only)
Averaged Train Loss: 0.4786
Averaged Test Accuracy: 0.7851
Averaged Test AUC: 0.7243
Averaged Test Precision: 0.7773
Averaged Test Recall: 0.7851
Averaged Test F1-Score: 0.7307
Std Test Accuracy: 0.0456
Std Test AUC: 0.0755
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 73 time cost: 4.42s
------------------------------------------------------------

[Phase 2 - Round 74] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 74 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4858
Averaged Test Accuracy (Personalized): 0.7811
Averaged Test AUC (Personalized): 0.6979
Std Test Accuracy (Personalized): 0.0506
Std Test AUC (Personalized): 0.0766

Evaluate global model (Reference only)
Averaged Train Loss: 0.4782
Averaged Test Accuracy: 0.7841
Averaged Test AUC: 0.7238
Averaged Test Precision: 0.7591
Averaged Test Recall: 0.7841
Averaged Test F1-Score: 0.7294
Std Test Accuracy: 0.0457
Std Test AUC: 0.0748
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 74 time cost: 4.41s
------------------------------------------------------------

[Phase 2 - Round 75] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 75 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4842
Averaged Test Accuracy (Personalized): 0.7811
Averaged Test AUC (Personalized): 0.6971
Std Test Accuracy (Personalized): 0.0518
Std Test AUC (Personalized): 0.0780

Evaluate global model (Reference only)
Averaged Train Loss: 0.4774
Averaged Test Accuracy: 0.7864
Averaged Test AUC: 0.7258
Averaged Test Precision: 0.7852
Averaged Test Recall: 0.7864
Averaged Test F1-Score: 0.7328
Std Test Accuracy: 0.0448
Std Test AUC: 0.0750
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 75 time cost: 4.44s
------------------------------------------------------------

[Phase 2 - Round 76] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 76 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4842
Averaged Test Accuracy (Personalized): 0.7823
Averaged Test AUC (Personalized): 0.6994
Std Test Accuracy (Personalized): 0.0496
Std Test AUC (Personalized): 0.0782

Evaluate global model (Reference only)
Averaged Train Loss: 0.4770
Averaged Test Accuracy: 0.7873
Averaged Test AUC: 0.7265
Averaged Test Precision: 0.7618
Averaged Test Recall: 0.7873
Averaged Test F1-Score: 0.7340
Std Test Accuracy: 0.0430
Std Test AUC: 0.0756
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 76 time cost: 4.45s
------------------------------------------------------------

[Phase 2 - Round 77] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 77 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4847
Averaged Test Accuracy (Personalized): 0.7816
Averaged Test AUC (Personalized): 0.6976
Std Test Accuracy (Personalized): 0.0512
Std Test AUC (Personalized): 0.0776

Evaluate global model (Reference only)
Averaged Train Loss: 0.4769
Averaged Test Accuracy: 0.7855
Averaged Test AUC: 0.7265
Averaged Test Precision: 0.7782
Averaged Test Recall: 0.7855
Averaged Test F1-Score: 0.7319
Std Test Accuracy: 0.0450
Std Test AUC: 0.0759
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 77 time cost: 4.29s
------------------------------------------------------------

[Phase 2 - Round 78] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 78 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4845
Averaged Test Accuracy (Personalized): 0.7809
Averaged Test AUC (Personalized): 0.6995
Std Test Accuracy (Personalized): 0.0517
Std Test AUC (Personalized): 0.0780

Evaluate global model (Reference only)
Averaged Train Loss: 0.4766
Averaged Test Accuracy: 0.7849
Averaged Test AUC: 0.7265
Averaged Test Precision: 0.7841
Averaged Test Recall: 0.7849
Averaged Test F1-Score: 0.7313
Std Test Accuracy: 0.0444
Std Test AUC: 0.0746
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 78 time cost: 4.04s
------------------------------------------------------------

[Phase 2 - Round 79] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 79 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4825
Averaged Test Accuracy (Personalized): 0.7827
Averaged Test AUC (Personalized): 0.7009
Std Test Accuracy (Personalized): 0.0507
Std Test AUC (Personalized): 0.0781

Evaluate global model (Reference only)
Averaged Train Loss: 0.4768
Averaged Test Accuracy: 0.7833
Averaged Test AUC: 0.7273
Averaged Test Precision: 0.7585
Averaged Test Recall: 0.7833
Averaged Test F1-Score: 0.7283
Std Test Accuracy: 0.0464
Std Test AUC: 0.0751
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 79 time cost: 4.92s
------------------------------------------------------------

[Phase 2 - Round 80] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 80 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4827
Averaged Test Accuracy (Personalized): 0.7812
Averaged Test AUC (Personalized): 0.7012
Std Test Accuracy (Personalized): 0.0511
Std Test AUC (Personalized): 0.0774

Evaluate global model (Reference only)
Averaged Train Loss: 0.4766
Averaged Test Accuracy: 0.7840
Averaged Test AUC: 0.7257
Averaged Test Precision: 0.7775
Averaged Test Recall: 0.7840
Averaged Test F1-Score: 0.7303
Std Test Accuracy: 0.0456
Std Test AUC: 0.0754
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 80 time cost: 4.44s
------------------------------------------------------------

============================================================
Phase 2 completed: 50/50 rounds
============================================================


============================================================
Final Evaluation - Round 81 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4829
Averaged Test Accuracy (Personalized): 0.7812
Averaged Test AUC (Personalized): 0.7012
Std Test Accuracy (Personalized): 0.0511
Std Test AUC (Personalized): 0.0774

Evaluate global model (Reference)
Averaged Train Loss: 0.4772
Averaged Test Accuracy: 0.7840
Averaged Test AUC: 0.7257
Averaged Test Precision: 0.7775
Averaged Test Recall: 0.7840
Averaged Test F1-Score: 0.7303
Std Test Accuracy: 0.0456
Std Test AUC: 0.0754

Best accuracy:
0.8038666666666666

Average time cost:
4.41882132589817

[FedGpro] Saving results...
  rs_test_acc entries: 82
  rs_test_auc entries: 82
  rs_train_loss entries: 82
  Saving to: system\results\Uci_FedGpro_Ablation_No_VAE_Generation_feature\Uci_FedGpro_Ablation_No_VAE_Generation_feature_1.h5
  [+] Saved h5 file successfully
  Saving CSV to: system\results\Uci_FedGpro_Ablation_No_VAE_Generation_feature\Uci_FedGpro_Ablation_No_VAE_Generation_feature_1_training_process.csv
  [+] Saved CSV file successfully
  [+] Saved npy files successfully

============= Running time: 2th =============
Creating server and clients ...
Auto-selected UciCreditNet for dataset Uci
UciCreditNet(
  (layers): Sequential(
    (0): Linear(in_features=23, out_features=32, bias=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.4, inplace=False)
    (4): Linear(in_features=32, out_features=16, bias=True)
    (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.2, inplace=False)
  )
  (fc): Linear(in_features=16, out_features=2, bias=True)
)
  Client 0: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 1: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 2: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 3: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 4: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 5: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 6: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 7: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 8: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 9: Personalization enabled (mu=0.0, plocal_epochs=1)

============================================================
FedGpro: Federated Global Prototype Learning
============================================================
Join ratio / total clients: 1.0 / 10

Phase 1 Parameters (Max 20 rounds):
  Minimum threshold: 0.6
  Threshold formula:
    ACC(t-1) = (best_acc(t-1) + avg_acc(t-1)) / 2
    threshold(r) = ACC(t-1),                                       if r <= 9
    threshold(r) = max(0.66, ACC(t-1)*(1-0.05*floor((r-10)/5))), if r >= 10
  Training stages:
    - Round 1-10: Forced training (no early stop check, ensure VAE quality)
    - Round 11+: Early stop check + dynamic threshold with time decay
  Phase transition: 70% clients qualified OR 25 rounds reached

Phase 2 Parameters:
  Aggregation: fedavg
  Supported algorithms: fedavg, fedprox, fedscaffold
============================================================

Finished creating server and clients.

[Phase 1] Statistical Collection (Round 0)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.6600
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7813
  Client 8 meets threshold! Generating virtual data...
  Client 8: Privacy disabled, skipping baseline VAE training.
  Client 8: Skipped virtual data generation (ratio=1.0)
  Client 8: No noise added (privacy disabled).
  Client 1 meets threshold! Generating virtual data...
  Client 1: Privacy disabled, skipping baseline VAE training.
  Client 1: Skipped virtual data generation (ratio=1.0)
  Client 1: No noise added (privacy disabled).
  Client 5 meets threshold! Generating virtual data...
  Client 5: Privacy disabled, skipping baseline VAE training.
  Client 5: Skipped virtual data generation (ratio=1.0)
  Client 5: No noise added (privacy disabled).
  Client 6 meets threshold! Generating virtual data...
  Client 6: Privacy disabled, skipping baseline VAE training.
  Client 6: Skipped virtual data generation (ratio=1.0)
  Client 6: No noise added (privacy disabled).
  Client 0 meets threshold! Generating virtual data...
  Client 0: Privacy disabled, skipping baseline VAE training.
  Client 0: Skipped virtual data generation (ratio=1.0)
  Client 0: No noise added (privacy disabled).
  Client 3 meets threshold! Generating virtual data...
  Client 3: Privacy disabled, skipping baseline VAE training.
  Client 3: Skipped virtual data generation (ratio=1.0)
  Client 3: No noise added (privacy disabled).
  Client 4 meets threshold! Generating virtual data...
  Client 4: Privacy disabled, skipping baseline VAE training.
  Client 4: Skipped virtual data generation (ratio=1.0)
  Client 4: No noise added (privacy disabled).
  Client 9 meets threshold! Generating virtual data...
  Client 9: Privacy disabled, skipping baseline VAE training.
  Client 9: Skipped virtual data generation (ratio=1.0)
  Client 9: No noise added (privacy disabled).
  Client 7 meets threshold! Generating virtual data...
  Client 7: Privacy disabled, skipping baseline VAE training.
  Client 7: Skipped virtual data generation (ratio=1.0)
  Client 7: No noise added (privacy disabled).
  Client 2 meets threshold! Generating virtual data...
  Client 2: Privacy disabled, skipping baseline VAE training.
  Client 2: Skipped virtual data generation (ratio=1.0)
  Client 2: No noise added (privacy disabled).
  Newly qualified clients: [8, 1, 5, 6, 0, 3, 4, 9, 7, 2]
  Total qualified clients: 10/10
  Virtual data pool size: 0

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 0):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 1: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 0 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4900
Averaged Test Accuracy: 0.7813
Averaged Test AUC: 0.6926
Averaged Test Precision: 0.7563
Averaged Test Recall: 0.7813
Averaged Test F1-Score: 0.7293
Std Test Accuracy: 0.0501
Std Test AUC: 0.0753
------------------------------------------------------------
Round 0 time cost: 4.54s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 1)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8127
  Best client accuracy (ACC(t)): 0.8427
  Global average accuracy (ACC(t)): 0.7849

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 2: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 1 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4717
Averaged Test Accuracy: 0.7849
Averaged Test AUC: 0.7180
Averaged Test Precision: 0.7554
Averaged Test Recall: 0.7849
Averaged Test F1-Score: 0.7344
Std Test Accuracy: 0.0464
Std Test AUC: 0.0745
------------------------------------------------------------
Round 1 time cost: 4.73s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 2)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8138
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7883

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 3: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 2 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4638
Averaged Test Accuracy: 0.7883
Averaged Test AUC: 0.7261
Averaged Test Precision: 0.7682
Averaged Test Recall: 0.7883
Averaged Test F1-Score: 0.7387
Std Test Accuracy: 0.0472
Std Test AUC: 0.0730
------------------------------------------------------------
Round 2 time cost: 4.13s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 3)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8161
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7917

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 4: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 3 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4591
Averaged Test Accuracy: 0.7917
Averaged Test AUC: 0.7298
Averaged Test Precision: 0.7698
Averaged Test Recall: 0.7917
Averaged Test F1-Score: 0.7464
Std Test Accuracy: 0.0407
Std Test AUC: 0.0712
------------------------------------------------------------
Round 3 time cost: 4.48s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 4)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8179
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7923

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 5: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 4 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4558
Averaged Test Accuracy: 0.7923
Averaged Test AUC: 0.7322
Averaged Test Precision: 0.7862
Averaged Test Recall: 0.7923
Averaged Test F1-Score: 0.7474
Std Test Accuracy: 0.0411
Std Test AUC: 0.0700
------------------------------------------------------------
Round 4 time cost: 4.51s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8181
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7936

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 5):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 6: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 5 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4528
Averaged Test Accuracy: 0.7936
Averaged Test AUC: 0.7348
Averaged Test Precision: 0.7868
Averaged Test Recall: 0.7936
Averaged Test F1-Score: 0.7509
Std Test Accuracy: 0.0399
Std Test AUC: 0.0694
------------------------------------------------------------
Round 5 time cost: 4.12s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 6)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8195
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7955

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 7: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 6 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4506
Averaged Test Accuracy: 0.7955
Averaged Test AUC: 0.7369
Averaged Test Precision: 0.7933
Averaged Test Recall: 0.7955
Averaged Test F1-Score: 0.7560
Std Test Accuracy: 0.0427
Std Test AUC: 0.0688
------------------------------------------------------------
Round 6 time cost: 4.36s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 7)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8204
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7943

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 8: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 7 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4495
Averaged Test Accuracy: 0.7943
Averaged Test AUC: 0.7382
Averaged Test Precision: 0.7861
Averaged Test Recall: 0.7943
Averaged Test F1-Score: 0.7545
Std Test Accuracy: 0.0433
Std Test AUC: 0.0673
------------------------------------------------------------
Round 7 time cost: 4.44s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 8)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8205
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7951

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 9: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 8 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4478
Averaged Test Accuracy: 0.7951
Averaged Test AUC: 0.7390
Averaged Test Precision: 0.7875
Averaged Test Recall: 0.7951
Averaged Test F1-Score: 0.7573
Std Test Accuracy: 0.0425
Std Test AUC: 0.0672
------------------------------------------------------------
Round 8 time cost: 4.36s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 9)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8209
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7964

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 10: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 9 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4464
Averaged Test Accuracy: 0.7964
Averaged Test AUC: 0.7396
Averaged Test Precision: 0.7889
Averaged Test Recall: 0.7964
Averaged Test F1-Score: 0.7591
Std Test Accuracy: 0.0444
Std Test AUC: 0.0663
------------------------------------------------------------
Round 9 time cost: 4.59s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 10)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 11: ˥�� 0% (��0��)
    Base: 0.8215 �� Decayed: 0.8215 �� Final: 0.8215
  Current threshold (based on ACC(t-1)): 0.8215
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7968

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 10):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 11: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 10 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4443
Averaged Test Accuracy: 0.7968
Averaged Test AUC: 0.7431
Averaged Test Precision: 0.7889
Averaged Test Recall: 0.7968
Averaged Test F1-Score: 0.7613
Std Test Accuracy: 0.0431
Std Test AUC: 0.0638
------------------------------------------------------------
Round 10 time cost: 4.39s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 11)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8211
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.7980

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 12: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 11 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4441
Averaged Test Accuracy: 0.7980
Averaged Test AUC: 0.7434
Averaged Test Precision: 0.7934
Averaged Test Recall: 0.7980
Averaged Test F1-Score: 0.7636
Std Test Accuracy: 0.0451
Std Test AUC: 0.0642
------------------------------------------------------------
Round 11 time cost: 4.24s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 12)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8243
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.7980

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 13: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 12 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4417
Averaged Test Accuracy: 0.7980
Averaged Test AUC: 0.7441
Averaged Test Precision: 0.7884
Averaged Test Recall: 0.7980
Averaged Test F1-Score: 0.7653
Std Test Accuracy: 0.0449
Std Test AUC: 0.0642
------------------------------------------------------------
Round 12 time cost: 4.53s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 13)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8250
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8000

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 14: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 13 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4409
Averaged Test Accuracy: 0.8000
Averaged Test AUC: 0.7446
Averaged Test Precision: 0.7888
Averaged Test Recall: 0.8000
Averaged Test F1-Score: 0.7697
Std Test Accuracy: 0.0458
Std Test AUC: 0.0628
------------------------------------------------------------
Round 13 time cost: 4.28s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 14)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8260
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.7985

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 15: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 14 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4404
Averaged Test Accuracy: 0.7985
Averaged Test AUC: 0.7446
Averaged Test Precision: 0.7905
Averaged Test Recall: 0.7985
Averaged Test F1-Score: 0.7669
Std Test Accuracy: 0.0450
Std Test AUC: 0.0631
------------------------------------------------------------
Round 14 time cost: 4.28s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 15)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 16: ˥�� 5% (��1��)
    Base: 0.8246 �� Decayed: 0.7834 �� Final: 0.7834
  Current threshold (based on ACC(t-1)): 0.7834
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8009

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 15):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 16: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 15 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4394
Averaged Test Accuracy: 0.8009
Averaged Test AUC: 0.7470
Averaged Test Precision: 0.7905
Averaged Test Recall: 0.8009
Averaged Test F1-Score: 0.7706
Std Test Accuracy: 0.0465
Std Test AUC: 0.0619
------------------------------------------------------------
Round 15 time cost: 4.50s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 16)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7839
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8011

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 17: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 16 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4388
Averaged Test Accuracy: 0.8011
Averaged Test AUC: 0.7473
Averaged Test Precision: 0.7948
Averaged Test Recall: 0.8011
Averaged Test F1-Score: 0.7726
Std Test Accuracy: 0.0477
Std Test AUC: 0.0615
------------------------------------------------------------
Round 16 time cost: 4.11s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 17)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7846
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8008

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 18: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 17 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4378
Averaged Test Accuracy: 0.8008
Averaged Test AUC: 0.7468
Averaged Test Precision: 0.7918
Averaged Test Recall: 0.8008
Averaged Test F1-Score: 0.7697
Std Test Accuracy: 0.0438
Std Test AUC: 0.0625
------------------------------------------------------------
Round 17 time cost: 4.43s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 18)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7844
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8019

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 19: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 18 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4362
Averaged Test Accuracy: 0.8019
Averaged Test AUC: 0.7490
Averaged Test Precision: 0.7939
Averaged Test Recall: 0.8019
Averaged Test F1-Score: 0.7719
Std Test Accuracy: 0.0449
Std Test AUC: 0.0607
------------------------------------------------------------
Round 18 time cost: 4.34s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 19)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7850
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.7989

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 20: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 19 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4365
Averaged Test Accuracy: 0.7989
Averaged Test AUC: 0.7478
Averaged Test Precision: 0.7924
Averaged Test Recall: 0.7989
Averaged Test F1-Score: 0.7692
Std Test Accuracy: 0.0481
Std Test AUC: 0.0624
------------------------------------------------------------
Round 19 time cost: 4.18s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 20)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 21: ˥�� 10% (��2��)
    Base: 0.8241 �� Decayed: 0.7417 �� Final: 0.7417
  Current threshold (based on ACC(t-1)): 0.7417
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8000

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 20):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 21: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 20 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4355
Averaged Test Accuracy: 0.8000
Averaged Test AUC: 0.7489
Averaged Test Precision: 0.7898
Averaged Test Recall: 0.8000
Averaged Test F1-Score: 0.7704
Std Test Accuracy: 0.0466
Std Test AUC: 0.0624
------------------------------------------------------------
Round 20 time cost: 4.45s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 21)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7422
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8024

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 22: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 21 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4341
Averaged Test Accuracy: 0.8024
Averaged Test AUC: 0.7499
Averaged Test Precision: 0.7920
Averaged Test Recall: 0.8024
Averaged Test F1-Score: 0.7746
Std Test Accuracy: 0.0450
Std Test AUC: 0.0611
------------------------------------------------------------
Round 21 time cost: 4.30s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 22)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7433
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8007

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 23: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 22 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4343
Averaged Test Accuracy: 0.8007
Averaged Test AUC: 0.7510
Averaged Test Precision: 0.7931
Averaged Test Recall: 0.8007
Averaged Test F1-Score: 0.7721
Std Test Accuracy: 0.0472
Std Test AUC: 0.0604
------------------------------------------------------------
Round 22 time cost: 4.44s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 23)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7431
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8023

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 24: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 23 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4346
Averaged Test Accuracy: 0.8023
Averaged Test AUC: 0.7512
Averaged Test Precision: 0.7943
Averaged Test Recall: 0.8023
Averaged Test F1-Score: 0.7727
Std Test Accuracy: 0.0460
Std Test AUC: 0.0600
------------------------------------------------------------
Round 23 time cost: 4.41s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 24)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7432
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8020

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 25: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 24 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4331
Averaged Test Accuracy: 0.8020
Averaged Test AUC: 0.7514
Averaged Test Precision: 0.7934
Averaged Test Recall: 0.8020
Averaged Test F1-Score: 0.7740
Std Test Accuracy: 0.0470
Std Test AUC: 0.0602
------------------------------------------------------------
Round 24 time cost: 4.10s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 25)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 26: ˥�� 15% (��3��)
    Base: 0.8263 �� Decayed: 0.7024 �� Final: 0.7024
  Current threshold (based on ACC(t-1)): 0.7024
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8041

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 25):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 26: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 25 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4331
Averaged Test Accuracy: 0.8041
Averaged Test AUC: 0.7516
Averaged Test Precision: 0.7956
Averaged Test Recall: 0.8041
Averaged Test F1-Score: 0.7757
Std Test Accuracy: 0.0456
Std Test AUC: 0.0599
------------------------------------------------------------
Round 25 time cost: 4.49s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 26)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7033
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8023

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 27: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 26 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4323
Averaged Test Accuracy: 0.8023
Averaged Test AUC: 0.7521
Averaged Test Precision: 0.7951
Averaged Test Recall: 0.8023
Averaged Test F1-Score: 0.7738
Std Test Accuracy: 0.0472
Std Test AUC: 0.0591
------------------------------------------------------------
Round 26 time cost: 4.60s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 27)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7025
  Best client accuracy (ACC(t)): 0.8547
  Global average accuracy (ACC(t)): 0.8025

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 28: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 27 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4317
Averaged Test Accuracy: 0.8025
Averaged Test AUC: 0.7524
Averaged Test Precision: 0.7932
Averaged Test Recall: 0.8025
Averaged Test F1-Score: 0.7747
Std Test Accuracy: 0.0475
Std Test AUC: 0.0591
------------------------------------------------------------
Round 27 time cost: 4.16s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 28)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7043
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8028

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 29: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 28 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4311
Averaged Test Accuracy: 0.8028
Averaged Test AUC: 0.7525
Averaged Test Precision: 0.7936
Averaged Test Recall: 0.8028
Averaged Test F1-Score: 0.7745
Std Test Accuracy: 0.0463
Std Test AUC: 0.0594
------------------------------------------------------------
Round 28 time cost: 4.54s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 29)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7033
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8021

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 30: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 29 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4308
Averaged Test Accuracy: 0.8021
Averaged Test AUC: 0.7534
Averaged Test Precision: 0.7932
Averaged Test Recall: 0.8021
Averaged Test F1-Score: 0.7740
Std Test Accuracy: 0.0487
Std Test AUC: 0.0592
------------------------------------------------------------
Round 29 time cost: 4.29s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 30)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 4] ��ͣ��� (��ǰ׼ȷ��: 0.8307)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6833
       ��29��: 0.8267 >= 0.6833 [+]
       ��30��: 0.8333 >= 0.6833 [+]
       ��31��: 0.8307 >= 0.6833 [+]
    [+] ����(3): �������ȶ� (0.0067 <= 0.0200)
       ���3��: ['0.8267', '0.8333', '0.8307']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 4 reached early stopping criteria (Round 31):
    - Accuracy: 0.8307 (threshold: 0.7033)
    - Fluctuation: 0.0067 (last 3 rounds)
    - History: ['0.827', '0.833', '0.831']
  [Virtual Data] Generating and locking virtual data for client 4...
  [Mentor Mode] Client 4 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 4 early stopped at round 30
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 7] ��ͣ��� (��ǰ׼ȷ��: 0.7320)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6833
       ��29��: 0.7320 >= 0.6833 [+]
       ��30��: 0.7280 >= 0.6833 [+]
       ��31��: 0.7320 >= 0.6833 [+]
    [+] ����(3): �������ȶ� (0.0040 <= 0.0200)
       ���3��: ['0.7320', '0.7280', '0.7320']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 7 reached early stopping criteria (Round 31):
    - Accuracy: 0.7320 (threshold: 0.7033)
    - Fluctuation: 0.0040 (last 3 rounds)
    - History: ['0.732', '0.728', '0.732']
  [Virtual Data] Generating and locking virtual data for client 7...
  [Mentor Mode] Client 7 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 7 early stopped at round 30
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 5] ��ͣ��� (��ǰ׼ȷ��: 0.7213)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6833
       ��29��: 0.7187 >= 0.6833 [+]
       ��30��: 0.7107 >= 0.6833 [+]
       ��31��: 0.7213 >= 0.6833 [+]
    [+] ����(3): �������ȶ� (0.0107 <= 0.0200)
       ���3��: ['0.7187', '0.7107', '0.7213']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 5 reached early stopping criteria (Round 31):
    - Accuracy: 0.7213 (threshold: 0.7033)
    - Fluctuation: 0.0107 (last 3 rounds)
    - History: ['0.719', '0.711', '0.721']
  [Virtual Data] Generating and locking virtual data for client 5...
  [Mentor Mode] Client 5 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 5 early stopped at round 30
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 6] ��ͣ��� (��ǰ׼ȷ��: 0.8493)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6833
       ��29��: 0.8520 >= 0.6833 [+]
       ��30��: 0.8467 >= 0.6833 [+]
       ��31��: 0.8493 >= 0.6833 [+]
    [+] ����(3): �������ȶ� (0.0053 <= 0.0200)
       ���3��: ['0.8520', '0.8467', '0.8493']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 6 reached early stopping criteria (Round 31):
    - Accuracy: 0.8493 (threshold: 0.7033)
    - Fluctuation: 0.0053 (last 3 rounds)
    - History: ['0.852', '0.847', '0.849']
  [Virtual Data] Generating and locking virtual data for client 6...
  [Mentor Mode] Client 6 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 6 early stopped at round 30
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 8] ��ͣ��� (��ǰ׼ȷ��: 0.7987)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6833
       ��29��: 0.7987 >= 0.6833 [+]
       ��30��: 0.7960 >= 0.6833 [+]
       ��31��: 0.7987 >= 0.6833 [+]
    [+] ����(3): �������ȶ� (0.0027 <= 0.0200)
       ���3��: ['0.7987', '0.7960', '0.7987']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 8 reached early stopping criteria (Round 31):
    - Accuracy: 0.7987 (threshold: 0.7033)
    - Fluctuation: 0.0027 (last 3 rounds)
    - History: ['0.799', '0.796', '0.799']
  [Virtual Data] Generating and locking virtual data for client 8...
  [Mentor Mode] Client 8 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 8 early stopped at round 30
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 0] ��ͣ��� (��ǰ׼ȷ��: 0.8413)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6833
       ��29��: 0.8400 >= 0.6833 [+]
       ��30��: 0.8453 >= 0.6833 [+]
       ��31��: 0.8413 >= 0.6833 [+]
    [+] ����(3): �������ȶ� (0.0053 <= 0.0200)
       ���3��: ['0.8400', '0.8453', '0.8413']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 0 reached early stopping criteria (Round 31):
    - Accuracy: 0.8413 (threshold: 0.7033)
    - Fluctuation: 0.0053 (last 3 rounds)
    - History: ['0.840', '0.845', '0.841']
  [Virtual Data] Generating and locking virtual data for client 0...
  [Mentor Mode] Client 0 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 0 early stopped at round 30
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 3] ��ͣ��� (��ǰ׼ȷ��: 0.7787)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6833
       ��29��: 0.7787 >= 0.6833 [+]
       ��30��: 0.7813 >= 0.6833 [+]
       ��31��: 0.7787 >= 0.6833 [+]
    [+] ����(3): �������ȶ� (0.0027 <= 0.0200)
       ���3��: ['0.7787', '0.7813', '0.7787']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 3 reached early stopping criteria (Round 31):
    - Accuracy: 0.7787 (threshold: 0.7033)
    - Fluctuation: 0.0027 (last 3 rounds)
    - History: ['0.779', '0.781', '0.779']
  [Virtual Data] Generating and locking virtual data for client 3...
  [Mentor Mode] Client 3 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 3 early stopped at round 30
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 1] ��ͣ��� (��ǰ׼ȷ��: 0.8480)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6833
       ��29��: 0.8480 >= 0.6833 [+]
       ��30��: 0.8493 >= 0.6833 [+]
       ��31��: 0.8480 >= 0.6833 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.8480', '0.8493', '0.8480']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 1 reached early stopping criteria (Round 31):
    - Accuracy: 0.8480 (threshold: 0.7033)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.848', '0.849', '0.848']
  [Virtual Data] Generating and locking virtual data for client 1...
  [Mentor Mode] Client 1 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 1 early stopped at round 30
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 9] ��ͣ��� (��ǰ׼ȷ��: 0.8467)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6833
       ��29��: 0.8480 >= 0.6833 [+]
       ��30��: 0.8467 >= 0.6833 [+]
       ��31��: 0.8467 >= 0.6833 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.8480', '0.8467', '0.8467']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 9 reached early stopping criteria (Round 31):
    - Accuracy: 0.8467 (threshold: 0.7033)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.848', '0.847', '0.847']
  [Virtual Data] Generating and locking virtual data for client 9...
  [Mentor Mode] Client 9 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 9 early stopped at round 30
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 2] ��ͣ��� (��ǰ׼ȷ��: 0.7867)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6833
       ��29��: 0.7853 >= 0.6833 [+]
       ��30��: 0.7840 >= 0.6833 [+]
       ��31��: 0.7867 >= 0.6833 [+]
    [+] ����(3): �������ȶ� (0.0027 <= 0.0200)
       ���3��: ['0.7853', '0.7840', '0.7867']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 2 reached early stopping criteria (Round 31):
    - Accuracy: 0.7867 (threshold: 0.7033)
    - Fluctuation: 0.0027 (last 3 rounds)
    - History: ['0.785', '0.784', '0.787']
  [Virtual Data] Generating and locking virtual data for client 2...
  [Mentor Mode] Client 2 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 2 early stopped at round 30
  [Threshold Decay] Round 31: ˥�� 20% (��4��)
    Base: 0.8257 �� Decayed: 0.6606 �� Final: 0.6606
  Current threshold (based on ACC(t-1)): 0.6606
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8033

  [Adaptive Decay] Ȩ��˥���������� (Round 31):
  ��ǰȫ��׼ȷ��: 0.8033
  ˥��ǿ�Ȧ�: 0.5
    Client 4: ��31�ִ��
      ���ʱ׼ȷ��: 0.8033
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 7: ��31�ִ��
      ���ʱ׼ȷ��: 0.8033
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 5: ��31�ִ��
      ���ʱ׼ȷ��: 0.8033
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 6: ��31�ִ��
      ���ʱ׼ȷ��: 0.8033
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 8: ��31�ִ��
      ���ʱ׼ȷ��: 0.8033
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 0: ��31�ִ��
      ���ʱ׼ȷ��: 0.8033
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 3: ��31�ִ��
      ���ʱ׼ȷ��: 0.8033
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 1: ��31�ִ��
      ���ʱ׼ȷ��: 0.8033
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 9: ��31�ִ��
      ���ʱ׼ȷ��: 0.8033
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 2: ��31�ִ��
      ���ʱ׼ȷ��: 0.8033
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
  Early-stopped clients: 10/10
  Active training clients: 0

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 30):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 1   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 2   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 3   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 4   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 5   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 6   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 7   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 8   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 9   2250        1.0000        2250.00         0.1000          ��ͣ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  [Adaptive Decay] Prototype aggregation weights: C0=1.000 C1=1.000 C2=1.000 C3=1.000 C4=1.000 ... (10 total)
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

================================================================================
[Phase Transition Check] Round 31 (Phase 1: ���50��)
================================================================================
���Ҫ��: 7/10 �ͻ��� (70%)
��ǰ״̬: 10/10 �ͻ��˴��

�ͻ�����ϸ״̬:

[+] �Ѵ��ͻ��� (10��):
  Client 6: 0.8493 [+]
  Client 1: 0.8480 [+]
  Client 9: 0.8467 [+]
  Client 0: 0.8413 [+]
  Client 4: 0.8307 [+]
  Client 8: 0.7987 [+]
  Client 2: 0.7867 [+]
  Client 3: 0.7787 [+]
  Client 7: 0.7320 [+]
  Client 5: 0.7213 [+]

��ǰ��ֵ: 0.6606
ƽ��׼ȷ��: 0.8033
���׼ȷ��: 0.8493
================================================================================

[>>] Phase Transition Triggered! (70% Threshold Strategy)
   Qualified clients: 10/10
   Required: 7 (70%)
   Remaining: 0 clients will join dynamically in Phase 2
   Phase 1 completed: 31 rounds (min: 30, max: 50)
================================================================================


============================================================
PHASE TRANSITION: Phase 1 �� Phase 2
============================================================
Virtual data pool size: 0
Phase 2 Algorithm: FEDAVG
Phase 2 Max Rounds: 50
============================================================

  [Algorithm Name] Updated: FedGpro �� FedGpro-FedAvg
  Client 0: Phase 2 (already contributed virtual data)
  Client 1: Phase 2 (already contributed virtual data)
  Client 2: Phase 2 (already contributed virtual data)
  Client 3: Phase 2 (already contributed virtual data)
  Client 4: Phase 2 (already contributed virtual data)
  Client 5: Phase 2 (already contributed virtual data)
  Client 6: Phase 2 (already contributed virtual data)
  Client 7: Phase 2 (already contributed virtual data)
  Client 8: Phase 2 (already contributed virtual data)
  Client 9: Phase 2 (already contributed virtual data)
[OK] Phase 2 initialized successfully!
   Algorithm: FEDAVG
   All clients enter Phase 2: 10 (100%)
   - Already contributed virtual data: 10 (100%)
   - Can still contribute (until round 20): 0 (0%)
   Virtual data pool size: 0 samples
   Phase 1 will continue in parallel until round 20


============================================================
Round 30 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 5.6831
Averaged Test Accuracy (Personalized): 0.3271
Averaged Test AUC (Personalized): 0.6104
Std Test Accuracy (Personalized): 0.1058
Std Test AUC (Personalized): 0.0590

Evaluate global model (Reference only)
Averaged Train Loss: 0.4304
Averaged Test Accuracy: 0.8033
Averaged Test AUC: 0.7530
Averaged Test Precision: 0.7938
Averaged Test Recall: 0.8033
Averaged Test F1-Score: 0.7759
Std Test Accuracy: 0.0457
Std Test AUC: 0.0595
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 30 time cost: 4.60s
------------------------------------------------------------

[Phase 2 - Round 31] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 31 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 1.1043
Averaged Test Accuracy (Personalized): 0.5240
Averaged Test AUC (Personalized): 0.6386
Std Test Accuracy (Personalized): 0.0432
Std Test AUC (Personalized): 0.0660

Evaluate global model (Reference only)
Averaged Train Loss: 0.8696
Averaged Test Accuracy: 0.6177
Averaged Test AUC: 0.6434
Averaged Test Precision: 0.7168
Averaged Test Recall: 0.6177
Averaged Test F1-Score: 0.6450
Std Test Accuracy: 0.0433
Std Test AUC: 0.0670
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 31 time cost: 4.49s
------------------------------------------------------------

[Phase 2 - Round 32] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 32 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.7872
Averaged Test Accuracy (Personalized): 0.6585
Averaged Test AUC (Personalized): 0.6414
Std Test Accuracy (Personalized): 0.0276
Std Test AUC (Personalized): 0.0699

Evaluate global model (Reference only)
Averaged Train Loss: 0.5783
Averaged Test Accuracy: 0.7532
Averaged Test AUC: 0.6356
Averaged Test Precision: 0.7224
Averaged Test Recall: 0.7532
Averaged Test F1-Score: 0.7295
Std Test Accuracy: 0.0533
Std Test AUC: 0.0645
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 32 time cost: 4.38s
------------------------------------------------------------

[Phase 2 - Round 33] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 33 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.6219
Averaged Test Accuracy (Personalized): 0.7367
Averaged Test AUC (Personalized): 0.6424
Std Test Accuracy (Personalized): 0.0455
Std Test AUC (Personalized): 0.0734

Evaluate global model (Reference only)
Averaged Train Loss: 0.5445
Averaged Test Accuracy: 0.7635
Averaged Test AUC: 0.6372
Averaged Test Precision: 0.7275
Averaged Test Recall: 0.7635
Averaged Test F1-Score: 0.7119
Std Test Accuracy: 0.0657
Std Test AUC: 0.0672
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 33 time cost: 4.31s
------------------------------------------------------------

[Phase 2 - Round 34] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 34 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5771
Averaged Test Accuracy (Personalized): 0.7629
Averaged Test AUC (Personalized): 0.6414
Std Test Accuracy (Personalized): 0.0482
Std Test AUC (Personalized): 0.0725

Evaluate global model (Reference only)
Averaged Train Loss: 0.5392
Averaged Test Accuracy: 0.7635
Averaged Test AUC: 0.6442
Averaged Test Precision: 0.7365
Averaged Test Recall: 0.7635
Averaged Test F1-Score: 0.7033
Std Test Accuracy: 0.0680
Std Test AUC: 0.0694
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 34 time cost: 4.52s
------------------------------------------------------------

[Phase 2 - Round 35] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 35 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5564
Averaged Test Accuracy (Personalized): 0.7685
Averaged Test AUC (Personalized): 0.6406
Std Test Accuracy (Personalized): 0.0548
Std Test AUC (Personalized): 0.0706

Evaluate global model (Reference only)
Averaged Train Loss: 0.5318
Averaged Test Accuracy: 0.7621
Averaged Test AUC: 0.6510
Averaged Test Precision: 0.7363
Averaged Test Recall: 0.7621
Averaged Test F1-Score: 0.6992
Std Test Accuracy: 0.0692
Std Test AUC: 0.0689
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 35 time cost: 4.60s
------------------------------------------------------------

[Phase 2 - Round 36] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 36 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5452
Averaged Test Accuracy (Personalized): 0.7707
Averaged Test AUC (Personalized): 0.6408
Std Test Accuracy (Personalized): 0.0581
Std Test AUC (Personalized): 0.0704

Evaluate global model (Reference only)
Averaged Train Loss: 0.5258
Averaged Test Accuracy: 0.7627
Averaged Test AUC: 0.6588
Averaged Test Precision: 0.7412
Averaged Test Recall: 0.7627
Averaged Test F1-Score: 0.7001
Std Test Accuracy: 0.0691
Std Test AUC: 0.0720
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 36 time cost: 4.35s
------------------------------------------------------------

[Phase 2 - Round 37] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 37 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5416
Averaged Test Accuracy (Personalized): 0.7707
Averaged Test AUC (Personalized): 0.6419
Std Test Accuracy (Personalized): 0.0582
Std Test AUC (Personalized): 0.0729

Evaluate global model (Reference only)
Averaged Train Loss: 0.5212
Averaged Test Accuracy: 0.7611
Averaged Test AUC: 0.6660
Averaged Test Precision: 0.7379
Averaged Test Recall: 0.7611
Averaged Test F1-Score: 0.6958
Std Test Accuracy: 0.0703
Std Test AUC: 0.0714
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 37 time cost: 4.47s
------------------------------------------------------------

[Phase 2 - Round 38] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 38 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5410
Averaged Test Accuracy (Personalized): 0.7703
Averaged Test AUC (Personalized): 0.6414
Std Test Accuracy (Personalized): 0.0593
Std Test AUC (Personalized): 0.0730

Evaluate global model (Reference only)
Averaged Train Loss: 0.5161
Averaged Test Accuracy: 0.7623
Averaged Test AUC: 0.6701
Averaged Test Precision: 0.7386
Averaged Test Recall: 0.7623
Averaged Test F1-Score: 0.6958
Std Test Accuracy: 0.0685
Std Test AUC: 0.0745
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 38 time cost: 4.43s
------------------------------------------------------------

[Phase 2 - Round 39] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 39 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5376
Averaged Test Accuracy (Personalized): 0.7699
Averaged Test AUC (Personalized): 0.6419
Std Test Accuracy (Personalized): 0.0590
Std Test AUC (Personalized): 0.0749

Evaluate global model (Reference only)
Averaged Train Loss: 0.5155
Averaged Test Accuracy: 0.7611
Averaged Test AUC: 0.6727
Averaged Test Precision: 0.7406
Averaged Test Recall: 0.7611
Averaged Test F1-Score: 0.6941
Std Test Accuracy: 0.0705
Std Test AUC: 0.0729
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 39 time cost: 4.48s
------------------------------------------------------------

[Phase 2 - Round 40] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 40 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5367
Averaged Test Accuracy (Personalized): 0.7689
Averaged Test AUC (Personalized): 0.6439
Std Test Accuracy (Personalized): 0.0600
Std Test AUC (Personalized): 0.0748

Evaluate global model (Reference only)
Averaged Train Loss: 0.5127
Averaged Test Accuracy: 0.7593
Averaged Test AUC: 0.6771
Averaged Test Precision: 0.7372
Averaged Test Recall: 0.7593
Averaged Test F1-Score: 0.6905
Std Test Accuracy: 0.0725
Std Test AUC: 0.0745
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 40 time cost: 4.45s
------------------------------------------------------------

[Phase 2 - Round 41] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 41 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5326
Averaged Test Accuracy (Personalized): 0.7700
Averaged Test AUC (Personalized): 0.6466
Std Test Accuracy (Personalized): 0.0602
Std Test AUC (Personalized): 0.0744

Evaluate global model (Reference only)
Averaged Train Loss: 0.5101
Averaged Test Accuracy: 0.7625
Averaged Test AUC: 0.6801
Averaged Test Precision: 0.7373
Averaged Test Recall: 0.7625
Averaged Test F1-Score: 0.6958
Std Test Accuracy: 0.0679
Std Test AUC: 0.0739
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 41 time cost: 4.42s
------------------------------------------------------------

[Phase 2 - Round 42] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 42 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5306
Averaged Test Accuracy (Personalized): 0.7680
Averaged Test AUC (Personalized): 0.6486
Std Test Accuracy (Personalized): 0.0613
Std Test AUC (Personalized): 0.0764

Evaluate global model (Reference only)
Averaged Train Loss: 0.5083
Averaged Test Accuracy: 0.7613
Averaged Test AUC: 0.6850
Averaged Test Precision: 0.7373
Averaged Test Recall: 0.7613
Averaged Test F1-Score: 0.6916
Std Test Accuracy: 0.0693
Std Test AUC: 0.0756
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 42 time cost: 4.29s
------------------------------------------------------------

[Phase 2 - Round 43] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 43 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5275
Averaged Test Accuracy (Personalized): 0.7689
Averaged Test AUC (Personalized): 0.6507
Std Test Accuracy (Personalized): 0.0596
Std Test AUC (Personalized): 0.0765

Evaluate global model (Reference only)
Averaged Train Loss: 0.5070
Averaged Test Accuracy: 0.7605
Averaged Test AUC: 0.6881
Averaged Test Precision: 0.7449
Averaged Test Recall: 0.7605
Averaged Test F1-Score: 0.6905
Std Test Accuracy: 0.0712
Std Test AUC: 0.0748
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 43 time cost: 4.53s
------------------------------------------------------------

[Phase 2 - Round 44] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 44 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5260
Averaged Test Accuracy (Personalized): 0.7675
Averaged Test AUC (Personalized): 0.6524
Std Test Accuracy (Personalized): 0.0630
Std Test AUC (Personalized): 0.0751

Evaluate global model (Reference only)
Averaged Train Loss: 0.5067
Averaged Test Accuracy: 0.7588
Averaged Test AUC: 0.6900
Averaged Test Precision: 0.7608
Averaged Test Recall: 0.7588
Averaged Test F1-Score: 0.6879
Std Test Accuracy: 0.0745
Std Test AUC: 0.0754
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 44 time cost: 4.34s
------------------------------------------------------------

[Phase 2 - Round 45] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 45 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5209
Averaged Test Accuracy (Personalized): 0.7711
Averaged Test AUC (Personalized): 0.6556
Std Test Accuracy (Personalized): 0.0585
Std Test AUC (Personalized): 0.0765

Evaluate global model (Reference only)
Averaged Train Loss: 0.5055
Averaged Test Accuracy: 0.7589
Averaged Test AUC: 0.6907
Averaged Test Precision: 0.7327
Averaged Test Recall: 0.7589
Averaged Test F1-Score: 0.6876
Std Test Accuracy: 0.0725
Std Test AUC: 0.0772
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 45 time cost: 4.24s
------------------------------------------------------------

[Phase 2 - Round 46] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 46 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5166
Averaged Test Accuracy (Personalized): 0.7719
Averaged Test AUC (Personalized): 0.6601
Std Test Accuracy (Personalized): 0.0586
Std Test AUC (Personalized): 0.0775

Evaluate global model (Reference only)
Averaged Train Loss: 0.5035
Averaged Test Accuracy: 0.7621
Averaged Test AUC: 0.6936
Averaged Test Precision: 0.7571
Averaged Test Recall: 0.7621
Averaged Test F1-Score: 0.6931
Std Test Accuracy: 0.0701
Std Test AUC: 0.0769
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 46 time cost: 4.58s
------------------------------------------------------------

[Phase 2 - Round 47] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 47 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5158
Averaged Test Accuracy (Personalized): 0.7744
Averaged Test AUC (Personalized): 0.6628
Std Test Accuracy (Personalized): 0.0557
Std Test AUC (Personalized): 0.0775

Evaluate global model (Reference only)
Averaged Train Loss: 0.5022
Averaged Test Accuracy: 0.7627
Averaged Test AUC: 0.6956
Averaged Test Precision: 0.7377
Averaged Test Recall: 0.7627
Averaged Test F1-Score: 0.6942
Std Test Accuracy: 0.0696
Std Test AUC: 0.0772
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 47 time cost: 4.25s
------------------------------------------------------------

[Phase 2 - Round 48] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 48 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5136
Averaged Test Accuracy (Personalized): 0.7728
Averaged Test AUC (Personalized): 0.6646
Std Test Accuracy (Personalized): 0.0574
Std Test AUC (Personalized): 0.0769

Evaluate global model (Reference only)
Averaged Train Loss: 0.5004
Averaged Test Accuracy: 0.7641
Averaged Test AUC: 0.6980
Averaged Test Precision: 0.7648
Averaged Test Recall: 0.7641
Averaged Test F1-Score: 0.6973
Std Test Accuracy: 0.0686
Std Test AUC: 0.0783
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 48 time cost: 4.38s
------------------------------------------------------------

[Phase 2 - Round 49] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 49 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5115
Averaged Test Accuracy (Personalized): 0.7729
Averaged Test AUC (Personalized): 0.6678
Std Test Accuracy (Personalized): 0.0582
Std Test AUC (Personalized): 0.0781

Evaluate global model (Reference only)
Averaged Train Loss: 0.4997
Averaged Test Accuracy: 0.7639
Averaged Test AUC: 0.7002
Averaged Test Precision: 0.7638
Averaged Test Recall: 0.7639
Averaged Test F1-Score: 0.6971
Std Test Accuracy: 0.0693
Std Test AUC: 0.0780
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 49 time cost: 4.47s
------------------------------------------------------------

[Phase 2 - Round 50] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 50 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5124
Averaged Test Accuracy (Personalized): 0.7723
Averaged Test AUC (Personalized): 0.6673
Std Test Accuracy (Personalized): 0.0572
Std Test AUC (Personalized): 0.0784

Evaluate global model (Reference only)
Averaged Train Loss: 0.4974
Averaged Test Accuracy: 0.7683
Averaged Test AUC: 0.7014
Averaged Test Precision: 0.7636
Averaged Test Recall: 0.7683
Averaged Test F1-Score: 0.7059
Std Test Accuracy: 0.0643
Std Test AUC: 0.0779
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 50 time cost: 4.09s
------------------------------------------------------------

[Phase 2 - Round 51] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 51 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5107
Averaged Test Accuracy (Personalized): 0.7728
Averaged Test AUC (Personalized): 0.6685
Std Test Accuracy (Personalized): 0.0573
Std Test AUC (Personalized): 0.0784

Evaluate global model (Reference only)
Averaged Train Loss: 0.4958
Averaged Test Accuracy: 0.7699
Averaged Test AUC: 0.7039
Averaged Test Precision: 0.7557
Averaged Test Recall: 0.7699
Averaged Test F1-Score: 0.7090
Std Test Accuracy: 0.0629
Std Test AUC: 0.0774
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 51 time cost: 4.39s
------------------------------------------------------------

[Phase 2 - Round 52] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 52 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5098
Averaged Test Accuracy (Personalized): 0.7729
Averaged Test AUC (Personalized): 0.6694
Std Test Accuracy (Personalized): 0.0556
Std Test AUC (Personalized): 0.0791

Evaluate global model (Reference only)
Averaged Train Loss: 0.4943
Averaged Test Accuracy: 0.7711
Averaged Test AUC: 0.7056
Averaged Test Precision: 0.7598
Averaged Test Recall: 0.7711
Averaged Test F1-Score: 0.7110
Std Test Accuracy: 0.0612
Std Test AUC: 0.0778
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 52 time cost: 4.78s
------------------------------------------------------------

[Phase 2 - Round 53] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 53 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5072
Averaged Test Accuracy (Personalized): 0.7709
Averaged Test AUC (Personalized): 0.6724
Std Test Accuracy (Personalized): 0.0592
Std Test AUC (Personalized): 0.0786

Evaluate global model (Reference only)
Averaged Train Loss: 0.4925
Averaged Test Accuracy: 0.7736
Averaged Test AUC: 0.7066
Averaged Test Precision: 0.7642
Averaged Test Recall: 0.7736
Averaged Test F1-Score: 0.7153
Std Test Accuracy: 0.0579
Std Test AUC: 0.0771
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 53 time cost: 4.09s
------------------------------------------------------------

[Phase 2 - Round 54] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 54 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5055
Averaged Test Accuracy (Personalized): 0.7763
Averaged Test AUC (Personalized): 0.6736
Std Test Accuracy (Personalized): 0.0534
Std Test AUC (Personalized): 0.0791

Evaluate global model (Reference only)
Averaged Train Loss: 0.4899
Averaged Test Accuracy: 0.7775
Averaged Test AUC: 0.7086
Averaged Test Precision: 0.7618
Averaged Test Recall: 0.7775
Averaged Test F1-Score: 0.7214
Std Test Accuracy: 0.0534
Std Test AUC: 0.0767
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 54 time cost: 4.43s
------------------------------------------------------------

[Phase 2 - Round 55] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 55 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5027
Averaged Test Accuracy (Personalized): 0.7776
Averaged Test AUC (Personalized): 0.6768
Std Test Accuracy (Personalized): 0.0529
Std Test AUC (Personalized): 0.0789

Evaluate global model (Reference only)
Averaged Train Loss: 0.4883
Averaged Test Accuracy: 0.7805
Averaged Test AUC: 0.7115
Averaged Test Precision: 0.7741
Averaged Test Recall: 0.7805
Averaged Test F1-Score: 0.7245
Std Test Accuracy: 0.0509
Std Test AUC: 0.0777
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 55 time cost: 4.60s
------------------------------------------------------------

[Phase 2 - Round 56] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 56 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5027
Averaged Test Accuracy (Personalized): 0.7792
Averaged Test AUC (Personalized): 0.6793
Std Test Accuracy (Personalized): 0.0515
Std Test AUC (Personalized): 0.0793

Evaluate global model (Reference only)
Averaged Train Loss: 0.4880
Averaged Test Accuracy: 0.7799
Averaged Test AUC: 0.7104
Averaged Test Precision: 0.7854
Averaged Test Recall: 0.7799
Averaged Test F1-Score: 0.7232
Std Test Accuracy: 0.0505
Std Test AUC: 0.0765
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 56 time cost: 4.05s
------------------------------------------------------------

[Phase 2 - Round 57] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 57 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5012
Averaged Test Accuracy (Personalized): 0.7759
Averaged Test AUC (Personalized): 0.6796
Std Test Accuracy (Personalized): 0.0549
Std Test AUC (Personalized): 0.0789

Evaluate global model (Reference only)
Averaged Train Loss: 0.4863
Averaged Test Accuracy: 0.7801
Averaged Test AUC: 0.7128
Averaged Test Precision: 0.7573
Averaged Test Recall: 0.7801
Averaged Test F1-Score: 0.7251
Std Test Accuracy: 0.0503
Std Test AUC: 0.0770
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 57 time cost: 4.54s
------------------------------------------------------------

[Phase 2 - Round 58] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 58 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4998
Averaged Test Accuracy (Personalized): 0.7772
Averaged Test AUC (Personalized): 0.6819
Std Test Accuracy (Personalized): 0.0542
Std Test AUC (Personalized): 0.0783

Evaluate global model (Reference only)
Averaged Train Loss: 0.4847
Averaged Test Accuracy: 0.7828
Averaged Test AUC: 0.7132
Averaged Test Precision: 0.7677
Averaged Test Recall: 0.7828
Averaged Test F1-Score: 0.7285
Std Test Accuracy: 0.0488
Std Test AUC: 0.0771
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 58 time cost: 4.57s
------------------------------------------------------------

[Phase 2 - Round 59] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 59 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4988
Averaged Test Accuracy (Personalized): 0.7760
Averaged Test AUC (Personalized): 0.6819
Std Test Accuracy (Personalized): 0.0537
Std Test AUC (Personalized): 0.0803

Evaluate global model (Reference only)
Averaged Train Loss: 0.4844
Averaged Test Accuracy: 0.7801
Averaged Test AUC: 0.7149
Averaged Test Precision: 0.7646
Averaged Test Recall: 0.7801
Averaged Test F1-Score: 0.7246
Std Test Accuracy: 0.0502
Std Test AUC: 0.0767
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 59 time cost: 4.19s
------------------------------------------------------------

[Phase 2 - Round 60] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 60 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4967
Averaged Test Accuracy (Personalized): 0.7769
Averaged Test AUC (Personalized): 0.6832
Std Test Accuracy (Personalized): 0.0536
Std Test AUC (Personalized): 0.0785

Evaluate global model (Reference only)
Averaged Train Loss: 0.4833
Averaged Test Accuracy: 0.7837
Averaged Test AUC: 0.7163
Averaged Test Precision: 0.7733
Averaged Test Recall: 0.7837
Averaged Test F1-Score: 0.7285
Std Test Accuracy: 0.0482
Std Test AUC: 0.0768
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 60 time cost: 4.42s
------------------------------------------------------------

[Phase 2 - Round 61] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 61 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4959
Averaged Test Accuracy (Personalized): 0.7784
Averaged Test AUC (Personalized): 0.6856
Std Test Accuracy (Personalized): 0.0511
Std Test AUC (Personalized): 0.0783

Evaluate global model (Reference only)
Averaged Train Loss: 0.4835
Averaged Test Accuracy: 0.7825
Averaged Test AUC: 0.7185
Averaged Test Precision: 0.7868
Averaged Test Recall: 0.7825
Averaged Test F1-Score: 0.7266
Std Test Accuracy: 0.0491
Std Test AUC: 0.0759
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 61 time cost: 4.37s
------------------------------------------------------------

[Phase 2 - Round 62] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 62 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4955
Averaged Test Accuracy (Personalized): 0.7777
Averaged Test AUC (Personalized): 0.6849
Std Test Accuracy (Personalized): 0.0530
Std Test AUC (Personalized): 0.0790

Evaluate global model (Reference only)
Averaged Train Loss: 0.4830
Averaged Test Accuracy: 0.7828
Averaged Test AUC: 0.7186
Averaged Test Precision: 0.7779
Averaged Test Recall: 0.7828
Averaged Test F1-Score: 0.7282
Std Test Accuracy: 0.0474
Std Test AUC: 0.0768
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 62 time cost: 4.46s
------------------------------------------------------------

[Phase 2 - Round 63] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 63 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4936
Averaged Test Accuracy (Personalized): 0.7801
Averaged Test AUC (Personalized): 0.6876
Std Test Accuracy (Personalized): 0.0503
Std Test AUC (Personalized): 0.0785

Evaluate global model (Reference only)
Averaged Train Loss: 0.4825
Averaged Test Accuracy: 0.7835
Averaged Test AUC: 0.7194
Averaged Test Precision: 0.7785
Averaged Test Recall: 0.7835
Averaged Test F1-Score: 0.7288
Std Test Accuracy: 0.0471
Std Test AUC: 0.0759
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 63 time cost: 4.46s
------------------------------------------------------------

[Phase 2 - Round 64] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 64 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4938
Averaged Test Accuracy (Personalized): 0.7795
Averaged Test AUC (Personalized): 0.6879
Std Test Accuracy (Personalized): 0.0519
Std Test AUC (Personalized): 0.0773

Evaluate global model (Reference only)
Averaged Train Loss: 0.4819
Averaged Test Accuracy: 0.7823
Averaged Test AUC: 0.7189
Averaged Test Precision: 0.7707
Averaged Test Recall: 0.7823
Averaged Test F1-Score: 0.7273
Std Test Accuracy: 0.0481
Std Test AUC: 0.0758
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 64 time cost: 4.37s
------------------------------------------------------------

[Phase 2 - Round 65] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 65 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4928
Averaged Test Accuracy (Personalized): 0.7793
Averaged Test AUC (Personalized): 0.6884
Std Test Accuracy (Personalized): 0.0505
Std Test AUC (Personalized): 0.0780

Evaluate global model (Reference only)
Averaged Train Loss: 0.4824
Averaged Test Accuracy: 0.7831
Averaged Test AUC: 0.7196
Averaged Test Precision: 0.7583
Averaged Test Recall: 0.7831
Averaged Test F1-Score: 0.7272
Std Test Accuracy: 0.0469
Std Test AUC: 0.0756
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 65 time cost: 4.50s
------------------------------------------------------------

[Phase 2 - Round 66] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 66 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4919
Averaged Test Accuracy (Personalized): 0.7779
Averaged Test AUC (Personalized): 0.6911
Std Test Accuracy (Personalized): 0.0529
Std Test AUC (Personalized): 0.0788

Evaluate global model (Reference only)
Averaged Train Loss: 0.4814
Averaged Test Accuracy: 0.7832
Averaged Test AUC: 0.7207
Averaged Test Precision: 0.7660
Averaged Test Recall: 0.7832
Averaged Test F1-Score: 0.7273
Std Test Accuracy: 0.0474
Std Test AUC: 0.0760
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 66 time cost: 4.60s
------------------------------------------------------------

[Phase 2 - Round 67] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 67 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4913
Averaged Test Accuracy (Personalized): 0.7787
Averaged Test AUC (Personalized): 0.6922
Std Test Accuracy (Personalized): 0.0518
Std Test AUC (Personalized): 0.0782

Evaluate global model (Reference only)
Averaged Train Loss: 0.4805
Averaged Test Accuracy: 0.7839
Averaged Test AUC: 0.7212
Averaged Test Precision: 0.7660
Averaged Test Recall: 0.7839
Averaged Test F1-Score: 0.7288
Std Test Accuracy: 0.0469
Std Test AUC: 0.0756
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 67 time cost: 4.17s
------------------------------------------------------------

[Phase 2 - Round 68] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 68 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4903
Averaged Test Accuracy (Personalized): 0.7787
Averaged Test AUC (Personalized): 0.6911
Std Test Accuracy (Personalized): 0.0524
Std Test AUC (Personalized): 0.0801

Evaluate global model (Reference only)
Averaged Train Loss: 0.4799
Averaged Test Accuracy: 0.7855
Averaged Test AUC: 0.7220
Averaged Test Precision: 0.7601
Averaged Test Recall: 0.7855
Averaged Test F1-Score: 0.7295
Std Test Accuracy: 0.0456
Std Test AUC: 0.0758
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 68 time cost: 4.28s
------------------------------------------------------------

[Phase 2 - Round 69] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 69 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4902
Averaged Test Accuracy (Personalized): 0.7780
Averaged Test AUC (Personalized): 0.6927
Std Test Accuracy (Personalized): 0.0546
Std Test AUC (Personalized): 0.0784

Evaluate global model (Reference only)
Averaged Train Loss: 0.4804
Averaged Test Accuracy: 0.7840
Averaged Test AUC: 0.7217
Averaged Test Precision: 0.7565
Averaged Test Recall: 0.7840
Averaged Test F1-Score: 0.7276
Std Test Accuracy: 0.0468
Std Test AUC: 0.0754
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 69 time cost: 4.53s
------------------------------------------------------------

[Phase 2 - Round 70] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 70 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4887
Averaged Test Accuracy (Personalized): 0.7800
Averaged Test AUC (Personalized): 0.6917
Std Test Accuracy (Personalized): 0.0504
Std Test AUC (Personalized): 0.0785

Evaluate global model (Reference only)
Averaged Train Loss: 0.4801
Averaged Test Accuracy: 0.7841
Averaged Test AUC: 0.7225
Averaged Test Precision: 0.7671
Averaged Test Recall: 0.7841
Averaged Test F1-Score: 0.7280
Std Test Accuracy: 0.0460
Std Test AUC: 0.0755
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 70 time cost: 4.53s
------------------------------------------------------------

[Phase 2 - Round 71] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 71 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4876
Averaged Test Accuracy (Personalized): 0.7817
Averaged Test AUC (Personalized): 0.6943
Std Test Accuracy (Personalized): 0.0491
Std Test AUC (Personalized): 0.0792

Evaluate global model (Reference only)
Averaged Train Loss: 0.4792
Averaged Test Accuracy: 0.7876
Averaged Test AUC: 0.7247
Averaged Test Precision: 0.7796
Averaged Test Recall: 0.7876
Averaged Test F1-Score: 0.7333
Std Test Accuracy: 0.0438
Std Test AUC: 0.0756
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 71 time cost: 4.45s
------------------------------------------------------------

[Phase 2 - Round 72] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 72 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4873
Averaged Test Accuracy (Personalized): 0.7801
Averaged Test AUC (Personalized): 0.6968
Std Test Accuracy (Personalized): 0.0507
Std Test AUC (Personalized): 0.0776

Evaluate global model (Reference only)
Averaged Train Loss: 0.4790
Averaged Test Accuracy: 0.7857
Averaged Test AUC: 0.7234
Averaged Test Precision: 0.7567
Averaged Test Recall: 0.7857
Averaged Test F1-Score: 0.7311
Std Test Accuracy: 0.0440
Std Test AUC: 0.0750
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 72 time cost: 4.62s
------------------------------------------------------------

[Phase 2 - Round 73] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 73 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4868
Averaged Test Accuracy (Personalized): 0.7801
Averaged Test AUC (Personalized): 0.6955
Std Test Accuracy (Personalized): 0.0511
Std Test AUC (Personalized): 0.0783

Evaluate global model (Reference only)
Averaged Train Loss: 0.4786
Averaged Test Accuracy: 0.7844
Averaged Test AUC: 0.7245
Averaged Test Precision: 0.7593
Averaged Test Recall: 0.7844
Averaged Test F1-Score: 0.7287
Std Test Accuracy: 0.0463
Std Test AUC: 0.0751
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 73 time cost: 4.12s
------------------------------------------------------------

[Phase 2 - Round 74] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 74 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4866
Averaged Test Accuracy (Personalized): 0.7784
Averaged Test AUC (Personalized): 0.6970
Std Test Accuracy (Personalized): 0.0521
Std Test AUC (Personalized): 0.0785

Evaluate global model (Reference only)
Averaged Train Loss: 0.4784
Averaged Test Accuracy: 0.7832
Averaged Test AUC: 0.7244
Averaged Test Precision: 0.7572
Averaged Test Recall: 0.7832
Averaged Test F1-Score: 0.7280
Std Test Accuracy: 0.0466
Std Test AUC: 0.0748
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 74 time cost: 4.47s
------------------------------------------------------------

[Phase 2 - Round 75] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 75 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4842
Averaged Test Accuracy (Personalized): 0.7801
Averaged Test AUC (Personalized): 0.7009
Std Test Accuracy (Personalized): 0.0502
Std Test AUC (Personalized): 0.0774

Evaluate global model (Reference only)
Averaged Train Loss: 0.4774
Averaged Test Accuracy: 0.7868
Averaged Test AUC: 0.7253
Averaged Test Precision: 0.7596
Averaged Test Recall: 0.7868
Averaged Test F1-Score: 0.7331
Std Test Accuracy: 0.0441
Std Test AUC: 0.0755
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 75 time cost: 4.62s
------------------------------------------------------------

[Phase 2 - Round 76] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 76 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4852
Averaged Test Accuracy (Personalized): 0.7821
Averaged Test AUC (Personalized): 0.6998
Std Test Accuracy (Personalized): 0.0480
Std Test AUC (Personalized): 0.0778

Evaluate global model (Reference only)
Averaged Train Loss: 0.4776
Averaged Test Accuracy: 0.7851
Averaged Test AUC: 0.7263
Averaged Test Precision: 0.7581
Averaged Test Recall: 0.7851
Averaged Test F1-Score: 0.7313
Std Test Accuracy: 0.0445
Std Test AUC: 0.0757
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 76 time cost: 4.49s
------------------------------------------------------------

[Phase 2 - Round 77] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 77 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4849
Averaged Test Accuracy (Personalized): 0.7807
Averaged Test AUC (Personalized): 0.6996
Std Test Accuracy (Personalized): 0.0498
Std Test AUC (Personalized): 0.0779

Evaluate global model (Reference only)
Averaged Train Loss: 0.4775
Averaged Test Accuracy: 0.7836
Averaged Test AUC: 0.7268
Averaged Test Precision: 0.7584
Averaged Test Recall: 0.7836
Averaged Test F1-Score: 0.7283
Std Test Accuracy: 0.0466
Std Test AUC: 0.0749
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 77 time cost: 4.52s
------------------------------------------------------------

[Phase 2 - Round 78] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 78 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4837
Averaged Test Accuracy (Personalized): 0.7825
Averaged Test AUC (Personalized): 0.7000
Std Test Accuracy (Personalized): 0.0486
Std Test AUC (Personalized): 0.0785

Evaluate global model (Reference only)
Averaged Train Loss: 0.4772
Averaged Test Accuracy: 0.7847
Averaged Test AUC: 0.7260
Averaged Test Precision: 0.7793
Averaged Test Recall: 0.7847
Averaged Test F1-Score: 0.7296
Std Test Accuracy: 0.0468
Std Test AUC: 0.0747
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 78 time cost: 4.52s
------------------------------------------------------------

[Phase 2 - Round 79] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 79 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4833
Averaged Test Accuracy (Personalized): 0.7825
Averaged Test AUC (Personalized): 0.7006
Std Test Accuracy (Personalized): 0.0496
Std Test AUC (Personalized): 0.0790

Evaluate global model (Reference only)
Averaged Train Loss: 0.4763
Averaged Test Accuracy: 0.7835
Averaged Test AUC: 0.7271
Averaged Test Precision: 0.7536
Averaged Test Recall: 0.7835
Averaged Test F1-Score: 0.7289
Std Test Accuracy: 0.0455
Std Test AUC: 0.0749
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 79 time cost: 4.42s
------------------------------------------------------------

[Phase 2 - Round 80] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 80 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4831
Averaged Test Accuracy (Personalized): 0.7811
Averaged Test AUC (Personalized): 0.7013
Std Test Accuracy (Personalized): 0.0503
Std Test AUC (Personalized): 0.0776

Evaluate global model (Reference only)
Averaged Train Loss: 0.4759
Averaged Test Accuracy: 0.7836
Averaged Test AUC: 0.7260
Averaged Test Precision: 0.7754
Averaged Test Recall: 0.7836
Averaged Test F1-Score: 0.7295
Std Test Accuracy: 0.0460
Std Test AUC: 0.0746
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 80 time cost: 4.62s
------------------------------------------------------------

============================================================
Phase 2 completed: 50/50 rounds
============================================================


============================================================
Final Evaluation - Round 81 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4833
Averaged Test Accuracy (Personalized): 0.7811
Averaged Test AUC (Personalized): 0.7013
Std Test Accuracy (Personalized): 0.0503
Std Test AUC (Personalized): 0.0776

Evaluate global model (Reference)
Averaged Train Loss: 0.4765
Averaged Test Accuracy: 0.7836
Averaged Test AUC: 0.7260
Averaged Test Precision: 0.7754
Averaged Test Recall: 0.7836
Averaged Test F1-Score: 0.7295
Std Test Accuracy: 0.0460
Std Test AUC: 0.0746

Best accuracy:
0.8041333333333334

Average time cost:
4.407206496596336

[FedGpro] Saving results...
  rs_test_acc entries: 82
  rs_test_auc entries: 82
  rs_train_loss entries: 82
  Saving to: system\results\Uci_FedGpro_Ablation_No_VAE_Generation_feature\Uci_FedGpro_Ablation_No_VAE_Generation_feature_2.h5
  [+] Saved h5 file successfully
  Saving CSV to: system\results\Uci_FedGpro_Ablation_No_VAE_Generation_feature\Uci_FedGpro_Ablation_No_VAE_Generation_feature_2_training_process.csv
  [+] Saved CSV file successfully
  [+] Saved npy files successfully

============= Running time: 3th =============
Creating server and clients ...
Auto-selected UciCreditNet for dataset Uci
UciCreditNet(
  (layers): Sequential(
    (0): Linear(in_features=23, out_features=32, bias=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.4, inplace=False)
    (4): Linear(in_features=32, out_features=16, bias=True)
    (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.2, inplace=False)
  )
  (fc): Linear(in_features=16, out_features=2, bias=True)
)
  Client 0: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 1: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 2: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 3: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 4: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 5: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 6: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 7: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 8: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 9: Personalization enabled (mu=0.0, plocal_epochs=1)

============================================================
FedGpro: Federated Global Prototype Learning
============================================================
Join ratio / total clients: 1.0 / 10

Phase 1 Parameters (Max 20 rounds):
  Minimum threshold: 0.6
  Threshold formula:
    ACC(t-1) = (best_acc(t-1) + avg_acc(t-1)) / 2
    threshold(r) = ACC(t-1),                                       if r <= 9
    threshold(r) = max(0.66, ACC(t-1)*(1-0.05*floor((r-10)/5))), if r >= 10
  Training stages:
    - Round 1-10: Forced training (no early stop check, ensure VAE quality)
    - Round 11+: Early stop check + dynamic threshold with time decay
  Phase transition: 70% clients qualified OR 25 rounds reached

Phase 2 Parameters:
  Aggregation: fedavg
  Supported algorithms: fedavg, fedprox, fedscaffold
============================================================

Finished creating server and clients.

[Phase 1] Statistical Collection (Round 0)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.6600
  Best client accuracy (ACC(t)): 0.8427
  Global average accuracy (ACC(t)): 0.7813
  Client 7 meets threshold! Generating virtual data...
  Client 7: Privacy disabled, skipping baseline VAE training.
  Client 7: Skipped virtual data generation (ratio=1.0)
  Client 7: No noise added (privacy disabled).
  Client 2 meets threshold! Generating virtual data...
  Client 2: Privacy disabled, skipping baseline VAE training.
  Client 2: Skipped virtual data generation (ratio=1.0)
  Client 2: No noise added (privacy disabled).
  Client 5 meets threshold! Generating virtual data...
  Client 5: Privacy disabled, skipping baseline VAE training.
  Client 5: Skipped virtual data generation (ratio=1.0)
  Client 5: No noise added (privacy disabled).
  Client 8 meets threshold! Generating virtual data...
  Client 8: Privacy disabled, skipping baseline VAE training.
  Client 8: Skipped virtual data generation (ratio=1.0)
  Client 8: No noise added (privacy disabled).
  Client 1 meets threshold! Generating virtual data...
  Client 1: Privacy disabled, skipping baseline VAE training.
  Client 1: Skipped virtual data generation (ratio=1.0)
  Client 1: No noise added (privacy disabled).
  Client 9 meets threshold! Generating virtual data...
  Client 9: Privacy disabled, skipping baseline VAE training.
  Client 9: Skipped virtual data generation (ratio=1.0)
  Client 9: No noise added (privacy disabled).
  Client 6 meets threshold! Generating virtual data...
  Client 6: Privacy disabled, skipping baseline VAE training.
  Client 6: Skipped virtual data generation (ratio=1.0)
  Client 6: No noise added (privacy disabled).
  Client 0 meets threshold! Generating virtual data...
  Client 0: Privacy disabled, skipping baseline VAE training.
  Client 0: Skipped virtual data generation (ratio=1.0)
  Client 0: No noise added (privacy disabled).
  Client 3 meets threshold! Generating virtual data...
  Client 3: Privacy disabled, skipping baseline VAE training.
  Client 3: Skipped virtual data generation (ratio=1.0)
  Client 3: No noise added (privacy disabled).
  Client 4 meets threshold! Generating virtual data...
  Client 4: Privacy disabled, skipping baseline VAE training.
  Client 4: Skipped virtual data generation (ratio=1.0)
  Client 4: No noise added (privacy disabled).
  Newly qualified clients: [7, 2, 5, 8, 1, 9, 6, 0, 3, 4]
  Total qualified clients: 10/10
  Virtual data pool size: 0

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 0):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 1: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 0 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4889
Averaged Test Accuracy: 0.7813
Averaged Test AUC: 0.6941
Averaged Test Precision: 0.7769
Averaged Test Recall: 0.7813
Averaged Test F1-Score: 0.7288
Std Test Accuracy: 0.0498
Std Test AUC: 0.0785
------------------------------------------------------------
Round 0 time cost: 4.60s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 1)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8120
  Best client accuracy (ACC(t)): 0.8427
  Global average accuracy (ACC(t)): 0.7840

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 2: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 1 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4731
Averaged Test Accuracy: 0.7840
Averaged Test AUC: 0.7163
Averaged Test Precision: 0.7451
Averaged Test Recall: 0.7840
Averaged Test F1-Score: 0.7297
Std Test Accuracy: 0.0481
Std Test AUC: 0.0758
------------------------------------------------------------
Round 1 time cost: 4.41s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 2)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8133
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7901

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 3: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 2 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4641
Averaged Test Accuracy: 0.7901
Averaged Test AUC: 0.7250
Averaged Test Precision: 0.7858
Averaged Test Recall: 0.7901
Averaged Test F1-Score: 0.7422
Std Test Accuracy: 0.0415
Std Test AUC: 0.0722
------------------------------------------------------------
Round 2 time cost: 4.27s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 3)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8171
  Best client accuracy (ACC(t)): 0.8427
  Global average accuracy (ACC(t)): 0.7927

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 4: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 3 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4581
Averaged Test Accuracy: 0.7927
Averaged Test AUC: 0.7296
Averaged Test Precision: 0.7848
Averaged Test Recall: 0.7927
Averaged Test F1-Score: 0.7486
Std Test Accuracy: 0.0430
Std Test AUC: 0.0706
------------------------------------------------------------
Round 3 time cost: 4.52s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 4)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8177
  Best client accuracy (ACC(t)): 0.8427
  Global average accuracy (ACC(t)): 0.7945

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 5: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 4 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4542
Averaged Test Accuracy: 0.7945
Averaged Test AUC: 0.7331
Averaged Test Precision: 0.7803
Averaged Test Recall: 0.7945
Averaged Test F1-Score: 0.7520
Std Test Accuracy: 0.0413
Std Test AUC: 0.0700
------------------------------------------------------------
Round 4 time cost: 4.44s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8186
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7959

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 5):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 6: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 5 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4522
Averaged Test Accuracy: 0.7959
Averaged Test AUC: 0.7364
Averaged Test Precision: 0.7890
Averaged Test Recall: 0.7959
Averaged Test F1-Score: 0.7563
Std Test Accuracy: 0.0431
Std Test AUC: 0.0661
------------------------------------------------------------
Round 5 time cost: 4.34s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 6)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8206
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7967

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 7: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 6 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4503
Averaged Test Accuracy: 0.7967
Averaged Test AUC: 0.7374
Averaged Test Precision: 0.7917
Averaged Test Recall: 0.7967
Averaged Test F1-Score: 0.7574
Std Test Accuracy: 0.0410
Std Test AUC: 0.0666
------------------------------------------------------------
Round 6 time cost: 4.19s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 7)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8210
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7973

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 8: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 7 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4484
Averaged Test Accuracy: 0.7973
Averaged Test AUC: 0.7396
Averaged Test Precision: 0.7915
Averaged Test Recall: 0.7973
Averaged Test F1-Score: 0.7595
Std Test Accuracy: 0.0417
Std Test AUC: 0.0657
------------------------------------------------------------
Round 7 time cost: 4.60s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 8)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8213
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7988

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 9: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 8 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4464
Averaged Test Accuracy: 0.7988
Averaged Test AUC: 0.7417
Averaged Test Precision: 0.7958
Averaged Test Recall: 0.7988
Averaged Test F1-Score: 0.7640
Std Test Accuracy: 0.0438
Std Test AUC: 0.0646
------------------------------------------------------------
Round 8 time cost: 4.57s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 9)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8227
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7983

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 10: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 9 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4456
Averaged Test Accuracy: 0.7983
Averaged Test AUC: 0.7409
Averaged Test Precision: 0.7940
Averaged Test Recall: 0.7983
Averaged Test F1-Score: 0.7608
Std Test Accuracy: 0.0410
Std Test AUC: 0.0653
------------------------------------------------------------
Round 9 time cost: 4.52s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 10)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 11: ˥�� 0% (��0��)
    Base: 0.8225 �� Decayed: 0.8225 �� Final: 0.8225
  Current threshold (based on ACC(t-1)): 0.8225
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.7993

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 10):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 11: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 10 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4433
Averaged Test Accuracy: 0.7993
Averaged Test AUC: 0.7429
Averaged Test Precision: 0.7950
Averaged Test Recall: 0.7993
Averaged Test F1-Score: 0.7656
Std Test Accuracy: 0.0454
Std Test AUC: 0.0643
------------------------------------------------------------
Round 10 time cost: 4.66s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 11)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8250
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7988

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 12: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 11 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4429
Averaged Test Accuracy: 0.7988
Averaged Test AUC: 0.7452
Averaged Test Precision: 0.7939
Averaged Test Recall: 0.7988
Averaged Test F1-Score: 0.7632
Std Test Accuracy: 0.0423
Std Test AUC: 0.0611
------------------------------------------------------------
Round 11 time cost: 4.41s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 12)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8227
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8012

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 13: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 12 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4411
Averaged Test Accuracy: 0.8012
Averaged Test AUC: 0.7468
Averaged Test Precision: 0.7925
Averaged Test Recall: 0.8012
Averaged Test F1-Score: 0.7683
Std Test Accuracy: 0.0432
Std Test AUC: 0.0627
------------------------------------------------------------
Round 12 time cost: 4.07s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 13)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8259
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8017

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 14: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 13 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4402
Averaged Test Accuracy: 0.8017
Averaged Test AUC: 0.7447
Averaged Test Precision: 0.7951
Averaged Test Recall: 0.8017
Averaged Test F1-Score: 0.7703
Std Test Accuracy: 0.0442
Std Test AUC: 0.0641
------------------------------------------------------------
Round 13 time cost: 4.75s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 14)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8262
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8023

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 15: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 14 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4391
Averaged Test Accuracy: 0.8023
Averaged Test AUC: 0.7488
Averaged Test Precision: 0.7928
Averaged Test Recall: 0.8023
Averaged Test F1-Score: 0.7736
Std Test Accuracy: 0.0453
Std Test AUC: 0.0612
------------------------------------------------------------
Round 14 time cost: 4.52s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 15)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 16: ˥�� 5% (��1��)
    Base: 0.8271 �� Decayed: 0.7858 �� Final: 0.7858
  Current threshold (based on ACC(t-1)): 0.7858
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8016

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 15):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 16: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 15 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4390
Averaged Test Accuracy: 0.8016
Averaged Test AUC: 0.7491
Averaged Test Precision: 0.7945
Averaged Test Recall: 0.8016
Averaged Test F1-Score: 0.7713
Std Test Accuracy: 0.0451
Std Test AUC: 0.0611
------------------------------------------------------------
Round 15 time cost: 4.46s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 16)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7855
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8025

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 17: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 16 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4378
Averaged Test Accuracy: 0.8025
Averaged Test AUC: 0.7499
Averaged Test Precision: 0.7959
Averaged Test Recall: 0.8025
Averaged Test F1-Score: 0.7726
Std Test Accuracy: 0.0446
Std Test AUC: 0.0606
------------------------------------------------------------
Round 16 time cost: 4.52s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 17)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7859
  Best client accuracy (ACC(t)): 0.8533
  Global average accuracy (ACC(t)): 0.8008

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 18: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 17 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4368
Averaged Test Accuracy: 0.8008
Averaged Test AUC: 0.7500
Averaged Test Precision: 0.7931
Averaged Test Recall: 0.8008
Averaged Test F1-Score: 0.7733
Std Test Accuracy: 0.0487
Std Test AUC: 0.0603
------------------------------------------------------------
Round 17 time cost: 4.29s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 18)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7857
  Best client accuracy (ACC(t)): 0.8547
  Global average accuracy (ACC(t)): 0.7999

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 19: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 18 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4366
Averaged Test Accuracy: 0.7999
Averaged Test AUC: 0.7503
Averaged Test Precision: 0.7922
Averaged Test Recall: 0.7999
Averaged Test F1-Score: 0.7722
Std Test Accuracy: 0.0497
Std Test AUC: 0.0603
------------------------------------------------------------
Round 18 time cost: 4.50s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 19)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7859
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8021

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 20: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 19 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4362
Averaged Test Accuracy: 0.8021
Averaged Test AUC: 0.7506
Averaged Test Precision: 0.7948
Averaged Test Recall: 0.8021
Averaged Test F1-Score: 0.7744
Std Test Accuracy: 0.0476
Std Test AUC: 0.0608
------------------------------------------------------------
Round 19 time cost: 4.61s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 20)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 21: ˥�� 10% (��2��)
    Base: 0.8257 �� Decayed: 0.7432 �� Final: 0.7432
  Current threshold (based on ACC(t-1)): 0.7432
  Best client accuracy (ACC(t)): 0.8547
  Global average accuracy (ACC(t)): 0.8036

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 20):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 21: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 20 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4354
Averaged Test Accuracy: 0.8036
Averaged Test AUC: 0.7502
Averaged Test Precision: 0.7975
Averaged Test Recall: 0.8036
Averaged Test F1-Score: 0.7765
Std Test Accuracy: 0.0475
Std Test AUC: 0.0604
------------------------------------------------------------
Round 20 time cost: 4.55s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 21)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7462
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8020

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 22: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 21 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4339
Averaged Test Accuracy: 0.8020
Averaged Test AUC: 0.7508
Averaged Test Precision: 0.7918
Averaged Test Recall: 0.8020
Averaged Test F1-Score: 0.7749
Std Test Accuracy: 0.0481
Std Test AUC: 0.0597
------------------------------------------------------------
Round 21 time cost: 4.40s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 22)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7443
  Best client accuracy (ACC(t)): 0.8547
  Global average accuracy (ACC(t)): 0.8013

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 23: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 22 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4343
Averaged Test Accuracy: 0.8013
Averaged Test AUC: 0.7520
Averaged Test Precision: 0.7940
Averaged Test Recall: 0.8013
Averaged Test F1-Score: 0.7740
Std Test Accuracy: 0.0496
Std Test AUC: 0.0575
------------------------------------------------------------
Round 22 time cost: 4.72s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 23)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7452
  Best client accuracy (ACC(t)): 0.8533
  Global average accuracy (ACC(t)): 0.8015

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 24: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 23 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4347
Averaged Test Accuracy: 0.8015
Averaged Test AUC: 0.7531
Averaged Test Precision: 0.7967
Averaged Test Recall: 0.8015
Averaged Test F1-Score: 0.7737
Std Test Accuracy: 0.0491
Std Test AUC: 0.0578
------------------------------------------------------------
Round 23 time cost: 4.30s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 24)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7447
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8007

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 25: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 24 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4330
Averaged Test Accuracy: 0.8007
Averaged Test AUC: 0.7534
Averaged Test Precision: 0.7936
Averaged Test Recall: 0.8007
Averaged Test F1-Score: 0.7725
Std Test Accuracy: 0.0491
Std Test AUC: 0.0574
------------------------------------------------------------
Round 24 time cost: 4.35s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 25)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 26: ˥�� 15% (��3��)
    Base: 0.8250 �� Decayed: 0.7013 �� Final: 0.7013
  Current threshold (based on ACC(t-1)): 0.7013
  Best client accuracy (ACC(t)): 0.8547
  Global average accuracy (ACC(t)): 0.8023

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 25):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 26: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 25 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4326
Averaged Test Accuracy: 0.8023
Averaged Test AUC: 0.7538
Averaged Test Precision: 0.7964
Averaged Test Recall: 0.8023
Averaged Test F1-Score: 0.7759
Std Test Accuracy: 0.0518
Std Test AUC: 0.0571
------------------------------------------------------------
Round 25 time cost: 4.55s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 26)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7042
  Best client accuracy (ACC(t)): 0.8573
  Global average accuracy (ACC(t)): 0.8037

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 27: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 26 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4315
Averaged Test Accuracy: 0.8037
Averaged Test AUC: 0.7550
Averaged Test Precision: 0.7982
Averaged Test Recall: 0.8037
Averaged Test F1-Score: 0.7783
Std Test Accuracy: 0.0509
Std Test AUC: 0.0577
------------------------------------------------------------
Round 26 time cost: 4.64s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 27)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7060
  Best client accuracy (ACC(t)): 0.8547
  Global average accuracy (ACC(t)): 0.8036

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 28: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 27 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4311
Averaged Test Accuracy: 0.8036
Averaged Test AUC: 0.7547
Averaged Test Precision: 0.7954
Averaged Test Recall: 0.8036
Averaged Test F1-Score: 0.7786
Std Test Accuracy: 0.0488
Std Test AUC: 0.0563
------------------------------------------------------------
Round 27 time cost: 4.52s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 28)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7048
  Best client accuracy (ACC(t)): 0.8547
  Global average accuracy (ACC(t)): 0.8045

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 29: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 28 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4314
Averaged Test Accuracy: 0.8045
Averaged Test AUC: 0.7550
Averaged Test Precision: 0.7950
Averaged Test Recall: 0.8045
Averaged Test F1-Score: 0.7768
Std Test Accuracy: 0.0475
Std Test AUC: 0.0575
------------------------------------------------------------
Round 28 time cost: 4.50s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 29)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7052
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.8016

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 30: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 29 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4293
Averaged Test Accuracy: 0.8016
Averaged Test AUC: 0.7552
Averaged Test Precision: 0.7913
Averaged Test Recall: 0.8016
Averaged Test F1-Score: 0.7766
Std Test Accuracy: 0.0481
Std Test AUC: 0.0567
------------------------------------------------------------
Round 29 time cost: 4.10s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 30)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 8] ��ͣ��� (��ǰ׼ȷ��: 0.8000)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6852
       ��29��: 0.7947 >= 0.6852 [+]
       ��30��: 0.7973 >= 0.6852 [+]
       ��31��: 0.8000 >= 0.6852 [+]
    [+] ����(3): �������ȶ� (0.0053 <= 0.0200)
       ���3��: ['0.7947', '0.7973', '0.8000']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 8 reached early stopping criteria (Round 31):
    - Accuracy: 0.8000 (threshold: 0.7052)
    - Fluctuation: 0.0053 (last 3 rounds)
    - History: ['0.795', '0.797', '0.800']
  [Virtual Data] Generating and locking virtual data for client 8...
  [Mentor Mode] Client 8 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 8 early stopped at round 30
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 6] ��ͣ��� (��ǰ׼ȷ��: 0.8507)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6852
       ��29��: 0.8547 >= 0.6852 [+]
       ��30��: 0.8480 >= 0.6852 [+]
       ��31��: 0.8507 >= 0.6852 [+]
    [+] ����(3): �������ȶ� (0.0067 <= 0.0200)
       ���3��: ['0.8547', '0.8480', '0.8507']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 6 reached early stopping criteria (Round 31):
    - Accuracy: 0.8507 (threshold: 0.7052)
    - Fluctuation: 0.0067 (last 3 rounds)
    - History: ['0.855', '0.848', '0.851']
  [Virtual Data] Generating and locking virtual data for client 6...
  [Mentor Mode] Client 6 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 6 early stopped at round 30
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 5] ��ͣ��� (��ǰ׼ȷ��: 0.7120)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6852
       ��29��: 0.7227 >= 0.6852 [+]
       ��30��: 0.7107 >= 0.6852 [+]
       ��31��: 0.7120 >= 0.6852 [+]
    [+] ����(3): �������ȶ� (0.0120 <= 0.0200)
       ���3��: ['0.7227', '0.7107', '0.7120']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 5 reached early stopping criteria (Round 31):
    - Accuracy: 0.7120 (threshold: 0.7052)
    - Fluctuation: 0.0120 (last 3 rounds)
    - History: ['0.723', '0.711', '0.712']
  [Virtual Data] Generating and locking virtual data for client 5...
  [Mentor Mode] Client 5 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 5 early stopped at round 30
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 1] ��ͣ��� (��ǰ׼ȷ��: 0.8480)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6852
       ��29��: 0.8440 >= 0.6852 [+]
       ��30��: 0.8440 >= 0.6852 [+]
       ��31��: 0.8480 >= 0.6852 [+]
    [+] ����(3): �������ȶ� (0.0040 <= 0.0200)
       ���3��: ['0.8440', '0.8440', '0.8480']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 1 reached early stopping criteria (Round 31):
    - Accuracy: 0.8480 (threshold: 0.7052)
    - Fluctuation: 0.0040 (last 3 rounds)
    - History: ['0.844', '0.844', '0.848']
  [Virtual Data] Generating and locking virtual data for client 1...
  [Mentor Mode] Client 1 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 1 early stopped at round 30
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 7] ��ͣ��� (��ǰ׼ȷ��: 0.7293)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6852
       ��29��: 0.7280 >= 0.6852 [+]
       ��30��: 0.7293 >= 0.6852 [+]
       ��31��: 0.7293 >= 0.6852 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.7280', '0.7293', '0.7293']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 7 reached early stopping criteria (Round 31):
    - Accuracy: 0.7293 (threshold: 0.7052)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.728', '0.729', '0.729']
  [Virtual Data] Generating and locking virtual data for client 7...
  [Mentor Mode] Client 7 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 7 early stopped at round 30
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 0] ��ͣ��� (��ǰ׼ȷ��: 0.8427)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6852
       ��29��: 0.8480 >= 0.6852 [+]
       ��30��: 0.8413 >= 0.6852 [+]
       ��31��: 0.8427 >= 0.6852 [+]
    [+] ����(3): �������ȶ� (0.0067 <= 0.0200)
       ���3��: ['0.8480', '0.8413', '0.8427']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 0 reached early stopping criteria (Round 31):
    - Accuracy: 0.8427 (threshold: 0.7052)
    - Fluctuation: 0.0067 (last 3 rounds)
    - History: ['0.848', '0.841', '0.843']
  [Virtual Data] Generating and locking virtual data for client 0...
  [Mentor Mode] Client 0 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 0 early stopped at round 30
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 2] ��ͣ��� (��ǰ׼ȷ��: 0.7853)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6852
       ��29��: 0.7907 >= 0.6852 [+]
       ��30��: 0.7893 >= 0.6852 [+]
       ��31��: 0.7853 >= 0.6852 [+]
    [+] ����(3): �������ȶ� (0.0053 <= 0.0200)
       ���3��: ['0.7907', '0.7893', '0.7853']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 2 reached early stopping criteria (Round 31):
    - Accuracy: 0.7853 (threshold: 0.7052)
    - Fluctuation: 0.0053 (last 3 rounds)
    - History: ['0.791', '0.789', '0.785']
  [Virtual Data] Generating and locking virtual data for client 2...
  [Mentor Mode] Client 2 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 2 early stopped at round 30
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 3] ��ͣ��� (��ǰ׼ȷ��: 0.7773)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6852
       ��29��: 0.7773 >= 0.6852 [+]
       ��30��: 0.7747 >= 0.6852 [+]
       ��31��: 0.7773 >= 0.6852 [+]
    [+] ����(3): �������ȶ� (0.0027 <= 0.0200)
       ���3��: ['0.7773', '0.7747', '0.7773']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 3 reached early stopping criteria (Round 31):
    - Accuracy: 0.7773 (threshold: 0.7052)
    - Fluctuation: 0.0027 (last 3 rounds)
    - History: ['0.777', '0.775', '0.777']
  [Virtual Data] Generating and locking virtual data for client 3...
  [Mentor Mode] Client 3 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 3 early stopped at round 30
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 9] ��ͣ��� (��ǰ׼ȷ��: 0.8507)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6852
       ��29��: 0.8507 >= 0.6852 [+]
       ��30��: 0.8493 >= 0.6852 [+]
       ��31��: 0.8507 >= 0.6852 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.8507', '0.8493', '0.8507']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 9 reached early stopping criteria (Round 31):
    - Accuracy: 0.8507 (threshold: 0.7052)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.851', '0.849', '0.851']
  [Virtual Data] Generating and locking virtual data for client 9...
  [Mentor Mode] Client 9 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 9 early stopped at round 30
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 4] ��ͣ��� (��ǰ׼ȷ��: 0.8360)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6852
       ��29��: 0.8347 >= 0.6852 [+]
       ��30��: 0.8320 >= 0.6852 [+]
       ��31��: 0.8360 >= 0.6852 [+]
    [+] ����(3): �������ȶ� (0.0040 <= 0.0200)
       ���3��: ['0.8347', '0.8320', '0.8360']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 4 reached early stopping criteria (Round 31):
    - Accuracy: 0.8360 (threshold: 0.7052)
    - Fluctuation: 0.0040 (last 3 rounds)
    - History: ['0.835', '0.832', '0.836']
  [Virtual Data] Generating and locking virtual data for client 4...
  [Mentor Mode] Client 4 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 4 early stopped at round 30
  [Threshold Decay] Round 31: ˥�� 20% (��4��)
    Base: 0.8255 �� Decayed: 0.6604 �� Final: 0.6604
  Current threshold (based on ACC(t-1)): 0.6604
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8032

  [Adaptive Decay] Ȩ��˥���������� (Round 31):
  ��ǰȫ��׼ȷ��: 0.8032
  ˥��ǿ�Ȧ�: 0.5
    Client 8: ��31�ִ��
      ���ʱ׼ȷ��: 0.8032
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 6: ��31�ִ��
      ���ʱ׼ȷ��: 0.8032
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 5: ��31�ִ��
      ���ʱ׼ȷ��: 0.8032
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 1: ��31�ִ��
      ���ʱ׼ȷ��: 0.8032
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 7: ��31�ִ��
      ���ʱ׼ȷ��: 0.8032
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 0: ��31�ִ��
      ���ʱ׼ȷ��: 0.8032
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 2: ��31�ִ��
      ���ʱ׼ȷ��: 0.8032
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 3: ��31�ִ��
      ���ʱ׼ȷ��: 0.8032
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 9: ��31�ִ��
      ���ʱ׼ȷ��: 0.8032
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 4: ��31�ִ��
      ���ʱ׼ȷ��: 0.8032
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
  Early-stopped clients: 10/10
  Active training clients: 0

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 30):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 1   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 2   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 3   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 4   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 5   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 6   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 7   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 8   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 9   2250        1.0000        2250.00         0.1000          ��ͣ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  [Adaptive Decay] Prototype aggregation weights: C0=1.000 C1=1.000 C2=1.000 C3=1.000 C4=1.000 ... (10 total)
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

================================================================================
[Phase Transition Check] Round 31 (Phase 1: ���50��)
================================================================================
���Ҫ��: 7/10 �ͻ��� (70%)
��ǰ״̬: 10/10 �ͻ��˴��

�ͻ�����ϸ״̬:

[+] �Ѵ��ͻ��� (10��):
  Client 6: 0.8507 [+]
  Client 9: 0.8507 [+]
  Client 1: 0.8480 [+]
  Client 0: 0.8427 [+]
  Client 4: 0.8360 [+]
  Client 8: 0.8000 [+]
  Client 2: 0.7853 [+]
  Client 3: 0.7773 [+]
  Client 7: 0.7293 [+]
  Client 5: 0.7120 [+]

��ǰ��ֵ: 0.6604
ƽ��׼ȷ��: 0.8032
���׼ȷ��: 0.8507
================================================================================

[>>] Phase Transition Triggered! (70% Threshold Strategy)
   Qualified clients: 10/10
   Required: 7 (70%)
   Remaining: 0 clients will join dynamically in Phase 2
   Phase 1 completed: 31 rounds (min: 30, max: 50)
================================================================================


============================================================
PHASE TRANSITION: Phase 1 �� Phase 2
============================================================
Virtual data pool size: 0
Phase 2 Algorithm: FEDAVG
Phase 2 Max Rounds: 50
============================================================

  [Algorithm Name] Updated: FedGpro �� FedGpro-FedAvg
  Client 0: Phase 2 (already contributed virtual data)
  Client 1: Phase 2 (already contributed virtual data)
  Client 2: Phase 2 (already contributed virtual data)
  Client 3: Phase 2 (already contributed virtual data)
  Client 4: Phase 2 (already contributed virtual data)
  Client 5: Phase 2 (already contributed virtual data)
  Client 6: Phase 2 (already contributed virtual data)
  Client 7: Phase 2 (already contributed virtual data)
  Client 8: Phase 2 (already contributed virtual data)
  Client 9: Phase 2 (already contributed virtual data)
[OK] Phase 2 initialized successfully!
   Algorithm: FEDAVG
   All clients enter Phase 2: 10 (100%)
   - Already contributed virtual data: 10 (100%)
   - Can still contribute (until round 20): 0 (0%)
   Virtual data pool size: 0 samples
   Phase 1 will continue in parallel until round 20


============================================================
Round 30 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 5.6831
Averaged Test Accuracy (Personalized): 0.3271
Averaged Test AUC (Personalized): 0.6104
Std Test Accuracy (Personalized): 0.1058
Std Test AUC (Personalized): 0.0590

Evaluate global model (Reference only)
Averaged Train Loss: 0.4302
Averaged Test Accuracy: 0.8032
Averaged Test AUC: 0.7546
Averaged Test Precision: 0.7953
Averaged Test Recall: 0.8032
Averaged Test F1-Score: 0.7768
Std Test Accuracy: 0.0489
Std Test AUC: 0.0565
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 30 time cost: 5.07s
------------------------------------------------------------

[Phase 2 - Round 31] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 31 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 1.1244
Averaged Test Accuracy (Personalized): 0.5221
Averaged Test AUC (Personalized): 0.6360
Std Test Accuracy (Personalized): 0.0437
Std Test AUC (Personalized): 0.0642

Evaluate global model (Reference only)
Averaged Train Loss: 0.8636
Averaged Test Accuracy: 0.6163
Averaged Test AUC: 0.6413
Averaged Test Precision: 0.7157
Averaged Test Recall: 0.6163
Averaged Test F1-Score: 0.6438
Std Test Accuracy: 0.0380
Std Test AUC: 0.0681
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 31 time cost: 4.41s
------------------------------------------------------------

[Phase 2 - Round 32] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 32 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.7950
Averaged Test Accuracy (Personalized): 0.6544
Averaged Test AUC (Personalized): 0.6434
Std Test Accuracy (Personalized): 0.0283
Std Test AUC (Personalized): 0.0685

Evaluate global model (Reference only)
Averaged Train Loss: 0.5771
Averaged Test Accuracy: 0.7523
Averaged Test AUC: 0.6392
Averaged Test Precision: 0.7204
Averaged Test Recall: 0.7523
Averaged Test F1-Score: 0.7281
Std Test Accuracy: 0.0518
Std Test AUC: 0.0639
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 32 time cost: 4.45s
------------------------------------------------------------

[Phase 2 - Round 33] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 33 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.6311
Averaged Test Accuracy (Personalized): 0.7369
Averaged Test AUC (Personalized): 0.6458
Std Test Accuracy (Personalized): 0.0487
Std Test AUC (Personalized): 0.0723

Evaluate global model (Reference only)
Averaged Train Loss: 0.5448
Averaged Test Accuracy: 0.7637
Averaged Test AUC: 0.6381
Averaged Test Precision: 0.7329
Averaged Test Recall: 0.7637
Averaged Test F1-Score: 0.7118
Std Test Accuracy: 0.0656
Std Test AUC: 0.0667
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 33 time cost: 4.47s
------------------------------------------------------------

[Phase 2 - Round 34] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 34 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5770
Averaged Test Accuracy (Personalized): 0.7615
Averaged Test AUC (Personalized): 0.6420
Std Test Accuracy (Personalized): 0.0511
Std Test AUC (Personalized): 0.0705

Evaluate global model (Reference only)
Averaged Train Loss: 0.5389
Averaged Test Accuracy: 0.7613
Averaged Test AUC: 0.6414
Averaged Test Precision: 0.7285
Averaged Test Recall: 0.7613
Averaged Test F1-Score: 0.6999
Std Test Accuracy: 0.0694
Std Test AUC: 0.0725
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 34 time cost: 4.45s
------------------------------------------------------------

[Phase 2 - Round 35] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 35 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5538
Averaged Test Accuracy (Personalized): 0.7708
Averaged Test AUC (Personalized): 0.6385
Std Test Accuracy (Personalized): 0.0549
Std Test AUC (Personalized): 0.0713

Evaluate global model (Reference only)
Averaged Train Loss: 0.5338
Averaged Test Accuracy: 0.7601
Averaged Test AUC: 0.6526
Averaged Test Precision: 0.7299
Averaged Test Recall: 0.7601
Averaged Test F1-Score: 0.6965
Std Test Accuracy: 0.0704
Std Test AUC: 0.0682
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 35 time cost: 4.50s
------------------------------------------------------------

[Phase 2 - Round 36] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 36 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5472
Averaged Test Accuracy (Personalized): 0.7703
Averaged Test AUC (Personalized): 0.6393
Std Test Accuracy (Personalized): 0.0576
Std Test AUC (Personalized): 0.0729

Evaluate global model (Reference only)
Averaged Train Loss: 0.5256
Averaged Test Accuracy: 0.7623
Averaged Test AUC: 0.6579
Averaged Test Precision: 0.7427
Averaged Test Recall: 0.7623
Averaged Test F1-Score: 0.6995
Std Test Accuracy: 0.0696
Std Test AUC: 0.0689
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 36 time cost: 4.55s
------------------------------------------------------------

[Phase 2 - Round 37] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 37 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5426
Averaged Test Accuracy (Personalized): 0.7715
Averaged Test AUC (Personalized): 0.6392
Std Test Accuracy (Personalized): 0.0592
Std Test AUC (Personalized): 0.0724

Evaluate global model (Reference only)
Averaged Train Loss: 0.5205
Averaged Test Accuracy: 0.7627
Averaged Test AUC: 0.6636
Averaged Test Precision: 0.7494
Averaged Test Recall: 0.7627
Averaged Test F1-Score: 0.6986
Std Test Accuracy: 0.0693
Std Test AUC: 0.0727
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 37 time cost: 4.43s
------------------------------------------------------------

[Phase 2 - Round 38] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 38 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5394
Averaged Test Accuracy (Personalized): 0.7679
Averaged Test AUC (Personalized): 0.6388
Std Test Accuracy (Personalized): 0.0628
Std Test AUC (Personalized): 0.0723

Evaluate global model (Reference only)
Averaged Train Loss: 0.5171
Averaged Test Accuracy: 0.7624
Averaged Test AUC: 0.6705
Averaged Test Precision: 0.7442
Averaged Test Recall: 0.7624
Averaged Test F1-Score: 0.6974
Std Test Accuracy: 0.0688
Std Test AUC: 0.0723
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 38 time cost: 4.36s
------------------------------------------------------------

[Phase 2 - Round 39] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 39 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5361
Averaged Test Accuracy (Personalized): 0.7680
Averaged Test AUC (Personalized): 0.6413
Std Test Accuracy (Personalized): 0.0625
Std Test AUC (Personalized): 0.0741

Evaluate global model (Reference only)
Averaged Train Loss: 0.5154
Averaged Test Accuracy: 0.7607
Averaged Test AUC: 0.6746
Averaged Test Precision: 0.7360
Averaged Test Recall: 0.7607
Averaged Test F1-Score: 0.6926
Std Test Accuracy: 0.0707
Std Test AUC: 0.0741
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 39 time cost: 4.55s
------------------------------------------------------------

[Phase 2 - Round 40] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 40 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5334
Averaged Test Accuracy (Personalized): 0.7692
Averaged Test AUC (Personalized): 0.6453
Std Test Accuracy (Personalized): 0.0608
Std Test AUC (Personalized): 0.0753

Evaluate global model (Reference only)
Averaged Train Loss: 0.5130
Averaged Test Accuracy: 0.7592
Averaged Test AUC: 0.6770
Averaged Test Precision: 0.7390
Averaged Test Recall: 0.7592
Averaged Test F1-Score: 0.6898
Std Test Accuracy: 0.0728
Std Test AUC: 0.0749
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 40 time cost: 4.26s
------------------------------------------------------------

[Phase 2 - Round 41] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 41 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5319
Averaged Test Accuracy (Personalized): 0.7685
Averaged Test AUC (Personalized): 0.6468
Std Test Accuracy (Personalized): 0.0605
Std Test AUC (Personalized): 0.0742

Evaluate global model (Reference only)
Averaged Train Loss: 0.5103
Averaged Test Accuracy: 0.7617
Averaged Test AUC: 0.6790
Averaged Test Precision: 0.7366
Averaged Test Recall: 0.7617
Averaged Test F1-Score: 0.6938
Std Test Accuracy: 0.0701
Std Test AUC: 0.0742
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 41 time cost: 4.53s
------------------------------------------------------------

[Phase 2 - Round 42] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 42 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5288
Averaged Test Accuracy (Personalized): 0.7697
Averaged Test AUC (Personalized): 0.6505
Std Test Accuracy (Personalized): 0.0588
Std Test AUC (Personalized): 0.0758

Evaluate global model (Reference only)
Averaged Train Loss: 0.5089
Averaged Test Accuracy: 0.7603
Averaged Test AUC: 0.6854
Averaged Test Precision: 0.7492
Averaged Test Recall: 0.7603
Averaged Test F1-Score: 0.6930
Std Test Accuracy: 0.0711
Std Test AUC: 0.0742
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 42 time cost: 4.51s
------------------------------------------------------------

[Phase 2 - Round 43] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 43 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5262
Averaged Test Accuracy (Personalized): 0.7708
Averaged Test AUC (Personalized): 0.6514
Std Test Accuracy (Personalized): 0.0589
Std Test AUC (Personalized): 0.0773

Evaluate global model (Reference only)
Averaged Train Loss: 0.5075
Averaged Test Accuracy: 0.7591
Averaged Test AUC: 0.6867
Averaged Test Precision: 0.7469
Averaged Test Recall: 0.7591
Averaged Test F1-Score: 0.6888
Std Test Accuracy: 0.0736
Std Test AUC: 0.0756
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 43 time cost: 4.50s
------------------------------------------------------------

[Phase 2 - Round 44] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 44 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5246
Averaged Test Accuracy (Personalized): 0.7693
Averaged Test AUC (Personalized): 0.6533
Std Test Accuracy (Personalized): 0.0626
Std Test AUC (Personalized): 0.0749

Evaluate global model (Reference only)
Averaged Train Loss: 0.5070
Averaged Test Accuracy: 0.7597
Averaged Test AUC: 0.6885
Averaged Test Precision: 0.7496
Averaged Test Recall: 0.7597
Averaged Test F1-Score: 0.6898
Std Test Accuracy: 0.0732
Std Test AUC: 0.0758
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 44 time cost: 4.48s
------------------------------------------------------------

[Phase 2 - Round 45] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 45 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5209
Averaged Test Accuracy (Personalized): 0.7708
Averaged Test AUC (Personalized): 0.6560
Std Test Accuracy (Personalized): 0.0603
Std Test AUC (Personalized): 0.0788

Evaluate global model (Reference only)
Averaged Train Loss: 0.5054
Averaged Test Accuracy: 0.7600
Averaged Test AUC: 0.6913
Averaged Test Precision: 0.7479
Averaged Test Recall: 0.7600
Averaged Test F1-Score: 0.6893
Std Test Accuracy: 0.0719
Std Test AUC: 0.0773
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 45 time cost: 4.15s
------------------------------------------------------------

[Phase 2 - Round 46] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 46 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5210
Averaged Test Accuracy (Personalized): 0.7708
Averaged Test AUC (Personalized): 0.6550
Std Test Accuracy (Personalized): 0.0612
Std Test AUC (Personalized): 0.0769

Evaluate global model (Reference only)
Averaged Train Loss: 0.5034
Averaged Test Accuracy: 0.7617
Averaged Test AUC: 0.6925
Averaged Test Precision: 0.7545
Averaged Test Recall: 0.7617
Averaged Test F1-Score: 0.6932
Std Test Accuracy: 0.0707
Std Test AUC: 0.0763
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 46 time cost: 4.17s
------------------------------------------------------------

[Phase 2 - Round 47] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 47 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5187
Averaged Test Accuracy (Personalized): 0.7725
Averaged Test AUC (Personalized): 0.6595
Std Test Accuracy (Personalized): 0.0578
Std Test AUC (Personalized): 0.0781

Evaluate global model (Reference only)
Averaged Train Loss: 0.5019
Averaged Test Accuracy: 0.7637
Averaged Test AUC: 0.6977
Averaged Test Precision: 0.7573
Averaged Test Recall: 0.7637
Averaged Test F1-Score: 0.6960
Std Test Accuracy: 0.0695
Std Test AUC: 0.0776
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 47 time cost: 4.63s
------------------------------------------------------------

[Phase 2 - Round 48] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 48 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5161
Averaged Test Accuracy (Personalized): 0.7713
Averaged Test AUC (Personalized): 0.6627
Std Test Accuracy (Personalized): 0.0594
Std Test AUC (Personalized): 0.0770

Evaluate global model (Reference only)
Averaged Train Loss: 0.4996
Averaged Test Accuracy: 0.7656
Averaged Test AUC: 0.6984
Averaged Test Precision: 0.7658
Averaged Test Recall: 0.7656
Averaged Test F1-Score: 0.7008
Std Test Accuracy: 0.0662
Std Test AUC: 0.0779
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 48 time cost: 4.53s
------------------------------------------------------------

[Phase 2 - Round 49] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 49 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5136
Averaged Test Accuracy (Personalized): 0.7704
Averaged Test AUC (Personalized): 0.6634
Std Test Accuracy (Personalized): 0.0595
Std Test AUC (Personalized): 0.0783

Evaluate global model (Reference only)
Averaged Train Loss: 0.4988
Averaged Test Accuracy: 0.7664
Averaged Test AUC: 0.7002
Averaged Test Precision: 0.7613
Averaged Test Recall: 0.7664
Averaged Test F1-Score: 0.7018
Std Test Accuracy: 0.0676
Std Test AUC: 0.0773
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 49 time cost: 4.43s
------------------------------------------------------------

[Phase 2 - Round 50] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 50 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5112
Averaged Test Accuracy (Personalized): 0.7731
Averaged Test AUC (Personalized): 0.6668
Std Test Accuracy (Personalized): 0.0576
Std Test AUC (Personalized): 0.0777

Evaluate global model (Reference only)
Averaged Train Loss: 0.4973
Averaged Test Accuracy: 0.7673
Averaged Test AUC: 0.7031
Averaged Test Precision: 0.7545
Averaged Test Recall: 0.7673
Averaged Test F1-Score: 0.7045
Std Test Accuracy: 0.0639
Std Test AUC: 0.0774
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 50 time cost: 4.62s
------------------------------------------------------------

[Phase 2 - Round 51] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 51 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5090
Averaged Test Accuracy (Personalized): 0.7757
Averaged Test AUC (Personalized): 0.6683
Std Test Accuracy (Personalized): 0.0560
Std Test AUC (Personalized): 0.0768

Evaluate global model (Reference only)
Averaged Train Loss: 0.4948
Averaged Test Accuracy: 0.7725
Averaged Test AUC: 0.7041
Averaged Test Precision: 0.7562
Averaged Test Recall: 0.7725
Averaged Test F1-Score: 0.7127
Std Test Accuracy: 0.0593
Std Test AUC: 0.0770
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 51 time cost: 4.47s
------------------------------------------------------------

[Phase 2 - Round 52] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 52 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5091
Averaged Test Accuracy (Personalized): 0.7727
Averaged Test AUC (Personalized): 0.6690
Std Test Accuracy (Personalized): 0.0594
Std Test AUC (Personalized): 0.0776

Evaluate global model (Reference only)
Averaged Train Loss: 0.4943
Averaged Test Accuracy: 0.7712
Averaged Test AUC: 0.7063
Averaged Test Precision: 0.7556
Averaged Test Recall: 0.7712
Averaged Test F1-Score: 0.7112
Std Test Accuracy: 0.0612
Std Test AUC: 0.0767
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 52 time cost: 4.51s
------------------------------------------------------------

[Phase 2 - Round 53] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 53 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5062
Averaged Test Accuracy (Personalized): 0.7729
Averaged Test AUC (Personalized): 0.6707
Std Test Accuracy (Personalized): 0.0599
Std Test AUC (Personalized): 0.0773

Evaluate global model (Reference only)
Averaged Train Loss: 0.4914
Averaged Test Accuracy: 0.7767
Averaged Test AUC: 0.7081
Averaged Test Precision: 0.7600
Averaged Test Recall: 0.7767
Averaged Test F1-Score: 0.7191
Std Test Accuracy: 0.0537
Std Test AUC: 0.0769
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 53 time cost: 4.44s
------------------------------------------------------------

[Phase 2 - Round 54] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 54 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5054
Averaged Test Accuracy (Personalized): 0.7760
Averaged Test AUC (Personalized): 0.6727
Std Test Accuracy (Personalized): 0.0556
Std Test AUC (Personalized): 0.0770

Evaluate global model (Reference only)
Averaged Train Loss: 0.4901
Averaged Test Accuracy: 0.7780
Averaged Test AUC: 0.7085
Averaged Test Precision: 0.7563
Averaged Test Recall: 0.7780
Averaged Test F1-Score: 0.7212
Std Test Accuracy: 0.0531
Std Test AUC: 0.0775
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 54 time cost: 4.35s
------------------------------------------------------------

[Phase 2 - Round 55] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 55 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5031
Averaged Test Accuracy (Personalized): 0.7753
Averaged Test AUC (Personalized): 0.6751
Std Test Accuracy (Personalized): 0.0573
Std Test AUC (Personalized): 0.0785

Evaluate global model (Reference only)
Averaged Train Loss: 0.4893
Averaged Test Accuracy: 0.7791
Averaged Test AUC: 0.7104
Averaged Test Precision: 0.7682
Averaged Test Recall: 0.7791
Averaged Test F1-Score: 0.7228
Std Test Accuracy: 0.0525
Std Test AUC: 0.0766
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 55 time cost: 4.45s
------------------------------------------------------------

[Phase 2 - Round 56] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 56 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5028
Averaged Test Accuracy (Personalized): 0.7749
Averaged Test AUC (Personalized): 0.6766
Std Test Accuracy (Personalized): 0.0578
Std Test AUC (Personalized): 0.0777

Evaluate global model (Reference only)
Averaged Train Loss: 0.4862
Averaged Test Accuracy: 0.7815
Averaged Test AUC: 0.7125
Averaged Test Precision: 0.7660
Averaged Test Recall: 0.7815
Averaged Test F1-Score: 0.7267
Std Test Accuracy: 0.0496
Std Test AUC: 0.0768
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 56 time cost: 4.44s
------------------------------------------------------------

[Phase 2 - Round 57] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 57 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5015
Averaged Test Accuracy (Personalized): 0.7745
Averaged Test AUC (Personalized): 0.6762
Std Test Accuracy (Personalized): 0.0588
Std Test AUC (Personalized): 0.0776

Evaluate global model (Reference only)
Averaged Train Loss: 0.4856
Averaged Test Accuracy: 0.7817
Averaged Test AUC: 0.7128
Averaged Test Precision: 0.7691
Averaged Test Recall: 0.7817
Averaged Test F1-Score: 0.7272
Std Test Accuracy: 0.0491
Std Test AUC: 0.0769
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 57 time cost: 4.51s
------------------------------------------------------------

[Phase 2 - Round 58] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 58 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.5005
Averaged Test Accuracy (Personalized): 0.7764
Averaged Test AUC (Personalized): 0.6776
Std Test Accuracy (Personalized): 0.0551
Std Test AUC (Personalized): 0.0774

Evaluate global model (Reference only)
Averaged Train Loss: 0.4852
Averaged Test Accuracy: 0.7807
Averaged Test AUC: 0.7148
Averaged Test Precision: 0.7739
Averaged Test Recall: 0.7807
Averaged Test F1-Score: 0.7246
Std Test Accuracy: 0.0504
Std Test AUC: 0.0764
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 58 time cost: 4.56s
------------------------------------------------------------

[Phase 2 - Round 59] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 59 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4979
Averaged Test Accuracy (Personalized): 0.7783
Averaged Test AUC (Personalized): 0.6805
Std Test Accuracy (Personalized): 0.0538
Std Test AUC (Personalized): 0.0769

Evaluate global model (Reference only)
Averaged Train Loss: 0.4838
Averaged Test Accuracy: 0.7839
Averaged Test AUC: 0.7163
Averaged Test Precision: 0.7680
Averaged Test Recall: 0.7839
Averaged Test F1-Score: 0.7293
Std Test Accuracy: 0.0467
Std Test AUC: 0.0765
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 59 time cost: 4.62s
------------------------------------------------------------

[Phase 2 - Round 60] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 60 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4972
Averaged Test Accuracy (Personalized): 0.7779
Averaged Test AUC (Personalized): 0.6812
Std Test Accuracy (Personalized): 0.0537
Std Test AUC (Personalized): 0.0781

Evaluate global model (Reference only)
Averaged Train Loss: 0.4830
Averaged Test Accuracy: 0.7837
Averaged Test AUC: 0.7174
Averaged Test Precision: 0.7623
Averaged Test Recall: 0.7837
Averaged Test F1-Score: 0.7296
Std Test Accuracy: 0.0468
Std Test AUC: 0.0766
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 60 time cost: 4.15s
------------------------------------------------------------

[Phase 2 - Round 61] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 61 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4964
Averaged Test Accuracy (Personalized): 0.7783
Averaged Test AUC (Personalized): 0.6837
Std Test Accuracy (Personalized): 0.0537
Std Test AUC (Personalized): 0.0771

Evaluate global model (Reference only)
Averaged Train Loss: 0.4825
Averaged Test Accuracy: 0.7839
Averaged Test AUC: 0.7175
Averaged Test Precision: 0.7707
Averaged Test Recall: 0.7839
Averaged Test F1-Score: 0.7290
Std Test Accuracy: 0.0472
Std Test AUC: 0.0759
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 61 time cost: 4.46s
------------------------------------------------------------

[Phase 2 - Round 62] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 62 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4958
Averaged Test Accuracy (Personalized): 0.7760
Averaged Test AUC (Personalized): 0.6841
Std Test Accuracy (Personalized): 0.0559
Std Test AUC (Personalized): 0.0773

Evaluate global model (Reference only)
Averaged Train Loss: 0.4829
Averaged Test Accuracy: 0.7821
Averaged Test AUC: 0.7180
Averaged Test Precision: 0.7567
Averaged Test Recall: 0.7821
Averaged Test F1-Score: 0.7269
Std Test Accuracy: 0.0476
Std Test AUC: 0.0758
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 62 time cost: 4.28s
------------------------------------------------------------

[Phase 2 - Round 63] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 63 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4945
Averaged Test Accuracy (Personalized): 0.7783
Averaged Test AUC (Personalized): 0.6862
Std Test Accuracy (Personalized): 0.0528
Std Test AUC (Personalized): 0.0773

Evaluate global model (Reference only)
Averaged Train Loss: 0.4819
Averaged Test Accuracy: 0.7844
Averaged Test AUC: 0.7186
Averaged Test Precision: 0.7710
Averaged Test Recall: 0.7844
Averaged Test F1-Score: 0.7296
Std Test Accuracy: 0.0462
Std Test AUC: 0.0759
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 63 time cost: 4.37s
------------------------------------------------------------

[Phase 2 - Round 64] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 64 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4930
Averaged Test Accuracy (Personalized): 0.7788
Averaged Test AUC (Personalized): 0.6857
Std Test Accuracy (Personalized): 0.0523
Std Test AUC (Personalized): 0.0786

Evaluate global model (Reference only)
Averaged Train Loss: 0.4815
Averaged Test Accuracy: 0.7845
Averaged Test AUC: 0.7187
Averaged Test Precision: 0.7541
Averaged Test Recall: 0.7845
Averaged Test F1-Score: 0.7297
Std Test Accuracy: 0.0453
Std Test AUC: 0.0753
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 64 time cost: 4.56s
------------------------------------------------------------

[Phase 2 - Round 65] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 65 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4934
Averaged Test Accuracy (Personalized): 0.7757
Averaged Test AUC (Personalized): 0.6881
Std Test Accuracy (Personalized): 0.0556
Std Test AUC (Personalized): 0.0783

Evaluate global model (Reference only)
Averaged Train Loss: 0.4809
Averaged Test Accuracy: 0.7845
Averaged Test AUC: 0.7205
Averaged Test Precision: 0.7723
Averaged Test Recall: 0.7845
Averaged Test F1-Score: 0.7298
Std Test Accuracy: 0.0469
Std Test AUC: 0.0753
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 65 time cost: 4.52s
------------------------------------------------------------

[Phase 2 - Round 66] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 66 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4919
Averaged Test Accuracy (Personalized): 0.7767
Averaged Test AUC (Personalized): 0.6900
Std Test Accuracy (Personalized): 0.0532
Std Test AUC (Personalized): 0.0795

Evaluate global model (Reference only)
Averaged Train Loss: 0.4815
Averaged Test Accuracy: 0.7816
Averaged Test AUC: 0.7204
Averaged Test Precision: 0.7645
Averaged Test Recall: 0.7816
Averaged Test F1-Score: 0.7259
Std Test Accuracy: 0.0486
Std Test AUC: 0.0758
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 66 time cost: 4.54s
------------------------------------------------------------

[Phase 2 - Round 67] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 67 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4905
Averaged Test Accuracy (Personalized): 0.7787
Averaged Test AUC (Personalized): 0.6903
Std Test Accuracy (Personalized): 0.0534
Std Test AUC (Personalized): 0.0774

Evaluate global model (Reference only)
Averaged Train Loss: 0.4802
Averaged Test Accuracy: 0.7841
Averaged Test AUC: 0.7212
Averaged Test Precision: 0.7752
Averaged Test Recall: 0.7841
Averaged Test F1-Score: 0.7287
Std Test Accuracy: 0.0475
Std Test AUC: 0.0754
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 67 time cost: 5.50s
------------------------------------------------------------

[Phase 2 - Round 68] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 68 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4896
Averaged Test Accuracy (Personalized): 0.7783
Averaged Test AUC (Personalized): 0.6921
Std Test Accuracy (Personalized): 0.0531
Std Test AUC (Personalized): 0.0782

Evaluate global model (Reference only)
Averaged Train Loss: 0.4794
Averaged Test Accuracy: 0.7841
Averaged Test AUC: 0.7220
Averaged Test Precision: 0.7613
Averaged Test Recall: 0.7841
Averaged Test F1-Score: 0.7293
Std Test Accuracy: 0.0466
Std Test AUC: 0.0752
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 68 time cost: 4.92s
------------------------------------------------------------

[Phase 2 - Round 69] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 69 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4888
Averaged Test Accuracy (Personalized): 0.7792
Averaged Test AUC (Personalized): 0.6927
Std Test Accuracy (Personalized): 0.0534
Std Test AUC (Personalized): 0.0775

Evaluate global model (Reference only)
Averaged Train Loss: 0.4807
Averaged Test Accuracy: 0.7831
Averaged Test AUC: 0.7216
Averaged Test Precision: 0.7658
Averaged Test Recall: 0.7831
Averaged Test F1-Score: 0.7263
Std Test Accuracy: 0.0486
Std Test AUC: 0.0748
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 69 time cost: 4.78s
------------------------------------------------------------

[Phase 2 - Round 70] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 70 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4878
Averaged Test Accuracy (Personalized): 0.7781
Averaged Test AUC (Personalized): 0.6943
Std Test Accuracy (Personalized): 0.0550
Std Test AUC (Personalized): 0.0785

Evaluate global model (Reference only)
Averaged Train Loss: 0.4791
Averaged Test Accuracy: 0.7865
Averaged Test AUC: 0.7227
Averaged Test Precision: 0.7631
Averaged Test Recall: 0.7865
Averaged Test F1-Score: 0.7323
Std Test Accuracy: 0.0444
Std Test AUC: 0.0743
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 70 time cost: 5.17s
------------------------------------------------------------

[Phase 2 - Round 71] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 71 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4880
Averaged Test Accuracy (Personalized): 0.7799
Averaged Test AUC (Personalized): 0.6946
Std Test Accuracy (Personalized): 0.0519
Std Test AUC (Personalized): 0.0783

Evaluate global model (Reference only)
Averaged Train Loss: 0.4788
Averaged Test Accuracy: 0.7884
Averaged Test AUC: 0.7239
Averaged Test Precision: 0.7572
Averaged Test Recall: 0.7884
Averaged Test F1-Score: 0.7349
Std Test Accuracy: 0.0428
Std Test AUC: 0.0754
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 71 time cost: 4.82s
------------------------------------------------------------

[Phase 2 - Round 72] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 72 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4871
Averaged Test Accuracy (Personalized): 0.7793
Averaged Test AUC (Personalized): 0.6954
Std Test Accuracy (Personalized): 0.0527
Std Test AUC (Personalized): 0.0795

Evaluate global model (Reference only)
Averaged Train Loss: 0.4791
Averaged Test Accuracy: 0.7847
Averaged Test AUC: 0.7237
Averaged Test Precision: 0.7619
Averaged Test Recall: 0.7847
Averaged Test F1-Score: 0.7299
Std Test Accuracy: 0.0458
Std Test AUC: 0.0762
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 72 time cost: 4.95s
------------------------------------------------------------

[Phase 2 - Round 73] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 73 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4858
Averaged Test Accuracy (Personalized): 0.7800
Averaged Test AUC (Personalized): 0.6955
Std Test Accuracy (Personalized): 0.0530
Std Test AUC (Personalized): 0.0778

Evaluate global model (Reference only)
Averaged Train Loss: 0.4783
Averaged Test Accuracy: 0.7857
Averaged Test AUC: 0.7245
Averaged Test Precision: 0.7738
Averaged Test Recall: 0.7857
Averaged Test F1-Score: 0.7319
Std Test Accuracy: 0.0445
Std Test AUC: 0.0749
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 73 time cost: 4.97s
------------------------------------------------------------

[Phase 2 - Round 74] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 74 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4863
Averaged Test Accuracy (Personalized): 0.7815
Averaged Test AUC (Personalized): 0.6970
Std Test Accuracy (Personalized): 0.0500
Std Test AUC (Personalized): 0.0786

Evaluate global model (Reference only)
Averaged Train Loss: 0.4779
Averaged Test Accuracy: 0.7853
Averaged Test AUC: 0.7252
Averaged Test Precision: 0.7776
Averaged Test Recall: 0.7853
Averaged Test F1-Score: 0.7313
Std Test Accuracy: 0.0450
Std Test AUC: 0.0750
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 74 time cost: 4.73s
------------------------------------------------------------

[Phase 2 - Round 75] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 75 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4845
Averaged Test Accuracy (Personalized): 0.7817
Averaged Test AUC (Personalized): 0.6967
Std Test Accuracy (Personalized): 0.0499
Std Test AUC (Personalized): 0.0788

Evaluate global model (Reference only)
Averaged Train Loss: 0.4777
Averaged Test Accuracy: 0.7840
Averaged Test AUC: 0.7254
Averaged Test Precision: 0.7653
Averaged Test Recall: 0.7840
Averaged Test F1-Score: 0.7296
Std Test Accuracy: 0.0455
Std Test AUC: 0.0749
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 75 time cost: 4.88s
------------------------------------------------------------

[Phase 2 - Round 76] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 76 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4850
Averaged Test Accuracy (Personalized): 0.7812
Averaged Test AUC (Personalized): 0.6984
Std Test Accuracy (Personalized): 0.0518
Std Test AUC (Personalized): 0.0785

Evaluate global model (Reference only)
Averaged Train Loss: 0.4774
Averaged Test Accuracy: 0.7859
Averaged Test AUC: 0.7257
Averaged Test Precision: 0.7863
Averaged Test Recall: 0.7859
Averaged Test F1-Score: 0.7319
Std Test Accuracy: 0.0443
Std Test AUC: 0.0761
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 76 time cost: 5.07s
------------------------------------------------------------

[Phase 2 - Round 77] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 77 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4846
Averaged Test Accuracy (Personalized): 0.7820
Averaged Test AUC (Personalized): 0.6997
Std Test Accuracy (Personalized): 0.0499
Std Test AUC (Personalized): 0.0776

Evaluate global model (Reference only)
Averaged Train Loss: 0.4776
Averaged Test Accuracy: 0.7839
Averaged Test AUC: 0.7259
Averaged Test Precision: 0.7759
Averaged Test Recall: 0.7839
Averaged Test F1-Score: 0.7291
Std Test Accuracy: 0.0457
Std Test AUC: 0.0753
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 77 time cost: 4.77s
------------------------------------------------------------

[Phase 2 - Round 78] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 78 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4839
Averaged Test Accuracy (Personalized): 0.7819
Averaged Test AUC (Personalized): 0.6990
Std Test Accuracy (Personalized): 0.0503
Std Test AUC (Personalized): 0.0789

Evaluate global model (Reference only)
Averaged Train Loss: 0.4772
Averaged Test Accuracy: 0.7848
Averaged Test AUC: 0.7257
Averaged Test Precision: 0.7597
Averaged Test Recall: 0.7848
Averaged Test F1-Score: 0.7290
Std Test Accuracy: 0.0466
Std Test AUC: 0.0747
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 78 time cost: 5.11s
------------------------------------------------------------

[Phase 2 - Round 79] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 79 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4834
Averaged Test Accuracy (Personalized): 0.7813
Averaged Test AUC (Personalized): 0.6997
Std Test Accuracy (Personalized): 0.0517
Std Test AUC (Personalized): 0.0789

Evaluate global model (Reference only)
Averaged Train Loss: 0.4762
Averaged Test Accuracy: 0.7841
Averaged Test AUC: 0.7264
Averaged Test Precision: 0.7748
Averaged Test Recall: 0.7841
Averaged Test F1-Score: 0.7301
Std Test Accuracy: 0.0447
Std Test AUC: 0.0749
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 79 time cost: 5.06s
------------------------------------------------------------

[Phase 2 - Round 80] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
  [FedAvg] Weighted average aggregation
[Phase 2] Aggregation complete: FEDAVG

============================================================
Round 80 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4829
Averaged Test Accuracy (Personalized): 0.7817
Averaged Test AUC (Personalized): 0.7012
Std Test Accuracy (Personalized): 0.0502
Std Test AUC (Personalized): 0.0790

Evaluate global model (Reference only)
Averaged Train Loss: 0.4752
Averaged Test Accuracy: 0.7871
Averaged Test AUC: 0.7272
Averaged Test Precision: 0.7793
Averaged Test Recall: 0.7871
Averaged Test F1-Score: 0.7343
Std Test Accuracy: 0.0435
Std Test AUC: 0.0743
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 80 time cost: 4.85s
------------------------------------------------------------

============================================================
Phase 2 completed: 50/50 rounds
============================================================


============================================================
Final Evaluation - Round 81 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 0.4830
Averaged Test Accuracy (Personalized): 0.7817
Averaged Test AUC (Personalized): 0.7012
Std Test Accuracy (Personalized): 0.0502
Std Test AUC (Personalized): 0.0790

Evaluate global model (Reference)
Averaged Train Loss: 0.4758
Averaged Test Accuracy: 0.7871
Averaged Test AUC: 0.7272
Averaged Test Precision: 0.7793
Averaged Test Recall: 0.7871
Averaged Test F1-Score: 0.7343
Std Test Accuracy: 0.0435
Std Test AUC: 0.0743

Best accuracy:
0.8045333333333333

Average time cost:
4.5519690185785295

[FedGpro] Saving results...
  rs_test_acc entries: 82
  rs_test_auc entries: 82
  rs_train_loss entries: 82
  Saving to: system\results\Uci_FedGpro_Ablation_No_VAE_Generation_feature\Uci_FedGpro_Ablation_No_VAE_Generation_feature_3.h5
  [+] Saved h5 file successfully
  Saving CSV to: system\results\Uci_FedGpro_Ablation_No_VAE_Generation_feature\Uci_FedGpro_Ablation_No_VAE_Generation_feature_3_training_process.csv
  [+] Saved CSV file successfully
  [+] Saved npy files successfully

============= Running time: 4th =============
Creating server and clients ...
Auto-selected UciCreditNet for dataset Uci
UciCreditNet(
  (layers): Sequential(
    (0): Linear(in_features=23, out_features=32, bias=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.4, inplace=False)
    (4): Linear(in_features=32, out_features=16, bias=True)
    (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.2, inplace=False)
  )
  (fc): Linear(in_features=16, out_features=2, bias=True)
)
  Client 0: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 1: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 2: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 3: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 4: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 5: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 6: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 7: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 8: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 9: Personalization enabled (mu=0.0, plocal_epochs=1)

============================================================
FedGpro: Federated Global Prototype Learning
============================================================
Join ratio / total clients: 1.0 / 10

Phase 1 Parameters (Max 20 rounds):
  Minimum threshold: 0.6
  Threshold formula:
    ACC(t-1) = (best_acc(t-1) + avg_acc(t-1)) / 2
    threshold(r) = ACC(t-1),                                       if r <= 9
    threshold(r) = max(0.66, ACC(t-1)*(1-0.05*floor((r-10)/5))), if r >= 10
  Training stages:
    - Round 1-10: Forced training (no early stop check, ensure VAE quality)
    - Round 11+: Early stop check + dynamic threshold with time decay
  Phase transition: 70% clients qualified OR 25 rounds reached

Phase 2 Parameters:
  Aggregation: fedavg
  Supported algorithms: fedavg, fedprox, fedscaffold
============================================================

Finished creating server and clients.

[Phase 1] Statistical Collection (Round 0)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.6600
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7783
  Client 0 meets threshold! Generating virtual data...
  Client 0: Privacy disabled, skipping baseline VAE training.
  Client 0: Skipped virtual data generation (ratio=1.0)
  Client 0: No noise added (privacy disabled).
  Client 5 meets threshold! Generating virtual data...
  Client 5: Privacy disabled, skipping baseline VAE training.
  Client 5: Skipped virtual data generation (ratio=1.0)
  Client 5: No noise added (privacy disabled).
  Client 2 meets threshold! Generating virtual data...
  Client 2: Privacy disabled, skipping baseline VAE training.
  Client 2: Skipped virtual data generation (ratio=1.0)
  Client 2: No noise added (privacy disabled).
  Client 3 meets threshold! Generating virtual data...
  Client 3: Privacy disabled, skipping baseline VAE training.
  Client 3: Skipped virtual data generation (ratio=1.0)
  Client 3: No noise added (privacy disabled).
  Client 4 meets threshold! Generating virtual data...
  Client 4: Privacy disabled, skipping baseline VAE training.
  Client 4: Skipped virtual data generation (ratio=1.0)
  Client 4: No noise added (privacy disabled).
  Client 8 meets threshold! Generating virtual data...
  Client 8: Privacy disabled, skipping baseline VAE training.
  Client 8: Skipped virtual data generation (ratio=1.0)
  Client 8: No noise added (privacy disabled).
  Client 9 meets threshold! Generating virtual data...
  Client 9: Privacy disabled, skipping baseline VAE training.
  Client 9: Skipped virtual data generation (ratio=1.0)
  Client 9: No noise added (privacy disabled).
  Client 7 meets threshold! Generating virtual data...
  Client 7: Privacy disabled, skipping baseline VAE training.
  Client 7: Skipped virtual data generation (ratio=1.0)
  Client 7: No noise added (privacy disabled).
  Client 1 meets threshold! Generating virtual data...
  Client 1: Privacy disabled, skipping baseline VAE training.
  Client 1: Skipped virtual data generation (ratio=1.0)
  Client 1: No noise added (privacy disabled).
  Client 6 meets threshold! Generating virtual data...
  Client 6: Privacy disabled, skipping baseline VAE training.
  Client 6: Skipped virtual data generation (ratio=1.0)
  Client 6: No noise added (privacy disabled).
  Newly qualified clients: [0, 5, 2, 3, 4, 8, 9, 7, 1, 6]
  Total qualified clients: 10/10
  Virtual data pool size: 0

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 0):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 1: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 0 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4903
Averaged Test Accuracy: 0.7783
Averaged Test AUC: 0.6918
Averaged Test Precision: 0.7556
Averaged Test Recall: 0.7783
Averaged Test F1-Score: 0.7242
Std Test Accuracy: 0.0532
Std Test AUC: 0.0760
------------------------------------------------------------
Round 0 time cost: 5.36s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 1)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8111
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7824

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 2: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 1 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4728
Averaged Test Accuracy: 0.7824
Averaged Test AUC: 0.7132
Averaged Test Precision: 0.7772
Averaged Test Recall: 0.7824
Averaged Test F1-Score: 0.7306
Std Test Accuracy: 0.0507
Std Test AUC: 0.0769
------------------------------------------------------------
Round 1 time cost: 4.81s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 2)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8132
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7875

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 3: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 2 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4641
Averaged Test Accuracy: 0.7875
Averaged Test AUC: 0.7231
Averaged Test Precision: 0.7827
Averaged Test Recall: 0.7875
Averaged Test F1-Score: 0.7395
Std Test Accuracy: 0.0465
Std Test AUC: 0.0746
------------------------------------------------------------
Round 2 time cost: 5.10s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 3)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8164
  Best client accuracy (ACC(t)): 0.8453
  Global average accuracy (ACC(t)): 0.7907

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 4: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 3 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4592
Averaged Test Accuracy: 0.7907
Averaged Test AUC: 0.7283
Averaged Test Precision: 0.7878
Averaged Test Recall: 0.7907
Averaged Test F1-Score: 0.7469
Std Test Accuracy: 0.0459
Std Test AUC: 0.0721
------------------------------------------------------------
Round 3 time cost: 5.44s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 4)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8180
  Best client accuracy (ACC(t)): 0.8440
  Global average accuracy (ACC(t)): 0.7915

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 5: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 4 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4556
Averaged Test Accuracy: 0.7915
Averaged Test AUC: 0.7316
Averaged Test Precision: 0.7799
Averaged Test Recall: 0.7915
Averaged Test F1-Score: 0.7471
Std Test Accuracy: 0.0437
Std Test AUC: 0.0711
------------------------------------------------------------
Round 4 time cost: 5.09s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8177
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7943

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 5):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 6: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 5 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4526
Averaged Test Accuracy: 0.7943
Averaged Test AUC: 0.7355
Averaged Test Precision: 0.7878
Averaged Test Recall: 0.7943
Averaged Test F1-Score: 0.7530
Std Test Accuracy: 0.0443
Std Test AUC: 0.0698
------------------------------------------------------------
Round 5 time cost: 4.83s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 6)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8205
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.7959

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 7: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 6 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4505
Averaged Test Accuracy: 0.7959
Averaged Test AUC: 0.7358
Averaged Test Precision: 0.7913
Averaged Test Recall: 0.7959
Averaged Test F1-Score: 0.7565
Std Test Accuracy: 0.0417
Std Test AUC: 0.0693
------------------------------------------------------------
Round 6 time cost: 4.82s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 7)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8233
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.7953

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 8: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 7 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4491
Averaged Test Accuracy: 0.7953
Averaged Test AUC: 0.7367
Averaged Test Precision: 0.7920
Averaged Test Recall: 0.7953
Averaged Test F1-Score: 0.7566
Std Test Accuracy: 0.0427
Std Test AUC: 0.0680
------------------------------------------------------------
Round 7 time cost: 5.04s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 8)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8230
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7957

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 9: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 8 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4468
Averaged Test Accuracy: 0.7957
Averaged Test AUC: 0.7390
Averaged Test Precision: 0.7898
Averaged Test Recall: 0.7957
Averaged Test F1-Score: 0.7584
Std Test Accuracy: 0.0430
Std Test AUC: 0.0671
------------------------------------------------------------
Round 8 time cost: 4.72s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 9)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8212
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.7959

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 10: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 9 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4460
Averaged Test Accuracy: 0.7959
Averaged Test AUC: 0.7402
Averaged Test Precision: 0.7900
Averaged Test Recall: 0.7959
Averaged Test F1-Score: 0.7592
Std Test Accuracy: 0.0450
Std Test AUC: 0.0671
------------------------------------------------------------
Round 9 time cost: 4.64s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 10)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 11: ˥�� 0% (��0��)
    Base: 0.8226 �� Decayed: 0.8226 �� Final: 0.8226
  Current threshold (based on ACC(t-1)): 0.8226
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.7972

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 10):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 11: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 10 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4437
Averaged Test Accuracy: 0.7972
Averaged Test AUC: 0.7422
Averaged Test Precision: 0.7884
Averaged Test Recall: 0.7972
Averaged Test F1-Score: 0.7640
Std Test Accuracy: 0.0456
Std Test AUC: 0.0648
------------------------------------------------------------
Round 10 time cost: 5.36s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 11)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8233
  Best client accuracy (ACC(t)): 0.8480
  Global average accuracy (ACC(t)): 0.7981

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 12: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 11 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4428
Averaged Test Accuracy: 0.7981
Averaged Test AUC: 0.7428
Averaged Test Precision: 0.7867
Averaged Test Recall: 0.7981
Averaged Test F1-Score: 0.7659
Std Test Accuracy: 0.0426
Std Test AUC: 0.0648
------------------------------------------------------------
Round 11 time cost: 4.72s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 12)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8231
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.7979

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 13: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 12 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4414
Averaged Test Accuracy: 0.7979
Averaged Test AUC: 0.7436
Averaged Test Precision: 0.7870
Averaged Test Recall: 0.7979
Averaged Test F1-Score: 0.7653
Std Test Accuracy: 0.0441
Std Test AUC: 0.0646
------------------------------------------------------------
Round 12 time cost: 5.03s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 13)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8236
  Best client accuracy (ACC(t)): 0.8467
  Global average accuracy (ACC(t)): 0.7996

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 14: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 13 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4411
Averaged Test Accuracy: 0.7996
Averaged Test AUC: 0.7452
Averaged Test Precision: 0.7913
Averaged Test Recall: 0.7996
Averaged Test F1-Score: 0.7684
Std Test Accuracy: 0.0468
Std Test AUC: 0.0637
------------------------------------------------------------
Round 13 time cost: 5.05s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 14)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.8231
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8005

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 15: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 14 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4394
Averaged Test Accuracy: 0.8005
Averaged Test AUC: 0.7460
Averaged Test Precision: 0.7924
Averaged Test Recall: 0.8005
Averaged Test F1-Score: 0.7704
Std Test Accuracy: 0.0463
Std Test AUC: 0.0639
------------------------------------------------------------
Round 14 time cost: 4.90s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 15)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 16: ˥�� 5% (��1��)
    Base: 0.8256 �� Decayed: 0.7843 �� Final: 0.7843
  Current threshold (based on ACC(t-1)): 0.7843
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8003

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 15):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 16: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 15 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4396
Averaged Test Accuracy: 0.8003
Averaged Test AUC: 0.7469
Averaged Test Precision: 0.7933
Averaged Test Recall: 0.8003
Averaged Test F1-Score: 0.7712
Std Test Accuracy: 0.0479
Std Test AUC: 0.0624
------------------------------------------------------------
Round 15 time cost: 5.26s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 16)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7848
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8007

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 17: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 16 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4390
Averaged Test Accuracy: 0.8007
Averaged Test AUC: 0.7479
Averaged Test Precision: 0.7977
Averaged Test Recall: 0.8007
Averaged Test F1-Score: 0.7702
Std Test Accuracy: 0.0497
Std Test AUC: 0.0624
------------------------------------------------------------
Round 16 time cost: 4.95s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 17)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7850
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8021

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 18: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 17 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4372
Averaged Test Accuracy: 0.8021
Averaged Test AUC: 0.7481
Averaged Test Precision: 0.7929
Averaged Test Recall: 0.8021
Averaged Test F1-Score: 0.7742
Std Test Accuracy: 0.0472
Std Test AUC: 0.0628
------------------------------------------------------------
Round 17 time cost: 4.93s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 18)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7857
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8011

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 19: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 18 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4365
Averaged Test Accuracy: 0.8011
Averaged Test AUC: 0.7486
Averaged Test Precision: 0.7925
Averaged Test Recall: 0.8011
Averaged Test F1-Score: 0.7723
Std Test Accuracy: 0.0464
Std Test AUC: 0.0623
------------------------------------------------------------
Round 18 time cost: 5.12s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 19)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7846
  Best client accuracy (ACC(t)): 0.8533
  Global average accuracy (ACC(t)): 0.8019

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 20: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 19 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4357
Averaged Test Accuracy: 0.8019
Averaged Test AUC: 0.7491
Averaged Test Precision: 0.7948
Averaged Test Recall: 0.8019
Averaged Test F1-Score: 0.7751
Std Test Accuracy: 0.0496
Std Test AUC: 0.0613
------------------------------------------------------------
Round 19 time cost: 4.97s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 20)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 21: ˥�� 10% (��2��)
    Base: 0.8276 �� Decayed: 0.7448 �� Final: 0.7448
  Current threshold (based on ACC(t-1)): 0.7448
  Best client accuracy (ACC(t)): 0.8493
  Global average accuracy (ACC(t)): 0.7985

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 20):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 21: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 20 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4359
Averaged Test Accuracy: 0.7985
Averaged Test AUC: 0.7493
Averaged Test Precision: 0.7890
Averaged Test Recall: 0.7985
Averaged Test F1-Score: 0.7677
Std Test Accuracy: 0.0466
Std Test AUC: 0.0618
------------------------------------------------------------
Round 20 time cost: 5.16s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 21)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7415
  Best client accuracy (ACC(t)): 0.8533
  Global average accuracy (ACC(t)): 0.8036

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 22: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 21 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4342
Averaged Test Accuracy: 0.8036
Averaged Test AUC: 0.7502
Averaged Test Precision: 0.7970
Averaged Test Recall: 0.8036
Averaged Test F1-Score: 0.7767
Std Test Accuracy: 0.0489
Std Test AUC: 0.0598
------------------------------------------------------------
Round 21 time cost: 4.68s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 22)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7456
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8021

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 23: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 22 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4341
Averaged Test Accuracy: 0.8021
Averaged Test AUC: 0.7520
Averaged Test Precision: 0.7936
Averaged Test Recall: 0.8021
Averaged Test F1-Score: 0.7767
Std Test Accuracy: 0.0501
Std Test AUC: 0.0589
------------------------------------------------------------
Round 22 time cost: 5.18s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 23)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7438
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8023

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 24: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 23 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4347
Averaged Test Accuracy: 0.8023
Averaged Test AUC: 0.7518
Averaged Test Precision: 0.7951
Averaged Test Recall: 0.8023
Averaged Test F1-Score: 0.7738
Std Test Accuracy: 0.0471
Std Test AUC: 0.0592
------------------------------------------------------------
Round 23 time cost: 5.27s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 24)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7438
  Best client accuracy (ACC(t)): 0.8507
  Global average accuracy (ACC(t)): 0.8032

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 25: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 24 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4327
Averaged Test Accuracy: 0.8032
Averaged Test AUC: 0.7518
Averaged Test Precision: 0.7949
Averaged Test Recall: 0.8032
Averaged Test F1-Score: 0.7769
Std Test Accuracy: 0.0486
Std Test AUC: 0.0592
------------------------------------------------------------
Round 24 time cost: 4.83s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 25)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  [Threshold Decay] Round 26: ˥�� 15% (��3��)
    Base: 0.8269 �� Decayed: 0.7029 �� Final: 0.7029
  Current threshold (based on ACC(t-1)): 0.7029
  Best client accuracy (ACC(t)): 0.8520
  Global average accuracy (ACC(t)): 0.8040

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 25):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 26: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 25 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4332
Averaged Test Accuracy: 0.8040
Averaged Test AUC: 0.7521
Averaged Test Precision: 0.7983
Averaged Test Recall: 0.8040
Averaged Test F1-Score: 0.7763
Std Test Accuracy: 0.0479
Std Test AUC: 0.0585
------------------------------------------------------------
Round 25 time cost: 5.36s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 26)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7038
  Best client accuracy (ACC(t)): 0.8547
  Global average accuracy (ACC(t)): 0.8037

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 27: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 26 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4316
Averaged Test Accuracy: 0.8037
Averaged Test AUC: 0.7532
Averaged Test Precision: 0.7947
Averaged Test Recall: 0.8037
Averaged Test F1-Score: 0.7786
Std Test Accuracy: 0.0479
Std Test AUC: 0.0575
------------------------------------------------------------
Round 26 time cost: 5.29s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 27)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7048
  Best client accuracy (ACC(t)): 0.8560
  Global average accuracy (ACC(t)): 0.8024

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 28: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 27 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4316
Averaged Test Accuracy: 0.8024
Averaged Test AUC: 0.7532
Averaged Test Precision: 0.7937
Averaged Test Recall: 0.8024
Averaged Test F1-Score: 0.7758
Std Test Accuracy: 0.0475
Std Test AUC: 0.0579
------------------------------------------------------------
Round 27 time cost: 4.98s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 28)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7048
  Best client accuracy (ACC(t)): 0.8560
  Global average accuracy (ACC(t)): 0.8019

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 29: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 28 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4311
Averaged Test Accuracy: 0.8019
Averaged Test AUC: 0.7541
Averaged Test Precision: 0.7939
Averaged Test Recall: 0.8019
Averaged Test F1-Score: 0.7761
Std Test Accuracy: 0.0502
Std Test AUC: 0.0575
------------------------------------------------------------
Round 28 time cost: 5.01s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 29)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7046
  Best client accuracy (ACC(t)): 0.8533
  Global average accuracy (ACC(t)): 0.8035

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 30: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 29 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.4304
Averaged Test Accuracy: 0.8035
Averaged Test AUC: 0.7541
Averaged Test Precision: 0.7945
Averaged Test Recall: 0.8035
Averaged Test F1-Score: 0.7779
Std Test Accuracy: 0.0476
Std Test AUC: 0.0571
------------------------------------------------------------
Round 29 time cost: 4.87s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 30)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 2] ��ͣ��� (��ǰ׼ȷ��: 0.7840)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6846
       ��29��: 0.7827 >= 0.6846 [+]
       ��30��: 0.7880 >= 0.6846 [+]
       ��31��: 0.7840 >= 0.6846 [+]
    [+] ����(3): �������ȶ� (0.0053 <= 0.0200)
       ���3��: ['0.7827', '0.7880', '0.7840']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 2 reached early stopping criteria (Round 31):
    - Accuracy: 0.7840 (threshold: 0.7046)
    - Fluctuation: 0.0053 (last 3 rounds)
    - History: ['0.783', '0.788', '0.784']
  [Virtual Data] Generating and locking virtual data for client 2...
  [Mentor Mode] Client 2 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 2 early stopped at round 30
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 7] ��ͣ��� (��ǰ׼ȷ��: 0.7307)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6846
       ��29��: 0.7267 >= 0.6846 [+]
       ��30��: 0.7307 >= 0.6846 [+]
       ��31��: 0.7307 >= 0.6846 [+]
    [+] ����(3): �������ȶ� (0.0040 <= 0.0200)
       ���3��: ['0.7267', '0.7307', '0.7307']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 7 reached early stopping criteria (Round 31):
    - Accuracy: 0.7307 (threshold: 0.7046)
    - Fluctuation: 0.0040 (last 3 rounds)
    - History: ['0.727', '0.731', '0.731']
  [Virtual Data] Generating and locking virtual data for client 7...
  [Mentor Mode] Client 7 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 7 early stopped at round 30
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 8] ��ͣ��� (��ǰ׼ȷ��: 0.7987)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6846
       ��29��: 0.7987 >= 0.6846 [+]
       ��30��: 0.7973 >= 0.6846 [+]
       ��31��: 0.7987 >= 0.6846 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.7987', '0.7973', '0.7987']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 8 reached early stopping criteria (Round 31):
    - Accuracy: 0.7987 (threshold: 0.7046)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.799', '0.797', '0.799']
  [Virtual Data] Generating and locking virtual data for client 8...
  [Mentor Mode] Client 8 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 8 early stopped at round 30
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 9] ��ͣ��� (��ǰ׼ȷ��: 0.8573)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6846
       ��29��: 0.8560 >= 0.6846 [+]
       ��30��: 0.8533 >= 0.6846 [+]
       ��31��: 0.8573 >= 0.6846 [+]
    [+] ����(3): �������ȶ� (0.0040 <= 0.0200)
       ���3��: ['0.8560', '0.8533', '0.8573']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 9 reached early stopping criteria (Round 31):
    - Accuracy: 0.8573 (threshold: 0.7046)
    - Fluctuation: 0.0040 (last 3 rounds)
    - History: ['0.856', '0.853', '0.857']
  [Virtual Data] Generating and locking virtual data for client 9...
  [Mentor Mode] Client 9 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 9 early stopped at round 30
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 5] ��ͣ��� (��ǰ׼ȷ��: 0.7093)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6846
       ��29��: 0.7067 >= 0.6846 [+]
       ��30��: 0.7160 >= 0.6846 [+]
       ��31��: 0.7093 >= 0.6846 [+]
    [+] ����(3): �������ȶ� (0.0093 <= 0.0200)
       ���3��: ['0.7067', '0.7160', '0.7093']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 5 reached early stopping criteria (Round 31):
    - Accuracy: 0.7093 (threshold: 0.7046)
    - Fluctuation: 0.0093 (last 3 rounds)
    - History: ['0.707', '0.716', '0.709']
  [Virtual Data] Generating and locking virtual data for client 5...
  [Mentor Mode] Client 5 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 5 early stopped at round 30
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 0] ��ͣ��� (��ǰ׼ȷ��: 0.8427)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6846
       ��29��: 0.8427 >= 0.6846 [+]
       ��30��: 0.8427 >= 0.6846 [+]
       ��31��: 0.8427 >= 0.6846 [+]
    [+] ����(3): �������ȶ� (0.0000 <= 0.0200)
       ���3��: ['0.8427', '0.8427', '0.8427']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 0 reached early stopping criteria (Round 31):
    - Accuracy: 0.8427 (threshold: 0.7046)
    - Fluctuation: 0.0000 (last 3 rounds)
    - History: ['0.843', '0.843', '0.843']
  [Virtual Data] Generating and locking virtual data for client 0...
  [Mentor Mode] Client 0 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 0 early stopped at round 30
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 1] ��ͣ��� (��ǰ׼ȷ��: 0.8493)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6846
       ��29��: 0.8480 >= 0.6846 [+]
       ��30��: 0.8480 >= 0.6846 [+]
       ��31��: 0.8493 >= 0.6846 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.8480', '0.8480', '0.8493']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 1 reached early stopping criteria (Round 31):
    - Accuracy: 0.8493 (threshold: 0.7046)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.848', '0.848', '0.849']
  [Virtual Data] Generating and locking virtual data for client 1...
  [Mentor Mode] Client 1 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 1 early stopped at round 30
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 4] ��ͣ��� (��ǰ׼ȷ��: 0.8307)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6846
       ��29��: 0.8293 >= 0.6846 [+]
       ��30��: 0.8280 >= 0.6846 [+]
       ��31��: 0.8307 >= 0.6846 [+]
    [+] ����(3): �������ȶ� (0.0027 <= 0.0200)
       ���3��: ['0.8293', '0.8280', '0.8307']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 4 reached early stopping criteria (Round 31):
    - Accuracy: 0.8307 (threshold: 0.7046)
    - Fluctuation: 0.0027 (last 3 rounds)
    - History: ['0.829', '0.828', '0.831']
  [Virtual Data] Generating and locking virtual data for client 4...
  [Mentor Mode] Client 4 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 4 early stopped at round 30
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 3] ��ͣ��� (��ǰ׼ȷ��: 0.7787)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6846
       ��29��: 0.7800 >= 0.6846 [+]
       ��30��: 0.7800 >= 0.6846 [+]
       ��31��: 0.7787 >= 0.6846 [+]
    [+] ����(3): �������ȶ� (0.0013 <= 0.0200)
       ���3��: ['0.7800', '0.7800', '0.7787']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 3 reached early stopping criteria (Round 31):
    - Accuracy: 0.7787 (threshold: 0.7046)
    - Fluctuation: 0.0013 (last 3 rounds)
    - History: ['0.780', '0.780', '0.779']
  [Virtual Data] Generating and locking virtual data for client 3...
  [Mentor Mode] Client 3 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 3 early stopped at round 30
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)

  [Client 6] ��ͣ��� (��ǰ׼ȷ��: 0.8493)
    [+] ����(1): ѵ���������� (31��)
    [+] ����(2): �����ִζ��������
       ������ֵ: 0.6846
       ��29��: 0.8480 >= 0.6846 [+]
       ��30��: 0.8507 >= 0.6846 [+]
       ��31��: 0.8493 >= 0.6846 [+]
    [+] ����(3): �������ȶ� (0.0027 <= 0.0200)
       ���3��: ['0.8480', '0.8507', '0.8493']
    [OK] ������������ - �ͻ��˴�꣡
  [Qualified] Client 6 reached early stopping criteria (Round 31):
    - Accuracy: 0.8493 (threshold: 0.7046)
    - Fluctuation: 0.0027 (last 3 rounds)
    - History: ['0.848', '0.851', '0.849']
  [Virtual Data] Generating and locking virtual data for client 6...
  [Mentor Mode] Client 6 enters mentor mode:
    - Continue training model (help weak clients)
    - Continue uploading prototypes (weight auto-decayed by ��_k(t))
    - Virtual data locked (privacy preserved)
  [Adaptive Decay] Client 6 early stopped at round 30
  [Threshold Decay] Round 31: ˥�� 20% (��4��)
    Base: 0.8284 �� Decayed: 0.6627 �� Final: 0.6627
  Current threshold (based on ACC(t-1)): 0.6627
  Best client accuracy (ACC(t)): 0.8573
  Global average accuracy (ACC(t)): 0.8031

  [Adaptive Decay] Ȩ��˥���������� (Round 31):
  ��ǰȫ��׼ȷ��: 0.8031
  ˥��ǿ�Ȧ�: 0.5
    Client 2: ��31�ִ��
      ���ʱ׼ȷ��: 0.8031
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 7: ��31�ִ��
      ���ʱ׼ȷ��: 0.8031
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 8: ��31�ִ��
      ���ʱ׼ȷ��: 0.8031
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 9: ��31�ִ��
      ���ʱ׼ȷ��: 0.8031
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 5: ��31�ִ��
      ���ʱ׼ȷ��: 0.8031
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 0: ��31�ִ��
      ���ʱ׼ȷ��: 0.8031
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 1: ��31�ִ��
      ���ʱ׼ȷ��: 0.8031
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 4: ��31�ִ��
      ���ʱ׼ȷ��: 0.8031
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 3: ��31�ִ��
      ���ʱ׼ȷ��: 0.8031
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
    Client 6: ��31�ִ��
      ���ʱ׼ȷ��: 0.8031
      ׼ȷ��������: +0.0000 �� max(0,��)=0.0000
      ˥��Ȩ�ئ�_k: exp(-0.5��0.0000) = 1.0000
  Early-stopped clients: 10/10
  Active training clients: 0

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 30):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 1   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 2   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 3   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 4   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 5   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 6   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 7   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 8   2250        1.0000        2250.00         0.1000          ��ͣ        
  Client 9   2250        1.0000        2250.00         0.1000          ��ͣ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  [Adaptive Decay] Prototype aggregation weights: C0=1.000 C1=1.000 C2=1.000 C3=1.000 C4=1.000 ... (10 total)
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

================================================================================
[Phase Transition Check] Round 31 (Phase 1: ���50��)
================================================================================
���Ҫ��: 7/10 �ͻ��� (70%)
��ǰ״̬: 10/10 �ͻ��˴��

�ͻ�����ϸ״̬:

[+] �Ѵ��ͻ��� (10��):
  Client 9: 0.8573 [+]
  Client 1: 0.8493 [+]
  Client 6: 0.8493 [+]
  Client 0: 0.8427 [+]
  Client 4: 0.8307 [+]
  Client 8: 0.7987 [+]
  Client 2: 0.7840 [+]
  Client 3: 0.7787 [+]
  Client 7: 0.7307 [+]
  Client 5: 0.7093 [+]

��ǰ��ֵ: 0.6627
ƽ��׼ȷ��: 0.8031
���׼ȷ��: 0.8573
================================================================================

[>>] Phase Transition Triggered! (70% Threshold Strategy)
   Qualified clients: 10/10
   Required: 7 (70%)
   Remaining: 0 clients will join dynamically in Phase 2
   Phase 1 completed: 31 rounds (min: 30, max: 50)
================================================================================


============================================================
PHASE TRANSITION: Phase 1 �� Phase 2
============================================================
Virtual data pool size: 0
Phase 2 Algorithm: FEDAVG
Phase 2 Max Rounds: 50
============================================================

  [Algorithm Name] Updated: FedGpro �� FedGpro-FedAvg
  Client 0: Phase 2 (already contributed virtual data)
  Client 1: Phase 2 (already contributed virtual data)
  Client 2: Phase 2 (already contributed virtual data)
  Client 3: Phase 2 (already contributed virtual data)
  Client 4: Phase 2 (already contributed virtual data)
  Client 5: Phase 2 (already contributed virtual data)
  Client 6: Phase 2 (already contributed virtual data)
  Client 7: Phase 2 (already contributed virtual data)
  Client 8: Phase 2 (already contributed virtual data)
  Client 9: Phase 2 (already contributed virtual data)
[OK] Phase 2 initialized successfully!
   Algorithm: FEDAVG
   All clients enter Phase 2: 10 (100%)
   - Already contributed virtual data: 10 (100%)
   - Can still contribute (until round 20): 0 (0%)
   Virtual data pool size: 0 samples
   Phase 1 will continue in parallel until round 20


============================================================
Round 30 | Phase 2
============================================================

Evaluate personalized models (Primary)
Averaged Train Loss (Personalized): 5.6831
Averaged Test Accuracy (Personalized): 0.3271
Averaged Test AUC (Personalized): 0.6104
Std Test Accuracy (Personalized): 0.1058
Std Test AUC (Personalized): 0.0590

Evaluate global model (Reference only)
Averaged Train Loss: 0.4297
Averaged Test Accuracy: 0.8031
Averaged Test AUC: 0.7536
Averaged Test Precision: 0.7948
Averaged Test Recall: 0.8031
Averaged Test F1-Score: 0.7791
Std Test Accuracy: 0.0496
Std Test AUC: 0.0575
  [Note] Global model results not saved to rs_test_acc (using personalized model as primary metric)
------------------------------------------------------------
Round 30 time cost: 6.24s
------------------------------------------------------------

[Phase 2 - Round 31] Algorithm: FEDAVG
  Phase 2 clients: 10 | Phase 1 clients (training): 0
Traceback (most recent call last):
