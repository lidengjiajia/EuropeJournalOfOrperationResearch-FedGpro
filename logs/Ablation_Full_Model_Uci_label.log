Warning: FedPAC requires cvxpy. Install with: pip install cvxpy
Warning: MemReporter requires calmsize. Install with: pip install calmsize
==================================================
goal = Ablation_Full_Model_label
device = cuda
device_id = 0
dataset = Uci
num_classes = 10
model = credit
batch_size = 64
local_learning_rate = 0.007
learning_rate_decay = False
learning_rate_decay_gamma = 0.99
global_rounds = 100
top_cnt = 100
local_epochs = 5
algorithm = FedGpro
join_ratio = 1.0
random_join_ratio = False
num_clients = 10
prev = 0
times = 5
eval_gap = 1
save_folder_name = system/models/Uci_FedGpro_Ablation_Full_Model_label
auto_break = False
dlg_eval = False
dlg_gap = 100
batch_num_per_client = 2
num_new_clients = 0
fine_tuning_epoch_new = 0
feature_dim = 512
vocab_size = 80
max_len = 200
few_shot = 0
client_drop_rate = 0.0
train_slow_rate = 0.0
send_slow_rate = 0.0
time_select = False
time_threthold = 10000
beta = 0.0
lamda = 1.0
mu = 0.0
K = 5
p_learning_rate = 0.01
M = 5
itk = 4000
alphaK = 1.0
sigma = 1.0
alpha = 1.0
plocal_epochs = 1
tau = 1.0
fine_tuning_epochs = 10
dr_learning_rate = 0.0
L = 1.0
noise_dim = 512
generator_learning_rate = 0.005
hidden_dim = 512
server_epochs = 1000
localize_feature_extractor = False
server_learning_rate = 1.0
eta = 1.0
rand_percent = 80
layer_idx = 2
mentee_learning_rate = 0.005
T_start = 0.95
T_end = 0.98
momentum = 0.1
kl_weight = 0.0
first_stage_bound = 0
fedcross_alpha = 0.99
collaberative_model_select_strategy = 1
fedgpro_phase = 1
fedgpro_use_vae = True
fedgpro_use_prototype = True
fedgpro_epsilon = None
fedgpro_noise_type = None
fedgpro_delta = 1e-05
fedgpro_adaptive_noise = False
fedgpro_adaptive_strategy = balanced
fedgpro_utility_weight = 1.0
fedgpro_use_iadp = False
fedgpro_iadp_alpha = 0.3
fedgpro_iadp_importance_method = vae_contrast
fedgpro_iadp_importance_momentum = 0.9
fedgpro_iadp_privacy_priority = False
fedgpro_lambda_cls = 10.0
fedgpro_lambda_recon = 1.0
fedgpro_lambda_kl = 0.1
fedgpro_lambda_proto = 0.3
fedgpro_proto_momentum = 0.95
fedgpro_latent_dim = None
fedgpro_vae_lr = 0.001
fedgpro_proto_align_lr = 0.001
fedgpro_threshold_min = 0.6
fedgpro_phase_transition_threshold = 0.7
fedgpro_phase2_agg = fedavg
fedgpro_phase2_rounds = 50
reserved_clients = []
gwo_alpha_decay = 0.015
pso_w_max = 0.9
pso_w_min = 0.4
pso_c1 = 2.0
pso_c2 = 2.0
pso_v_max = 0.5
cs_f_max = 2.0
cs_f_min = 0.1
cs_AP_max = 0.3
cs_AP_min = 0.1
==================================================

============= Running time: 0th =============
Creating server and clients ...
Warning: Credit dataset Uci should have 2 classes. Auto-correcting from 10 to 2.
Auto-selected UciCreditNet for dataset Uci
UciCreditNet(
  (layers): Sequential(
    (0): Linear(in_features=23, out_features=32, bias=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.4, inplace=False)
    (4): Linear(in_features=32, out_features=16, bias=True)
    (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.2, inplace=False)
  )
  (fc): Linear(in_features=16, out_features=2, bias=True)
)
  Client 0: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 1: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 2: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 3: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 4: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 5: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 6: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 7: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 8: Personalization enabled (mu=0.0, plocal_epochs=1)
  Client 9: Personalization enabled (mu=0.0, plocal_epochs=1)

============================================================
FedGpro: Federated Global Prototype Learning
============================================================
Join ratio / total clients: 1.0 / 10

Phase 1 Parameters (Max 20 rounds):
  Minimum threshold: 0.6
  Threshold formula:
    ACC(t-1) = (best_acc(t-1) + avg_acc(t-1)) / 2
    threshold(r) = ACC(t-1),                                       if r <= 9
    threshold(r) = max(0.66, ACC(t-1)*(1-0.05*floor((r-10)/5))), if r >= 10
  Training stages:
    - Round 1-10: Forced training (no early stop check, ensure VAE quality)
    - Round 11+: Early stop check + dynamic threshold with time decay
  Phase transition: 70% clients qualified OR 25 rounds reached

Phase 2 Parameters:
  Aggregation: fedavg
  Supported algorithms: fedavg, fedprox, fedscaffold
============================================================

Finished creating server and clients.

[Phase 1] Statistical Collection (Round 0)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.6600
  Best client accuracy (ACC(t)): 0.8427
  Global average accuracy (ACC(t)): 0.7208
  Client 4 meets threshold! Generating virtual data...
  Client 4: Privacy disabled, skipping baseline VAE training.
  Client 4: Collecting latent distribution from real data...
    [OK] Class 0: 1125��������������� (threshold=0.80)
    Class 0: 1125/2250 candidates passed filter (avg confidence: 0.842)
    [WARNING] Class 1: ��0/1125������� (threshold=0.80), ��ȱ���ģ����������������
    Class 1: 0/2250 candidates passed filter (avg confidence: nan)
  Client 4: Generated 1125/2250 high-quality samples (50.0% pass rate, strict threshold=0.80)
  Client 4: No noise added (privacy disabled).
  Client 1 meets threshold! Generating virtual data...
  Client 1: Privacy disabled, skipping baseline VAE training.
  Client 1: Collecting latent distribution from real data...
    [OK] Class 0: 1125��������������� (threshold=0.80)
    Class 0: 1125/2250 candidates passed filter (avg confidence: 0.884)
    [WARNING] Class 1: ��0/1125������� (threshold=0.80), ��ȱ���ģ����������������
    Class 1: 0/2250 candidates passed filter (avg confidence: nan)
  Client 1: Generated 1125/2250 high-quality samples (50.0% pass rate, strict threshold=0.80)
  Client 1: No noise added (privacy disabled).
  Client 8 meets threshold! Generating virtual data...
  Client 8: Privacy disabled, skipping baseline VAE training.
  Client 8: Collecting latent distribution from real data...
    [OK] Class 0: 1125��������������� (threshold=0.80)
    Class 0: 1125/2250 candidates passed filter (avg confidence: 0.834)
    [WARNING] Class 1: ��0/1125������� (threshold=0.80), ��ȱ���ģ����������������
    Class 1: 0/2250 candidates passed filter (avg confidence: nan)
  Client 8: Generated 1125/2250 high-quality samples (50.0% pass rate, strict threshold=0.80)
  Client 8: No noise added (privacy disabled).
  Client 3 meets threshold! Generating virtual data...
  Client 3: Privacy disabled, skipping baseline VAE training.
  Client 3: Collecting latent distribution from real data...
    [WARNING] Class 0: ��3/1125������� (threshold=0.80), ��ȱ���ģ����������������
    Class 0: 3/2250 candidates passed filter (avg confidence: 0.840)
    [WARNING] Class 1: ��0/1125������� (threshold=0.80), ��ȱ���ģ����������������
    Class 1: 0/2250 candidates passed filter (avg confidence: nan)
  Client 3: Generated 3/2250 high-quality samples (0.1% pass rate, strict threshold=0.80)
  Client 3: No noise added (privacy disabled).
  Client 9 meets threshold! Generating virtual data...
  Client 9: Privacy disabled, skipping baseline VAE training.
  Client 9: Collecting latent distribution from real data...
    [OK] Class 0: 1125��������������� (threshold=0.80)
    Class 0: 1125/2250 candidates passed filter (avg confidence: 0.827)
    [WARNING] Class 1: ��0/1125������� (threshold=0.80), ��ȱ���ģ����������������
    Class 1: 0/2250 candidates passed filter (avg confidence: nan)
  Client 9: Generated 1125/2250 high-quality samples (50.0% pass rate, strict threshold=0.80)
  Client 9: No noise added (privacy disabled).
  Client 6 meets threshold! Generating virtual data...
  Client 6: Privacy disabled, skipping baseline VAE training.
  Client 6: Collecting latent distribution from real data...
    [OK] Class 0: 1125��������������� (threshold=0.80)
    Class 0: 1125/2250 candidates passed filter (avg confidence: 0.833)
    [WARNING] Class 1: ��0/1125������� (threshold=0.80), ��ȱ���ģ����������������
    Class 1: 0/2250 candidates passed filter (avg confidence: nan)
  Client 6: Generated 1125/2250 high-quality samples (50.0% pass rate, strict threshold=0.80)
  Client 6: No noise added (privacy disabled).
  Client 0 meets threshold! Generating virtual data...
  Client 0: Privacy disabled, skipping baseline VAE training.
  Client 0: Collecting latent distribution from real data...
    [OK] Class 0: 1125��������������� (threshold=0.80)
    Class 0: 1125/2250 candidates passed filter (avg confidence: 0.840)
    [WARNING] Class 1: ��0/1125������� (threshold=0.80), ��ȱ���ģ����������������
    Class 1: 0/2250 candidates passed filter (avg confidence: nan)
  Client 0: Generated 1125/2250 high-quality samples (50.0% pass rate, strict threshold=0.80)
  Client 0: No noise added (privacy disabled).
  Newly qualified clients: [4, 1, 8, 3, 9, 6, 0]
  Total qualified clients: 7/10
  Virtual data pool size: 6753

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers

  [Prototype Aggregation] Ȩ�طֽ����� (Round 0):
  ================================================================================
  �ͻ���      ������        ˥����_k        ���Ȩ��           ��һ��Ȩ��          ״̬        
  --------------------------------------------------------------------------------
  Client 0   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 1   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 2   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 3   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 4   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 5   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 6   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 7   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 8   2250        1.0000        2250.00         0.1000          ��Ծ        
  Client 9   2250        1.0000        2250.00         0.1000          ��Ծ        
  --------------------------------------------------------------------------------
  �����Ȩ��: 22500.00
  ��һ�����: ��w_k_norm = 1.000000 (ӦΪ1.0)
  ================================================================================

  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 1: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 0 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.5621
Averaged Test Accuracy: 0.7208
Averaged Test AUC: 0.5171
Averaged Test Precision: 0.6049
Averaged Test Recall: 0.7208
Averaged Test F1-Score: 0.6403
Std Test Accuracy: 0.1264
Std Test AUC: 0.0438
------------------------------------------------------------
Round 0 time cost: 10.20s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 1)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7817
  Best client accuracy (ACC(t)): 0.8427
  Global average accuracy (ACC(t)): 0.7212

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 2: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 1 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.5513
Averaged Test Accuracy: 0.7212
Averaged Test AUC: 0.5195
Averaged Test Precision: 0.6060
Averaged Test Recall: 0.7212
Averaged Test F1-Score: 0.6468
Std Test Accuracy: 0.1195
Std Test AUC: 0.0477
------------------------------------------------------------
Round 1 time cost: 8.78s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 2)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7819
  Best client accuracy (ACC(t)): 0.8400
  Global average accuracy (ACC(t)): 0.7179

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 3: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 2 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.6189
Averaged Test Accuracy: 0.7179
Averaged Test AUC: 0.5247
Averaged Test Precision: 0.6603
Averaged Test Recall: 0.7179
Averaged Test F1-Score: 0.6789
Std Test Accuracy: 0.1010
Std Test AUC: 0.0804
------------------------------------------------------------
Round 2 time cost: 8.57s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 3)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7789
  Best client accuracy (ACC(t)): 0.8227
  Global average accuracy (ACC(t)): 0.7055

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 4: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 3 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.7783
Averaged Test Accuracy: 0.7055
Averaged Test AUC: 0.5335
Averaged Test Precision: 0.6717
Averaged Test Recall: 0.7055
Averaged Test F1-Score: 0.6789
Std Test Accuracy: 0.0830
Std Test AUC: 0.0881
------------------------------------------------------------
Round 3 time cost: 8.43s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 4)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 7: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 7: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 2: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 2: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Current threshold (based on ACC(t-1)): 0.7641
  Best client accuracy (ACC(t)): 0.8120
  Global average accuracy (ACC(t)): 0.7048

  [VAE Aggregation] ����ۺ�VAE����...
  [OK] VAE�����ۺ���ɣ��ѷַ��� 10 ���ͻ���
  ������ģ: Encoder=21 layers, Decoder=23 layers
  Client 0 received 2 global prototypes
  Client 1 received 2 global prototypes
  Client 2 received 2 global prototypes
  Client 3 received 2 global prototypes
  Client 4 received 2 global prototypes
  Client 5 received 2 global prototypes
  Client 6 received 2 global prototypes
  Client 7 received 2 global prototypes
  Client 8 received 2 global prototypes
  Client 9 received 2 global prototypes

[Phase Transition Check] Round 5: ǰ30��ǿ��Phase 1����ͬѵ����ȷ��VAE������

============================================================
Round 4 | Phase 1
============================================================

Evaluate global model
Averaged Train Loss: 0.8936
Averaged Test Accuracy: 0.7048
Averaged Test AUC: 0.5507
Averaged Test Precision: 0.6811
Averaged Test Recall: 0.7048
Averaged Test F1-Score: 0.6839
Std Test Accuracy: 0.0741
Std Test AUC: 0.0950
------------------------------------------------------------
Round 4 time cost: 8.39s
------------------------------------------------------------

[Phase 1] Statistical Collection (Round 5)
  Client 5: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 5: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 4: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 4: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 3: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 3: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 8: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 8: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 9: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 9: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 0: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 0: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 6: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 6: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
  Client 1: [Warm-up Stage] Pretraining classifier on real data (epochs 1-1)
  Client 1: [Joint Training Stage] VAE + Classifier joint training (epochs 2-5)
Traceback (most recent call last):
  File "C:\Users\��Ǽ�\Documents\����\С����\���˳�\EuropeJournalOfOrperationResearch-FedGpro\system\main.py", line 824, in <module>
    run(args)
    ~~~^^^^^^
  File "C:\Users\��Ǽ�\Documents\����\С����\���˳�\EuropeJournalOfOrperationResearch-FedGpro\system\main.py", line 561, in run
