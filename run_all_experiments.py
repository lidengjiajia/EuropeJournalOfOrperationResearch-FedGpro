"""
è”é‚¦å­¦ä¹ åŸºå‡†ç®—æ³•æ‰¹é‡å®éªŒè¿è¡Œè„šæœ¬ (ä¼˜åŒ–ç‰ˆ)
ç‰¹æ€§:
- å¹¶å‘æ‰§è¡Œ: æ¯ä¸ªGPUåŒæ—¶è¿è¡Œ2ä¸ªå®éªŒ
- æ™ºèƒ½æ£€æµ‹: æ‰“å°ç¼ºå¤±çš„å®éªŒæ–‡ä»¶
- ç®€åŒ–æ—¥å¿—: æ¯20è½®æ‰“å°ä¸€æ¬¡è¿›åº¦
- å®æ—¶ç›‘æ§: æ˜¾ç¤ºæ¯ä¸ªå®éªŒçš„è¿›åº¦
"""

import os
import sys
import time
import subprocess
import threading
from datetime import datetime
from pathlib import Path
from queue import Queue, Empty
from typing import Dict, List, Optional, Any
from collections import defaultdict
import re

# æ·»åŠ systemç›®å½•åˆ°è·¯å¾„
BASE_DIR = Path(__file__).parent.resolve()
sys.path.insert(0, str(BASE_DIR / 'system'))

# =============================================================================
# é…ç½®å¸¸é‡
# =============================================================================

DATASETS = ['Uci', 'Xinwang']
HETEROGENEITY_TYPES = {'feature': 'ç‰¹å¾å¼‚è´¨æ€§', 'label': 'æ ‡ç­¾å¼‚è´¨æ€§', 
                       'quantity': 'æ ·æœ¬æ•°é‡å¼‚è´¨æ€§', 'iid': 'IIDå‡åŒ€åˆ†å¸ƒ'}
ALGORITHMS = ['FedAvg', 'FedProx', 'FedScaffold', 'FedMoon', 'FedGen',
              'Per-FedAvg', 'FedDitto', 'FedRep', 'FedProto', 'FedPso', 'FedGwo',
              'FedGpro']

GLOBAL_ROUNDS = 100
LOCAL_EPOCHS = 5

# è‡ªåŠ¨æ£€æµ‹GPUå¹¶é…ç½®
try:
    import torch
    if torch.cuda.is_available():
        num_gpus = torch.cuda.device_count()
        GPU_IDS = list(range(num_gpus))  # è‡ªåŠ¨ä½¿ç”¨æ‰€æœ‰GPU
        print(f"âœ… æ£€æµ‹åˆ° {num_gpus} ä¸ªGPU: {GPU_IDS}")
        for i in range(num_gpus):
            print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
    else:
        GPU_IDS = [0]
        print("âš ï¸ æœªæ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨é»˜è®¤é…ç½® GPU 0")
except:
    GPU_IDS = [0]
    print("âš ï¸ æ— æ³•æ£€æµ‹GPUï¼Œä½¿ç”¨é»˜è®¤é…ç½® GPU 0")

SLOTS_PER_GPU = 2

# è¶…å‚æ•°é…ç½®
HYPERPARAMETERS = {
    'Uci': {
        'feature': {
            'FedAvg': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5},
            'FedProx': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.2},
            'FedScaffold': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5},
            'FedMoon': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5, 'mu': 1.0},
            'FedGen': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5},
            'Per-FedAvg': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5, 'beta': 0.003},
            'FedDitto': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.2, 'plocal_epochs': 3},
            'FedRep': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5},
            'FedProto': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5, 'lamda': 15},
            'FedPso': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5},
            'FedGwo': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5},
            'FedGpro': {'lr': 0.005, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.2, 'plocal_epochs': 3, 'fedgpro_phase2_agg': 'ditto', 'fedgpro_phase2_rounds': 50, 'fedgpro_phase_transition_threshold': 0.70},
        },
        'label': {
            'FedAvg': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedProx': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.1},
            'FedScaffold': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedMoon': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 1.2},
            'FedGen': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'Per-FedAvg': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'beta': 0.005},
            'FedDitto': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.1, 'plocal_epochs': 4},
            'FedRep': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedProto': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'lamda': 20},
            'FedPso': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedGwo': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedGpro': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.1, 'plocal_epochs': 4, 'fedgpro_phase2_agg': 'ditto', 'fedgpro_phase2_rounds': 50, 'fedgpro_phase_transition_threshold': 0.70},
        },
        'quantity': {
            'FedAvg': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedProx': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.05},
            'FedScaffold': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedMoon': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 1.0},
            'FedGen': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'Per-FedAvg': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'beta': 0.004},
            'FedDitto': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.05, 'plocal_epochs': 3},
            'FedRep': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedProto': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'lamda': 18},
            'FedPso': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedGwo': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedGpro': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.05, 'plocal_epochs': 3, 'fedgpro_phase2_agg': 'ditto', 'fedgpro_phase2_rounds': 50, 'fedgpro_phase_transition_threshold': 0.70},
        },
        'iid': {
            'FedAvg': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedProx': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.01},
            'FedScaffold': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedMoon': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 1.0},
            'FedGen': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'Per-FedAvg': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'beta': 0.003},
            'FedDitto': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.01, 'plocal_epochs': 2},
            'FedRep': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedProto': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'lamda': 15},
            'FedPso': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedGwo': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5},
            'FedGpro': {'lr': 0.007, 'batch_size': 64, 'local_epochs': 5, 'mu': 0.01, 'plocal_epochs': 2, 'fedgpro_phase2_agg': 'ditto', 'fedgpro_phase2_rounds': 50, 'fedgpro_phase_transition_threshold': 0.70},
        },
    },
    'Xinwang': {
        'feature': {
            'FedAvg': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedProx': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.12},
            'FedScaffold': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedMoon': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 1.5},
            'FedGen': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'Per-FedAvg': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'beta': 0.002},
            'FedDitto': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.12, 'plocal_epochs': 3},
            'FedRep': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedProto': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'lamda': 18},
            'FedPso': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedGwo': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedGpro': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.12, 'plocal_epochs': 3, 'fedgpro_phase2_agg': 'ditto', 'fedgpro_phase2_rounds': 50, 'fedgpro_phase_transition_threshold': 0.70},
        },
        'label': {
            'FedAvg': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedProx': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.08},
            'FedScaffold': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedMoon': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 1.3},
            'FedGen': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'Per-FedAvg': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'beta': 0.003},
            'FedDitto': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.08, 'plocal_epochs': 4},
            'FedRep': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedProto': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'lamda': 25},
            'FedPso': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedGwo': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedGpro': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.08, 'plocal_epochs': 4, 'fedgpro_phase2_agg': 'ditto', 'fedgpro_phase2_rounds': 50, 'fedgpro_phase_transition_threshold': 0.70},
        },
        'quantity': {
            'FedAvg': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedProx': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.08},
            'FedScaffold': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedMoon': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 1.0},
            'FedGen': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'Per-FedAvg': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'beta': 0.003},
            'FedDitto': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.08, 'plocal_epochs': 3},
            'FedRep': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedProto': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'lamda': 20},
            'FedPso': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedGwo': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedGpro': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.08, 'plocal_epochs': 3, 'fedgpro_phase2_agg': 'ditto', 'fedgpro_phase2_rounds': 50, 'fedgpro_phase_transition_threshold': 0.70},
        },
        'iid': {
            'FedAvg': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedProx': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.01},
            'FedScaffold': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedMoon': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 1.0},
            'FedGen': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'Per-FedAvg': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'beta': 0.002},
            'FedDitto': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.01, 'plocal_epochs': 2},
            'FedRep': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedProto': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'lamda': 15},
            'FedPso': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedGwo': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5},
            'FedGpro': {'lr': 0.006, 'batch_size': 128, 'local_epochs': 5, 'mu': 0.01, 'plocal_epochs': 2, 'fedgpro_phase2_agg': 'ditto', 'fedgpro_phase2_rounds': 50, 'fedgpro_phase_transition_threshold': 0.70},
        },
    },
}

progress_lock = threading.Lock()
gpu_status = {}  # {(gpu_id, slot_id): task_info}
completed_count = 0
failed_count = 0
total_experiments = 0
task_queue = None  # å°†åœ¨è¿è¡Œæ—¶åˆå§‹åŒ–
results_list = []
results_lock = threading.Lock()

for gpu_id in GPU_IDS:
    for slot_id in range(SLOTS_PER_GPU):
        gpu_status[(gpu_id, slot_id)] = None

# =============================================================================
# å·¥å…·å‡½æ•°
# =============================================================================

def _ts():
    """æ—¶é—´æˆ³"""
    return datetime.now().strftime('%H:%M:%S')

def check_missing_experiments():
    """æ£€æŸ¥ç¼ºå¤±çš„å®éªŒæ–‡ä»¶"""
    print("\n" + "="*80)
    print("æ£€æŸ¥ç¼ºå¤±çš„å®éªŒæ–‡ä»¶...")
    print("="*80)
    
    missing = []
    for dataset in DATASETS:
        for hetero in HETEROGENEITY_TYPES.keys():
            for algo in ALGORITHMS:
                # åŸºçº¿å®éªŒç›®å½•ç»“æ„: æ¯ä¸ªç®—æ³•é…ç½®ä¸€ä¸ªç‹¬ç«‹ç›®å½•
                # ç›®å½•åæ ¼å¼: {dataset}_{algo}_{hetero}
                results_dir = BASE_DIR / 'system' / 'results' / f"{dataset}_{algo}_{hetero}"
                # æ–‡ä»¶åæ ¼å¼: {dataset}_{algo}_{hetero}_*.h5 (ä¸å«testå‰ç¼€)
                file_prefix = f"{dataset}_{algo}_{hetero}"
                
                if not results_dir.exists():
                    missing.append((dataset, hetero, algo, 0))
                    continue
                
                # æŸ¥æ‰¾å®é™…çš„æ–‡ä»¶æ¨¡å¼ï¼ˆæ¯ä¸ªç›®å½•åº”è¯¥åªæœ‰5ä¸ªæ–‡ä»¶ï¼‰
                completed_files = list(results_dir.glob(f"{file_prefix}_*.h5"))
                completed = len(completed_files)
                
                if completed < 5:
                    missing.append((dataset, hetero, algo, completed))
    
    if missing:
        print(f"\nç¼ºå¤±å®éªŒæ•°: {len(missing)}")
        print(f"{'æ•°æ®é›†':<10} {'å¼‚è´¨æ€§':<10} {'ç®—æ³•':<20} {'å·²å®Œæˆ/éœ€è¦'}")
        print("-" * 80)
        for dataset, hetero, algo, completed in missing:
            print(f"{dataset:<10} {hetero:<10} {algo:<20} {completed}/5")
    else:
        print("\nâœ… æ‰€æœ‰å®éªŒå‡å·²å®Œæˆï¼")
    
    print("="*80 + "\n")
    return missing

def build_command(dataset, algorithm, hetero_type, gpu_id):
    """æ„å»ºè¿è¡Œå‘½ä»¤"""
    params = HYPERPARAMETERS[dataset][hetero_type][algorithm]
    model_name = 'credit'
    # ç›®æ ‡åç§°ï¼ˆç®€æ´æ ¼å¼ï¼‰: {hetero_type}
    goal_name = hetero_type
    # æ¨¡å‹ä¿å­˜ç›®å½•ï¼šæ¯ä¸ªå®éªŒé…ç½®ä¸€ä¸ªç‹¬ç«‹ç›®å½•
    save_folder = f'system/models/{dataset}_{algorithm}_{hetero_type}'
    
    cmd = [
        'python', '-u', 'system/main.py',
        '-data', dataset, '-m', model_name, '-algo', algorithm,
        '-did', str(gpu_id), '-gr', str(GLOBAL_ROUNDS),
        '-nc', '10', '-ls', str(params.get('local_epochs', LOCAL_EPOCHS)),
        '-lr', str(params['lr']), '-lbs', str(params['batch_size']),
        '-t', '5', '-go', goal_name,
        '-sfn', save_folder,
    ]
    
    # æ·»åŠ é¢å¤–å‚æ•°
    if 'mu' in params:
        cmd.extend(['-mu', str(params['mu'])])
    if 'plocal_epochs' in params:
        cmd.extend(['-pls', str(params['plocal_epochs'])])
    if 'beta' in params:
        cmd.extend(['-bt', str(params['beta'])])
    if 'lamda' in params:
        cmd.extend(['-lam', str(params['lamda'])])
    if 'fedgpro_phase2_agg' in params:
        cmd.extend(['--fedgpro_phase2_agg', params['fedgpro_phase2_agg']])
    if 'fedgpro_phase2_rounds' in params:
        cmd.extend(['--fedgpro_phase2_rounds', str(params['fedgpro_phase2_rounds'])])
    if 'fedgpro_phase_transition_threshold' in params:
        cmd.extend(['--fedgpro_phase_transition_threshold', str(params['fedgpro_phase_transition_threshold'])])
    
    return cmd

def worker_thread(gpu_id, slot_id):
    """Workerçº¿ç¨‹ - ä»é˜Ÿåˆ—è·å–ä»»åŠ¡å¹¶æ‰§è¡Œ"""
    global completed_count, failed_count, task_queue, results_list, results_lock
    
    while True:
        try:
            task = task_queue.get(timeout=1)
            if task is None:
                break
            
            dataset, hetero, algo, exp_id, current_time = task
            
            # æ›´æ–°GPUçŠ¶æ€
            with progress_lock:
                gpu_status[(gpu_id, slot_id)] = {
                    'dataset': dataset, 'hetero': hetero, 'algo': algo,
                    'exp_id': exp_id, 'start_time': time.time(),
                    'last_round': 0, 'current_time': current_time
                }
            
            print(f"[{_ts()}] ğŸš€ GPU{gpu_id}-æ§½ä½{slot_id}: {dataset}-{hetero}-{algo} [ç¬¬{current_time+1}æ¬¡/å…±5æ¬¡]")
            
            cmd = build_command(dataset, algo, hetero, gpu_id)
            start_time = time.time()
            success = False
            
            try:
                # åˆ›å»ºlogsç›®å½•
                logs_dir = BASE_DIR / 'logs'
                logs_dir.mkdir(exist_ok=True)
                log_file_path = logs_dir / f"{dataset}_{algo}_{hetero}.log"
                
                # stderr=subprocess.STDOUT å°†stderråˆå¹¶åˆ°stdout
                process = subprocess.Popen(
                    cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                    text=True, encoding='utf-8', errors='replace',
                    bufsize=1, universal_newlines=True
                )
                
                # æ‰“å¼€æ—¥å¿—æ–‡ä»¶å¹¶å®æ—¶å†™å…¥
                with open(log_file_path, 'w', encoding='utf-8') as log_file:
                    last_printed_round = -1  # è®°å½•ä¸Šæ¬¡æ‰“å°çš„roundï¼Œé¿å…é‡å¤
                    # æ¯20è½®æ‰“å°ä¸€æ¬¡
                    for line in process.stdout:
                        # å†™å…¥æ—¥å¿—æ–‡ä»¶
                        log_file.write(line)
                        log_file.flush()
                        
                        line = line.strip()
                        if not line:
                            continue
                        
                        # å¢å¼ºæ­£åˆ™ï¼šåŒ¹é… "Round 5", "Round number: 5", "Round 5 |", "----- Round 5 -----"
                        match = re.search(r'Round[:\s]+(?:number[:\s]+)?(\d+)', line, re.IGNORECASE)
                        if match:
                            round_num = int(match.group(1))
                            with progress_lock:
                                if (gpu_id, slot_id) in gpu_status and gpu_status[(gpu_id, slot_id)]:
                                    gpu_status[(gpu_id, slot_id)]['last_round'] = round_num
                            
                            # æ’é™¤round 0ï¼Œä¸”é¿å…é‡å¤æ‰“å°åŒä¸€è½®
                            if round_num > 0 and round_num % 20 == 0 and round_num != last_printed_round:
                                last_printed_round = round_num
                                elapsed_min = (time.time() - start_time) / 60
                                print(f"  [{_ts()}] {dataset}-{hetero}-{algo} [ç¬¬{current_time+1}æ¬¡] | Round {round_num}/{GLOBAL_ROUNDS} | {elapsed_min:.1f}åˆ†é’Ÿ")
                
                returncode = process.wait(timeout=7200)
                elapsed = time.time() - start_time
                
                if returncode == 0:
                    success = True
                    with progress_lock:
                        completed_count += 1
                    print(f"[{_ts()}] âœ… {dataset}-{hetero}-{algo} [ç¬¬{current_time+1}æ¬¡] å®Œæˆ ({elapsed/60:.1f}åˆ†é’Ÿ)")
                else:
                    with progress_lock:
                        failed_count += 1
                    print(f"[{_ts()}] âŒ {dataset}-{hetero}-{algo} [ç¬¬{current_time+1}æ¬¡] å¤±è´¥")
            
            except subprocess.TimeoutExpired:
                process.kill()
                elapsed = time.time() - start_time
                with progress_lock:
                    failed_count += 1
                print(f"[{_ts()}] â±ï¸ {dataset}-{hetero}-{algo} [ç¬¬{current_time+1}æ¬¡] è¶…æ—¶ ({elapsed/60:.1f}åˆ†é’Ÿ)")
            except Exception as e:
                elapsed = time.time() - start_time
                with progress_lock:
                    failed_count += 1
                print(f"[{_ts()}] ğŸ’¥ {dataset}-{hetero}-{algo} [ç¬¬{current_time+1}æ¬¡] å¼‚å¸¸: {str(e)}")
                import traceback
                print(f"  è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            
            # æ¸…é™¤GPUçŠ¶æ€
            with progress_lock:
                gpu_status[(gpu_id, slot_id)] = None
            
            with results_lock:
                results_list.append({
                    'dataset': dataset, 'hetero': hetero, 'algo': algo,
                    'success': success, 'elapsed': elapsed
                })
            
            task_queue.task_done()
        
        except Empty:
            continue

# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================

def run_experiments():
    """è¿è¡Œæ‰€æœ‰å®éªŒ"""
    global total_experiments, task_queue, results_list, results_lock
    
    print("\n" + "="*80)
    print("è”é‚¦å­¦ä¹ åŸºå‡†ç®—æ³•æ‰¹é‡å®éªŒ (ä¼˜åŒ–ç‰ˆ)")
    print("="*80)
    print(f"GPUé…ç½®: {len(GPU_IDS)}ä¸ªGPU Ã— {SLOTS_PER_GPU}æ§½ä½ = {len(GPU_IDS) * SLOTS_PER_GPU}å¹¶å‘")
    print(f"æ•°æ®é›†: {', '.join(DATASETS)}")
    print(f"ç®—æ³•æ•°: {len(ALGORITHMS)}")
    print(f"å¼‚è´¨æ€§: {', '.join(HETEROGENEITY_TYPES.keys())}")
    print("="*80)
    
    # æ£€æŸ¥ç¼ºå¤±æ–‡ä»¶
    missing = check_missing_experiments()
    
    if not missing:
        print("æ‰€æœ‰å®éªŒå·²å®Œæˆï¼Œæ— éœ€è¿è¡Œï¼")
        return
    
    # ç”Ÿæˆä»»åŠ¡é˜Ÿåˆ—
    task_queue = Queue()
    exp_id = 0
    for dataset, hetero, algo, completed in missing:
        # completedè¡¨ç¤ºå·²å®Œæˆçš„æ¬¡æ•°ï¼Œä¸‹ä¸€æ¬¡è¿è¡Œå°±æ˜¯completedæ¬¡ï¼ˆä»0å¼€å§‹ï¼‰
        task_queue.put((dataset, hetero, algo, exp_id, completed))
        exp_id += 1
    
    total_experiments = exp_id
    print(f"\néœ€è¦è¿è¡Œçš„å®éªŒæ•°: {total_experiments}\n")
    
    # å¯åŠ¨workerçº¿ç¨‹
    threads = []
    
    for gpu_id in GPU_IDS:
        for slot_id in range(SLOTS_PER_GPU):
            t = threading.Thread(
                target=worker_thread,
                args=(gpu_id, slot_id),
                daemon=True
            )
            t.start()
            threads.append(t)
    
    # ç›‘æ§è¿›åº¦
    start_time = time.time()
    while True:
        time.sleep(10)
        
        with progress_lock:
            running = sum(1 for s in gpu_status.values() if s is not None)
            comp = completed_count
            fail = failed_count
            remain = total_experiments - comp - fail
        
        if remain == 0 and running == 0:
            break
        
        print(f"\n[{_ts()}] è¿›åº¦: å®Œæˆ{comp} | å¤±è´¥{fail} | è¿è¡Œä¸­{running} | å‰©ä½™{remain}")
        
        with progress_lock:
            for (gpu_id, slot_id), info in gpu_status.items():
                if info:
                    elapsed_min = (time.time() - info['start_time']) / 60
                    r = info.get('last_round', 0)
                    ct = info.get('current_time', 0)
                    print(f"  GPU{gpu_id}-æ§½ä½{slot_id}: {info['dataset']}-{info['hetero']}-{info['algo']} [ç¬¬{ct+1}æ¬¡] | Round {r}/{GLOBAL_ROUNDS} | {elapsed_min:.1f}åˆ†é’Ÿ")
    
    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    for gpu_id in GPU_IDS:
        for slot_id in range(SLOTS_PER_GPU):
            task_queue.put(None)
    
    for t in threads:
        t.join()
    
    # æ‰“å°æ€»ç»“
    total_time = time.time() - start_time
    print("\n" + "="*80)
    print("å®éªŒå®Œæˆï¼")
    print(f"æ€»è€—æ—¶: {total_time/3600:.2f}å°æ—¶")
    print(f"å®Œæˆ: {completed_count}/{total_experiments}")
    print(f"å¤±è´¥: {failed_count}/{total_experiments}")
    print(f"æˆåŠŸç‡: {completed_count/total_experiments*100:.1f}%")
    print("="*80 + "\n")

if __name__ == '__main__':
    run_experiments()
