"""
ç»˜å›¾å·¥å…·å‡½æ•°
ç”¨äºè®­ç»ƒå®Œæˆåè‡ªåŠ¨ç”Ÿæˆç»“æœå¯è§†åŒ–å›¾è¡¨
"""

import h5py
import numpy as np
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯ï¼Œé€‚åˆæœåŠ¡å™¨ç¯å¢ƒ
import matplotlib.pyplot as plt
import os

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def plot_training_results(result_file, result_subdir=None, show_plot=False):
    """
    è‡ªåŠ¨ç»˜åˆ¶è®­ç»ƒç»“æœå¹¶ä¿å­˜åˆ°resultsç›®å½•
    
    Args:
        result_file: ç»“æœæ–‡ä»¶åï¼Œå¦‚ 'Uci_FedGWO_test_0.h5'
        result_subdir: ç»“æœå­ç›®å½•ï¼Œå¦‚ 'Uci_FedGWO_feature'
        show_plot: æ˜¯å¦æ˜¾ç¤ºå›¾è¡¨ï¼ˆæœåŠ¡å™¨ç¯å¢ƒå»ºè®®Falseï¼‰
    
    Returns:
        output_path: ä¿å­˜çš„å›¾ç‰‡è·¯å¾„
    """
    # è·å–æ­£ç¡®çš„ç»“æœç›®å½•è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    results_base = os.path.join(os.path.dirname(current_dir), "results")
    
    # æ„å»ºå®Œæ•´è·¯å¾„ï¼ˆåŒ…å«å­ç›®å½•ï¼‰
    if result_subdir:
        result_path = os.path.join(results_base, result_subdir, result_file)
    else:
        # å…¼å®¹æ—§çš„è°ƒç”¨æ–¹å¼
        result_path = os.path.join(results_base, result_file)
    
    if not os.path.exists(result_path):
        print(f"âš ï¸  ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {result_path}")
        return None
    
    try:
        # è¯»å–æ•°æ®
        with h5py.File(result_path, 'r') as f:
            test_acc = np.array(f['rs_test_acc'])
            test_auc = np.array(f.get('rs_test_auc', []))
            train_loss = np.array(f['rs_train_loss'])
        
        # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
        if len(test_acc) == 0:
            print(f"âš ï¸  æ•°æ®ä¸ºç©º: {result_path}")
            return None
        
        has_auc = len(test_auc) > 0
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        
        # 1. å‡†ç¡®ç‡æ›²çº¿
        ax1 = axes[0]
        ax1.plot(test_acc, linewidth=2, color='#2E86AB')
        ax1.set_title('Test Accuracy', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Round', fontsize=12)
        ax1.set_ylabel('Accuracy', fontsize=12)
        ax1.grid(True, alpha=0.3)
        ax1.axhline(y=test_acc.max(), color='r', linestyle='--', alpha=0.5, 
                    label=f'Max: {test_acc.max():.4f}')
        ax1.legend()
        
        # 2. æŸå¤±æ›²çº¿
        ax2 = axes[1]
        ax2.plot(train_loss, linewidth=2, color='#F18F01')
        ax2.set_title('Training Loss', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Round', fontsize=12)
        ax2.set_ylabel('Loss', fontsize=12)
        ax2.grid(True, alpha=0.3)
        ax2.axhline(y=train_loss.min(), color='r', linestyle='--', alpha=0.5,
                    label=f'Min: {train_loss.min():.4f}')
        ax2.legend()
        
        # 3. æ”¶æ•›åˆ†æï¼ˆé€‚ç”¨äºGWOç­‰ä¼˜åŒ–ç®—æ³•ï¼‰
        ax3 = axes[2]
        rounds = np.arange(len(test_acc))
        
        # å¦‚æœæ˜¯FedGWOï¼Œç»˜åˆ¶æ”¶æ•›å› å­a
        if 'GWO' in result_file or 'gwo' in result_file.lower():
            a_values = 2 - 2 * rounds / max(len(test_acc) - 1, 1)
            ax3.plot(a_values, linewidth=2, color='#6A994E')
            ax3.set_title('GWO Convergence Factor (a)', fontsize=14, fontweight='bold')
            ax3.set_ylabel('Factor a', fontsize=12)
            ax3.axhline(y=1.0, color='orange', linestyle='--', alpha=0.5,
                        label='Exploration/Exploitation (a=1)')
            ax3.fill_between(rounds, 0, a_values, where=(a_values > 1), 
                             alpha=0.2, color='blue', label='Exploration')
            ax3.fill_between(rounds, 0, a_values, where=(a_values <= 1), 
                             alpha=0.2, color='green', label='Exploitation')
        else:
            # å…¶ä»–ç®—æ³•ç»˜åˆ¶å‡†ç¡®ç‡æå‡æ›²çº¿
            acc_improvement = np.diff(test_acc, prepend=test_acc[0])
            ax3.plot(acc_improvement, linewidth=2, color='#A23B72')
            ax3.set_title('Accuracy Improvement', fontsize=14, fontweight='bold')
            ax3.set_ylabel('Î” Accuracy', fontsize=12)
            ax3.axhline(y=0, color='gray', linestyle='-', alpha=0.3)
        
        ax3.set_xlabel('Round', fontsize=12)
        ax3.grid(True, alpha=0.3)
        ax3.legend()
        
        plt.tight_layout()
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼ˆä¿å­˜åœ¨åŒä¸€å­ç›®å½•ä¸‹ï¼‰
        base_name = os.path.splitext(result_file)[0]
        if result_subdir:
            output_path = os.path.join(results_base, result_subdir, f'{base_name}_plot.png')
        else:
            output_path = os.path.join(results_base, f'{base_name}_plot.png')
        
        # ä¿å­˜å›¾è¡¨
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"âœ… è®­ç»ƒç»“æœå¯è§†åŒ–å·²ä¿å­˜: {output_path}")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print("\n" + "="*70)
        print("ğŸ“Š è®­ç»ƒç»“æœç»Ÿè®¡")
        print("="*70)
        print(f"  æœ€å¤§å‡†ç¡®ç‡: {test_acc.max():.4f} @ Round {test_acc.argmax()}")
        if has_auc:
            print(f"  æœ€å¤§AUC: {test_auc.max():.4f} @ Round {test_auc.argmax()}")
        print(f"  æœ€å°æŸå¤±: {train_loss.min():.4f} @ Round {train_loss.argmin()}")
        print(f"  æœ€ç»ˆå‡†ç¡®ç‡: {test_acc[-1]:.4f}")
        if has_auc:
            print(f"  æœ€ç»ˆAUC: {test_auc[-1]:.4f}")
        print(f"  æœ€ç»ˆæŸå¤±: {train_loss[-1]:.4f}")
        print(f"  æ€»è®­ç»ƒè½®æ•°: {len(test_acc)}")
        print("="*70)
        
        if show_plot:
            plt.show()
        else:
            plt.close()
        
        return output_path
        
    except Exception as e:
        print(f"âŒ ç»˜å›¾å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def compare_algorithms(result_files, algorithms, output_path='results/algorithm_comparison.png'):
    """
    å¯¹æ¯”å¤šä¸ªç®—æ³•çš„æ€§èƒ½
    
    Args:
        result_files: ç»“æœæ–‡ä»¶åˆ—è¡¨
        algorithms: ç®—æ³•åç§°åˆ—è¡¨
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
    """
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    colors = ['#2E86AB', '#A23B72', '#F18F01', '#6A994E', '#C73E1D']
    
    for i, (file, algo) in enumerate(zip(result_files, algorithms)):
        if not os.path.exists(file):
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file}")
            continue
            
        try:
            with h5py.File(file, 'r') as f:
                test_acc = np.array(f['rs_test_acc'])
                test_auc = np.array(f.get('rs_test_auc', []))
                train_loss = np.array(f['rs_train_loss'])
            
            color = colors[i % len(colors)]
            
            # å‡†ç¡®ç‡å¯¹æ¯”
            axes[0].plot(test_acc, linewidth=2, color=color, label=algo)
            
            # AUCå¯¹æ¯”ï¼ˆå¦‚æœæœ‰ï¼‰
            if len(test_auc) > 0:
                axes[1].plot(test_auc, linewidth=2, color=color, label=algo)
            
            # æŸå¤±å¯¹æ¯”
            axes[2].plot(train_loss, linewidth=2, color=color, label=algo)
            
        except Exception as e:
            print(f"âš ï¸  è¯»å–å¤±è´¥ {file}: {e}")
            continue
    
    axes[0].set_title('Test Accuracy Comparison', fontsize=14, fontweight='bold')
    axes[0].set_xlabel('Round', fontsize=12)
    axes[0].set_ylabel('Accuracy', fontsize=12)
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    axes[1].set_title('Test AUC Comparison', fontsize=14, fontweight='bold')
    axes[1].set_xlabel('Round', fontsize=12)
    axes[1].set_ylabel('AUC', fontsize=12)
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    axes[2].set_title('Training Loss Comparison', fontsize=14, fontweight='bold')
    axes[2].set_xlabel('Round', fontsize=12)
    axes[2].set_ylabel('Loss', fontsize=12)
    axes[2].legend()
    axes[2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ç®—æ³•å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")
    plt.close()
    
    return output_path
