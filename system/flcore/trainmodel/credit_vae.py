"""
Variational Autoencoder (VAE) for Credit Scoring Data

Designed for generating synthetic tabular data in federated learning scenarios.
Supports both UCI Credit Card (23 features) and Xinwang Credit (100 features) datasets.

Key Features:
- Reparameterization trick for stable training
- Reconstruction + KL divergence losses
- Specialized for tabular financial data

References:
- Kingma & Welling (2014). "Auto-Encoding Variational Bayes". ICLR 2014.
- Xu et al. (2019). "Modeling Tabular data using Conditional GAN". NeurIPS 2019.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


class CreditVAE(nn.Module):
    """
    Variational Autoencoder for Credit Scoring Tabular Data
    
    Supports two configurations:
    - UCI Credit Card: input_dim=23, latent_dim=16
    - Xinwang Credit: input_dim=100, latent_dim=32
    
    Architecture:
    Encoder: input â†’ hidden layers â†’ (mu, logvar)
    Decoder: latent â†’ hidden layers â†’ reconstructed input
    
    Loss = Reconstruction Loss + Î² Ã— KL Divergence
    """
    
    def __init__(self, input_dim, latent_dim=16, hidden_dims=None, beta=1.0):
        """
        Args:
            input_dim (int): Number of input features (23 for UCI, 100 for Xinwang)
            latent_dim (int): Dimension of latent space
            hidden_dims (list): Hidden layer dimensions. If None, auto-configured
            beta (float): Weight for KL divergence term (Î²-VAE)
        """
        super(CreditVAE, self).__init__()
        
        self.input_dim = input_dim
        self.latent_dim = latent_dim
        self.beta = beta
        
        # Auto-configure hidden dimensions based on input size
        # ä¼˜åŒ–ï¼šå¢åŠ VAEå®¹é‡ä»¥æé«˜ç”Ÿæˆè´¨é‡
        if hidden_dims is None:
            if input_dim <= 30:  # UCI-like small datasets
                hidden_dims = [128, 64, 32]  # åŸ[64, 32] â†’ å¢åŠ å®¹é‡
            else:  # Xinwang-like larger datasets
                hidden_dims = [256, 128, 64]  # åŸ[128, 64] â†’ å¢åŠ å®¹é‡
        
        self.hidden_dims = hidden_dims
        
        # Build Encoder
        encoder_layers = []
        prev_dim = input_dim
        
        for h_dim in hidden_dims:
            encoder_layers.append(nn.Linear(prev_dim, h_dim))
            encoder_layers.append(nn.BatchNorm1d(h_dim))
            encoder_layers.append(nn.ReLU())
            encoder_layers.append(nn.Dropout(0.2))
            prev_dim = h_dim
        
        self.encoder = nn.Sequential(*encoder_layers)
        
        # Latent space projection (mu and logvar)
        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)
        self.fc_logvar = nn.Linear(hidden_dims[-1], latent_dim)
        
        # Build Decoder (reverse of encoder)
        decoder_layers = []
        prev_dim = latent_dim
        
        for h_dim in reversed(hidden_dims):
            decoder_layers.append(nn.Linear(prev_dim, h_dim))
            decoder_layers.append(nn.BatchNorm1d(h_dim))
            decoder_layers.append(nn.ReLU())
            decoder_layers.append(nn.Dropout(0.2))
            prev_dim = h_dim
        
        # Final reconstruction layer (no activation for continuous features)
        decoder_layers.append(nn.Linear(hidden_dims[0], input_dim))
        
        self.decoder = nn.Sequential(*decoder_layers)
        
        # Initialize weights
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        """Xavier initialization for better gradient flow"""
        if isinstance(module, nn.Linear):
            nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                nn.init.constant_(module.bias, 0)
    
    def encode(self, x):
        """
        Encode input to latent distribution parameters
        
        Args:
            x (torch.Tensor): Input features [batch_size, input_dim]
        
        Returns:
            mu (torch.Tensor): Mean of latent distribution [batch_size, latent_dim]
            logvar (torch.Tensor): Log variance [batch_size, latent_dim]
        """
        h = self.encoder(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar
    
    def reparameterize(self, mu, logvar):
        """
        Reparameterization trick: z = mu + std * epsilon
        
        Args:
            mu (torch.Tensor): Mean [batch_size, latent_dim]
            logvar (torch.Tensor): Log variance [batch_size, latent_dim]
        
        Returns:
            z (torch.Tensor): Sampled latent code [batch_size, latent_dim]
        """
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        """
        Decode latent code to reconstructed input
        
        Args:
            z (torch.Tensor): Latent code [batch_size, latent_dim]
        
        Returns:
            recon_x (torch.Tensor): Reconstructed input [batch_size, input_dim]
        """
        # ç¡®ä¿zçš„ç±»å‹ä¸decoderæƒé‡ä¸€è‡´ï¼ˆä¿®å¤dtype mismatchï¼‰
        model_dtype = next(self.decoder.parameters()).dtype
        if z.dtype != model_dtype:
            z = z.to(model_dtype)
        return self.decoder(z)
    
    def forward(self, x):
        """
        Full forward pass: encode â†’ reparameterize â†’ decode
        
        Args:
            x (torch.Tensor): Input features [batch_size, input_dim]
        
        Returns:
            recon_x (torch.Tensor): Reconstructed input
            mu (torch.Tensor): Latent mean
            logvar (torch.Tensor): Latent log variance
        """
        # ç¡®ä¿è¾“å…¥ç±»å‹ä¸æ¨¡å‹æƒé‡ä¸€è‡´ï¼ˆè§£å†³dtype mismatché—®é¢˜ï¼‰
        model_dtype = next(self.encoder.parameters()).dtype
        if x.dtype != model_dtype:
            x = x.to(model_dtype)
        
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        recon_x = self.decode(z)
        return recon_x, mu, logvar
    
    def loss_function(self, recon_x, x, mu, logvar):
        """
        VAE loss = Reconstruction Loss + Î² Ã— KL Divergence
        
        Reconstruction Loss: MSE (for continuous tabular data)
        KL Divergence: KL(N(mu, sigma) || N(0, 1))
        
        Args:
            recon_x (torch.Tensor): Reconstructed input
            x (torch.Tensor): Original input
            mu (torch.Tensor): Latent mean
            logvar (torch.Tensor): Latent log variance
        
        Returns:
            loss (torch.Tensor): Total VAE loss
            recon_loss (torch.Tensor): Reconstruction component
            kl_loss (torch.Tensor): KL divergence component
        """
        # Reconstruction loss (MSE for tabular data)
        recon_loss = F.mse_loss(recon_x, x, reduction='mean')
        
        # KL divergence: -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)
        kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
        
        # Total loss with Î² weighting
        loss = recon_loss + self.beta * kl_loss
        
        return loss, recon_loss, kl_loss
    
    def sample(self, num_samples, device='cuda'):
        """
        Generate synthetic samples from the learned distribution
        
        Args:
            num_samples (int): Number of samples to generate
            device (str): Device to generate samples on
        
        Returns:
            samples (torch.Tensor): Generated samples [num_samples, input_dim]
        """
        self.eval()
        with torch.no_grad():
            # Sample from standard normal distribution
            z = torch.randn(num_samples, self.latent_dim).to(device)
            # Decode to feature space
            samples = self.decode(z)
        return samples
    
    def reconstruct(self, x):
        """
        Reconstruct input (for quality assessment)
        
        Args:
            x (torch.Tensor): Input features
        
        Returns:
            recon_x (torch.Tensor): Reconstructed input
        """
        self.eval()
        with torch.no_grad():
            recon_x, _, _ = self.forward(x)
        return recon_x


class ConditionalCreditVAE(nn.Module):
    """
    Conditional Variational Autoencoder (CVAE) for Credit Scoring Data
    
    Key Improvement: æ·»åŠ ç±»åˆ«æ¡ä»¶ï¼Œå®ç°å¯æ§ç”Ÿæˆ
    - è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼ˆå¯æŒ‡å®šç”Ÿæˆå°‘æ•°ç±»æ ·æœ¬ï¼‰
    - æå‡ç”Ÿæˆè´¨é‡ï¼ˆç±»åˆ«ä¿¡æ¯å¼•å¯¼ç”Ÿæˆï¼‰
    - é€‚åˆè”é‚¦å­¦ä¹ å¼‚è´¨æ€§åœºæ™¯
    
    Architecture:
    Encoder: (input + class_embedding) â†’ hidden â†’ (mu, logvar)
    Decoder: (latent + class_embedding) â†’ hidden â†’ reconstructed input
    
    Usage:
        cvae.encode(x, y)  # ç¼–ç æ—¶åŠ å…¥ç±»åˆ«æ¡ä»¶
        cvae.decode(z, y)  # è§£ç æ—¶æŒ‡å®šç›®æ ‡ç±»åˆ«
    """
    
    def __init__(self, input_dim, num_classes, latent_dim=16, hidden_dims=None, 
                 beta=1.0, class_embedding_dim=10):
        """
        Args:
            input_dim (int): è¾“å…¥ç‰¹å¾ç»´åº¦ (23 for UCI, 100 for Xinwang)
            num_classes (int): ç±»åˆ«æ•°é‡ (é€šå¸¸ä¸º2ï¼ŒäºŒåˆ†ç±»ä¿¡ç”¨è¯„åˆ†)
            latent_dim (int): æ½œåœ¨ç©ºé—´ç»´åº¦
            hidden_dims (list): éšè—å±‚ç»´åº¦
            beta (float): KLæŸå¤±æƒé‡ï¼ˆÎ²-VAEï¼‰
            class_embedding_dim (int): ç±»åˆ«åµŒå…¥ç»´åº¦
        """
        super(ConditionalCreditVAE, self).__init__()
        
        self.input_dim = input_dim
        self.num_classes = num_classes
        self.latent_dim = latent_dim
        self.beta = beta
        self.class_embedding_dim = class_embedding_dim
        
        # Auto-configure hidden dimensions
        if hidden_dims is None:
            if input_dim <= 30:
                hidden_dims = [128, 64, 32]  # UCI
            else:
                hidden_dims = [256, 128, 64]  # Xinwang
        self.hidden_dims = hidden_dims
        
        # === ç±»åˆ«åµŒå…¥å±‚ ===
        self.class_embedding = nn.Embedding(num_classes, class_embedding_dim)
        
        # === Build Encoder (input + class_embedding) ===
        encoder_layers = []
        prev_dim = input_dim + class_embedding_dim  # æ‹¼æ¥è¾“å…¥å’Œç±»åˆ«åµŒå…¥
        
        for h_dim in hidden_dims:
            encoder_layers.append(nn.Linear(prev_dim, h_dim))
            encoder_layers.append(nn.BatchNorm1d(h_dim))
            encoder_layers.append(nn.ReLU())
            encoder_layers.append(nn.Dropout(0.2))
            prev_dim = h_dim
        
        self.encoder = nn.Sequential(*encoder_layers)
        
        # Latent space projection
        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)
        self.fc_logvar = nn.Linear(hidden_dims[-1], latent_dim)
        
        # === Build Decoder (latent + class_embedding) ===
        decoder_layers = []
        prev_dim = latent_dim + class_embedding_dim  # æ‹¼æ¥æ½œåœ¨å˜é‡å’Œç±»åˆ«åµŒå…¥
        
        for h_dim in reversed(hidden_dims):
            decoder_layers.append(nn.Linear(prev_dim, h_dim))
            decoder_layers.append(nn.BatchNorm1d(h_dim))
            decoder_layers.append(nn.ReLU())
            decoder_layers.append(nn.Dropout(0.2))
            prev_dim = h_dim
        
        decoder_layers.append(nn.Linear(hidden_dims[0], input_dim))
        self.decoder = nn.Sequential(*decoder_layers)
        
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                nn.init.constant_(module.bias, 0)
        elif isinstance(module, nn.Embedding):
            nn.init.normal_(module.weight, mean=0, std=0.1)
    
    def encode(self, x, y):
        """
        æ¡ä»¶ç¼–ç ï¼šè¾“å…¥ç‰¹å¾ + ç±»åˆ«æ ‡ç­¾ â†’ æ½œåœ¨åˆ†å¸ƒå‚æ•°
        
        Args:
            x: è¾“å…¥ç‰¹å¾ [batch_size, input_dim]
            y: ç±»åˆ«æ ‡ç­¾ [batch_size] (æ•´æ•°)
        
        Returns:
            mu, logvar: æ½œåœ¨åˆ†å¸ƒå‚æ•°
        """
        # ç±»åˆ«åµŒå…¥
        class_emb = self.class_embedding(y)  # [batch_size, class_embedding_dim]
        
        # æ‹¼æ¥è¾“å…¥å’Œç±»åˆ«åµŒå…¥
        x_cond = torch.cat([x, class_emb], dim=1)  # [batch_size, input_dim + emb_dim]
        
        # ç¼–ç 
        h = self.encoder(x_cond)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar
    
    def reparameterize(self, mu, logvar):
        """é‡å‚æ•°åŒ–æŠ€å·§"""
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z, y):
        """
        æ¡ä»¶è§£ç ï¼šæ½œåœ¨å˜é‡ + ç±»åˆ«æ ‡ç­¾ â†’ é‡æ„ç‰¹å¾
        
        Args:
            z: æ½œåœ¨å˜é‡ [batch_size, latent_dim]
            y: ç±»åˆ«æ ‡ç­¾ [batch_size] (æ•´æ•°)
        
        Returns:
            recon_x: é‡æ„ç‰¹å¾ [batch_size, input_dim]
        """
        # ç±»åˆ«åµŒå…¥
        class_emb = self.class_embedding(y)  # [batch_size, class_embedding_dim]
        
        # æ‹¼æ¥æ½œåœ¨å˜é‡å’Œç±»åˆ«åµŒå…¥
        z_cond = torch.cat([z, class_emb], dim=1)  # [batch_size, latent_dim + emb_dim]
        
        # ç¡®ä¿dtypeä¸€è‡´
        model_dtype = next(self.decoder.parameters()).dtype
        if z_cond.dtype != model_dtype:
            z_cond = z_cond.to(model_dtype)
        
        # è§£ç 
        return self.decoder(z_cond)
    
    def forward(self, x, y):
        """
        å®Œæ•´å‰å‘ä¼ æ’­ï¼šç¼–ç  â†’ é‡å‚æ•°åŒ– â†’ è§£ç 
        
        Args:
            x: è¾“å…¥ç‰¹å¾
            y: ç±»åˆ«æ ‡ç­¾
        
        Returns:
            recon_x, mu, logvar
        """
        model_dtype = next(self.encoder.parameters()).dtype
        if x.dtype != model_dtype:
            x = x.to(model_dtype)
        
        mu, logvar = self.encode(x, y)
        z = self.reparameterize(mu, logvar)
        recon_x = self.decode(z, y)
        return recon_x, mu, logvar
    
    def loss_function(self, recon_x, x, mu, logvar):
        """è®¡ç®—VAEæŸå¤±ï¼ˆä¸æ ‡å‡†VAEç›¸åŒï¼‰"""
        recon_loss = F.mse_loss(recon_x, x, reduction='mean')
        kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
        loss = recon_loss + self.beta * kl_loss
        return loss, recon_loss, kl_loss
    
    def sample(self, num_samples, class_id, device='cuda'):
        """
        ç”ŸæˆæŒ‡å®šç±»åˆ«çš„æ ·æœ¬ï¼ˆCVAEæ ¸å¿ƒåŠŸèƒ½ï¼‰
        
        Args:
            num_samples: ç”Ÿæˆæ ·æœ¬æ•°é‡
            class_id: ç›®æ ‡ç±»åˆ«ï¼ˆ0æˆ–1ï¼‰
            device: è®¾å¤‡
        
        Returns:
            samples: ç”Ÿæˆçš„æ ·æœ¬ [num_samples, input_dim]
        """
        self.eval()
        with torch.no_grad():
            # ä»æ ‡å‡†æ­£æ€åˆ†å¸ƒé‡‡æ ·
            z = torch.randn(num_samples, self.latent_dim).to(device)
            
            # åˆ›å»ºç±»åˆ«æ ‡ç­¾å¼ é‡
            y = torch.full((num_samples,), class_id, dtype=torch.long).to(device)
            
            # æ¡ä»¶è§£ç 
            samples = self.decode(z, y)
        return samples


class CreditVAEWithClassifier(nn.Module):
    """
    Joint VAE + Classifier for FedVPS Phase 1
    
    Combines VAE for virtual data generation with a classifier for 
    supervised learning. Used in Phase 1 of FedVPS algorithm.
    
    Training flow:
    1. Real data â†’ VAE â†’ Virtual data
    2. Virtual data â†’ Classifier â†’ Classification loss
    3. Virtual features â†’ Prototype loss
    4. Total loss = Classification + Reconstruction + KL + Prototype
    """
    
    def __init__(self, vae, classifier):
        """
        Args:
            vae (CreditVAE): Pre-initialized VAE
            classifier (nn.Module): Classification model from credit.py
        """
        super(CreditVAEWithClassifier, self).__init__()
        
        self.vae = vae
        self.classifier = classifier
        
        # Loss weights (will be set from args)
        self.lambda_cls = 1.0
        self.lambda_recon = 1.0
        self.lambda_kl = 0.01
        self.lambda_proto = 0.1
    
    def set_loss_weights(self, lambda_cls=1.0, lambda_recon=1.0, 
                        lambda_kl=0.01, lambda_proto=0.1):
        """Set loss combination weights"""
        self.lambda_cls = lambda_cls
        self.lambda_recon = lambda_recon
        self.lambda_kl = lambda_kl
        self.lambda_proto = lambda_proto
    
    def forward(self, x):
        """
        Forward pass for training
        
        Args:
            x (torch.Tensor): Input features [batch_size, input_dim]
        
        Returns:
            virtual_x (torch.Tensor): Generated virtual features
            cls_output (torch.Tensor): Classification logits
            mu, logvar: VAE latent parameters
        """
        # VAE forward: generate virtual data
        virtual_x, mu, logvar = self.vae(x)
        
        # Classify virtual data
        cls_output = self.classifier(virtual_x)
        
        return virtual_x, cls_output, mu, logvar
    
    def compute_loss(self, x, y, prototypes=None):
        """
        Compute joint loss for Phase 1 training
        
        Args:
            x (torch.Tensor): Input features
            y (torch.Tensor): Labels
            prototypes (dict): Class prototypes {class_id: prototype_tensor}
        
        Returns:
            total_loss, cls_loss, recon_loss, kl_loss, proto_loss
        """
        # Forward pass
        virtual_x, cls_output, mu, logvar = self.forward(x)
        
        # 1. Classification loss
        cls_loss = F.cross_entropy(cls_output, y)
        
        # 2. VAE reconstruction loss
        recon_loss = F.mse_loss(virtual_x, x, reduction='mean')
        
        # 3. KL divergence
        kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
        
        # 4. Prototype loss (if prototypes provided)
        proto_loss = torch.tensor(0.0, device=x.device)
        if prototypes is not None and len(prototypes) > 0:
            # Virtual features should be close to class prototypes
            for i, label in enumerate(y):
                class_id = label.item()
                if class_id in prototypes:
                    # Distance between virtual feature and prototype
                    proto_loss += F.mse_loss(virtual_x[i], prototypes[class_id])
            proto_loss = proto_loss / len(y)
        
        # Total weighted loss
        total_loss = (self.lambda_cls * cls_loss + 
                     self.lambda_recon * recon_loss + 
                     self.lambda_kl * kl_loss + 
                     self.lambda_proto * proto_loss)
        
        return total_loss, cls_loss, recon_loss, kl_loss, proto_loss
    
    def generate_virtual_data(self, num_samples, device='cuda'):
        """Generate virtual data for sharing"""
        return self.vae.sample(num_samples, device)


def create_credit_vae(input_dim, latent_dim=None, dataset_name='UCI', 
                     num_classes=2, use_conditional=True):
    """
    Factory function to create appropriate VAE for dataset
    
    Args:
        input_dim (int): Number of features
        latent_dim (int): Latent dimension (auto-configured if None)
        dataset_name (str): 'UCI' or 'Xinwang'
        num_classes (int): ç±»åˆ«æ•°é‡ï¼ˆé»˜è®¤2ï¼ŒäºŒåˆ†ç±»ï¼‰
        use_conditional (bool): æ˜¯å¦ä½¿ç”¨æ¡ä»¶VAEï¼ˆæ¨èTrueï¼‰
    
    Returns:
        vae (CreditVAE or ConditionalCreditVAE): Configured VAE model
    """
    if latent_dim is None:
        # Auto-configure latent dimension
        latent_dim = 16 if input_dim <= 30 else 32
    
    # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨CVAEï¼ˆæ¡ä»¶VAEï¼‰
    if use_conditional:
        if dataset_name.lower() == 'uci' or input_dim <= 30:
            vae = ConditionalCreditVAE(
                input_dim=input_dim,
                num_classes=num_classes,
                latent_dim=latent_dim,
                hidden_dims=[128, 64, 32],  # å¢å¼ºå®¹é‡
                beta=1.0,  # åˆå§‹Î²å€¼ï¼ˆä¼šè¢«åŠ¨æ€è°ƒåº¦å™¨è¦†ç›–ï¼‰
                class_embedding_dim=10
            )
        else:
            vae = ConditionalCreditVAE(
                input_dim=input_dim,
                num_classes=num_classes,
                latent_dim=latent_dim,
                hidden_dims=[256, 128, 64],  # Xinwangå¢å¼ºå®¹é‡
                beta=1.0,
                class_embedding_dim=10
            )
    else:
        # ä¿ç•™æ ‡å‡†VAEï¼ˆå‘åå…¼å®¹ï¼‰
        if dataset_name.lower() == 'uci' or input_dim <= 30:
            vae = CreditVAE(
                input_dim=input_dim,
                latent_dim=latent_dim,
                hidden_dims=[64, 32],
                beta=1.0
            )
        else:
            vae = CreditVAE(
                input_dim=input_dim,
                latent_dim=latent_dim,
                hidden_dims=[128, 64],
                beta=1.0
            )
    
    return vae
