"""
FedGpro Client: Federated Global Prototype Learning

Two-phase federated learning client for credit scoring with privacy-preserving
virtual data generation.

Phase 1: VAE Training + Prototype Learning (No Parameter Aggregation)
- Train VAE + Classifier jointly with prototype regularization
- Generate virtual data when accuracy threshold is met
- Add differential privacy noise to virtual data
- Upload: accuracy, prototypes, noisy virtual data

Phase 2: Federated Training with Virtual Data (Flexible Aggregation)
- Train on mixed data (real + shared virtual)
- Server uses configurable aggregation algorithm (FedAvg/FedCS/FedProx/etc.)
- Standard federated learning workflow

Author: [Your Name]
Date: 2025-12-16
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import time
import copy
from collections import defaultdict
from flcore.clients.clientbase import Client
from flcore.trainmodel.credit_vae import CreditVAE, create_credit_vae
from sklearn.preprocessing import label_binarize
from sklearn import metrics


class PrototypeAlignmentLayer(nn.Module):
    """
    åŸå‹å¯¹é½å±‚ï¼šæ˜¾å¼ç‰¹å¾å¢å¼ºæ¨¡å—
    
    åŠŸèƒ½ï¼šåœ¨ç‰¹å¾è¿›å…¥åˆ†ç±»å™¨å‰ï¼Œå°†ç‰¹å¾å‘å…¨å±€åŸå‹æ–¹å‘è°ƒæ•´ï¼Œ
    å¢å¼ºæ¨¡å‹å¯¹ç±»åˆ«å…±äº«è¡¨å¾çš„å­¦ä¹ èƒ½åŠ›ã€‚
    
    ä¸åŸå‹æŸå¤±çš„å…³ç³»ï¼š
    - åŸå‹æŸå¤±ï¼šè®­ç»ƒæ—¶çš„ç›‘ç£ä¿¡å·ï¼ˆè®©VAEå­¦ä¼šç”Ÿæˆæ¥è¿‘åŸå‹çš„ç‰¹å¾ï¼‰
    - åŸå‹å¯¹é½å±‚ï¼šæ¨ç†æ—¶çš„æ˜¾å¼å¢å¼ºï¼ˆå³ä½¿VAEæ²¡å­¦å¥½ä¹Ÿèƒ½æ‹‰å›æ¥ï¼‰
    
    Args:
        feature_dim: ç‰¹å¾ç»´åº¦
        alpha: åŸå‹å¢å¼ºå¼ºåº¦ï¼Œé»˜è®¤0.3
    """
    def __init__(self, feature_dim, alpha=0.3):
        super().__init__()
        self.projector = nn.Linear(feature_dim, feature_dim)
        self.alpha = alpha
        
    def forward(self, features, prototypes):
        """
        Args:
            features: [batch_size, feature_dim] - VAEç”Ÿæˆçš„ç‰¹å¾
            prototypes: [num_classes, feature_dim] - å…¨å±€åŸå‹å¼ é‡
        Returns:
            enhanced_features: åŸå‹å¢å¼ºåçš„ç‰¹å¾
        """
        if prototypes is None or prototypes.shape[0] == 0:
            return features
        
        # Step 1: ç‰¹å¾æŠ•å½±ï¼ˆå¯å­¦ä¹ å˜æ¢ï¼‰
        features_proj = self.projector(features)
        
        # Step 2: è®¡ç®—ç‰¹å¾ä¸å„åŸå‹çš„ç›¸ä¼¼åº¦
        similarity = torch.mm(features_proj, prototypes.T) / 0.5  # æ¸©åº¦=0.5
        weights = F.softmax(similarity, dim=1)  # [batch_size, num_classes]
        
        # Step 3: åŠ æƒåŸå‹å‘é‡
        proto_weighted = torch.mm(weights, prototypes)  # [batch_size, feature_dim]
        
        # Step 4: æ®‹å·®è¿æ¥ï¼ˆä¿ç•™åŸå§‹ç‰¹å¾+åŸå‹å¢å¼ºï¼‰
        enhanced_features = features + self.alpha * proto_weighted
        
        return enhanced_features


class clientGpro(Client):
    """
    FedGpro Client Implementation
    
    Key Features:
    - Two-phase training protocol
    - VAE-based virtual data generation
    - Prototype learning for feature regularization
    - Differential privacy via Laplace/Gaussian noise
    - Threshold-based phase transition
    
    Args:
        args: Arguments containing VPS-specific parameters
            - fedgpro_phase: Current phase (1 or 2)
            - fedgpro_epsilon: Privacy budget for DP noise
            - fedgpro_noise_type: 'laplace' or 'gaussian'
            - fedgpro_lambda_cls: Weight for classification loss
            - fedgpro_lambda_recon: Weight for reconstruction loss
            - fedgpro_lambda_kl: Weight for KL divergence
            - fedgpro_lambda_proto: Weight for prototype loss
            - fedgpro_proto_momentum: EMA momentum for prototype update
            - fedgpro_latent_dim: VAE latent dimension
    """
    
    def __init__(self, args, id, train_samples, test_samples, **kwargs):
        super().__init__(args, id, train_samples, test_samples, **kwargs)
        
        # Ensure model is float64
        self.model = self.model.double()
        
        # Phase control
        self.current_phase = getattr(args, 'fedgpro_phase', 1)
        
        # Privacy parameters (optional, default: no noise)
        self.epsilon = getattr(args, 'fedgpro_epsilon', None)  # None = disabled
        self.noise_type = getattr(args, 'fedgpro_noise_type', None)  # None, 'laplace', 'gaussian'
        self.delta = getattr(args, 'fedgpro_delta', 1e-5)  # For Gaussian noise
        
        # Ditto-style personalized model (Phase2 only)
        self.model_per = None
        self.optimizer_per = None
        self.mu_ditto = getattr(args, 'mu', 0.01)  # Ditto regularization parameter
        self.plocal_epochs = getattr(args, 'plocal_epochs', 3)  # Personalized training epochs
        
        # Component switches for ablation study
        self.use_vae_generation = getattr(args, 'fedgpro_use_vae', True)  # Default: enabled
        self.use_prototype_loss = getattr(args, 'fedgpro_use_prototype', True)  # Default: enabled
        
        # Generated data ratio (for ablation study)
        self.gen_data_ratio = getattr(args, 'fedgpro_gen_data_ratio', 1.0)  # Default: 100% (1.0)
        
        # Loss weights - ä¼˜åŒ–ç­–ç•¥
        self.lambda_cls = getattr(args, 'fedgpro_lambda_cls', 10.0)  # å¢åŠ åˆ°10.0ä»¥å¼ºåŒ–åˆ†ç±»
        
        # Dataset-specific loss weights
        if 'Xinwang' in args.dataset:
            # Xinwang: é«˜ç»´æ•°æ®ï¼Œå¢å¼ºé‡æ„è´¨é‡å’ŒåŸå‹çº¦æŸ
            self.lambda_recon = getattr(args, 'fedgpro_lambda_recon', 1.5)  # å¢å¼ºé‡æ„ï¼š1.0 â†’ 1.5
            self.lambda_kl = getattr(args, 'fedgpro_lambda_kl', 0.1)  # Optimized: 0.1 (best from ablation)
            self.lambda_proto = getattr(args, 'fedgpro_lambda_proto', 0.1)  # Optimized: 0.1 (best from ablation)
        else:
            # Uci: ä½ç»´æ•°æ®ï¼Œä½¿ç”¨æ ‡å‡†æƒé‡
            self.lambda_recon = getattr(args, 'fedgpro_lambda_recon', 1.0)
            self.lambda_kl = getattr(args, 'fedgpro_lambda_kl', 0.01)
            self.lambda_proto = getattr(args, 'fedgpro_lambda_proto', 0.5)  # åŸ0.1 â†’ 0.3 â†’ 0.5
        
        # Prototype learning
        self.proto_momentum = getattr(args, 'fedgpro_proto_momentum', 0.9)
        self.prototypes = {}  # {class_id: prototype_tensor}
        
        # Phase 1: VAE model - Get correct input dimension based on model architecture
        if hasattr(self.model, 'input_dim'):
            # For UciCreditNet and XinwangCreditNet which have input_dim attribute
            input_dim = self.model.input_dim
        elif hasattr(self.model, 'fc1'):
            # Fallback: try to get from first layer
            input_dim = self.model.fc1.in_features
        elif hasattr(self.model, 'input_embedding'):
            # For XinwangCreditNet's input_embedding layer
            input_dim = self.model.input_embedding[0].in_features
        else:
            # Ultimate fallback based on dataset name
            if 'Xinwang' in args.dataset:
                input_dim = 100
            else:
                input_dim = 23
        
        # é’ˆå¯¹Xinwangæ‰©å¤§éšç©ºé—´å®¹é‡ä»¥å¤„ç†é«˜ç»´ç‰¹å¾
        if 'Xinwang' in args.dataset:
            latent_dim = getattr(args, 'fedgpro_latent_dim', 32)  # å¼ºåˆ¶32ç»´
        else:
            latent_dim = getattr(args, 'fedgpro_latent_dim', 16 if input_dim <= 30 else 32)
        
        # âœ¨ é˜¶æ®µ1ï¼šå¯ç”¨CVAEï¼ˆæ¡ä»¶VAEï¼‰
        self.use_cvae = getattr(args, 'fedgpro_use_cvae', True)  # é»˜è®¤True
        
        self.vae = create_credit_vae(
            input_dim=input_dim,
            latent_dim=latent_dim,
            dataset_name=args.dataset,
            num_classes=self.num_classes,
            use_conditional=self.use_cvae  # CVAE or standard VAE
        ).to(self.device).double()
        
        # âš¡ é˜¶æ®µ2ï¼šåŠ¨æ€Î²è°ƒåº¦å™¨
        self.beta_schedule_enabled = getattr(args, 'fedgpro_beta_schedule', True)  # é»˜è®¤True
        self.beta_warmup_epochs = getattr(args, 'fedgpro_beta_warmup', 3)  # å‰3è½®ä½Î²
        self.beta_min = getattr(args, 'fedgpro_beta_min', 0.001)  # æœ€å°Î²
        self.beta_max = self.lambda_kl  # æœ€å¤§Î² = åŸKLæƒé‡
        self.current_beta = self.beta_min  # å½“å‰Î²å€¼ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰
        
        # VAE optimizer
        self.vae_optimizer = torch.optim.Adam(
            self.vae.parameters(),
            lr=getattr(args, 'fedgpro_vae_lr', 0.001)
        )
        
        # Baseline VAE (for feature importance computation via contrastive learning)
        self.vae_baseline = None  # Created on-demand
        self.vae_baseline_optimizer = None
        self.feature_importance = None  # Computed from VAE comparison
        self.baseline_epochs = getattr(args, 'fedgpro_baseline_epochs', 50)  # Fixed training epochs
        
        # Phase 1 metrics
        self.accuracy = 0.0
        self.virtual_data = []  # List of (features, labels)
        self.threshold_met = False
        self.virtual_data_generated = False  # æ ‡è®°è™šæ‹Ÿæ•°æ®æ˜¯å¦å·²ç”Ÿæˆï¼ˆé”å®šï¼‰
        
        # ğŸ”¥ Phase 2æœºåˆ¶æ ‡è®°ï¼šæ˜¯å¦è´¡çŒ®è™šæ‹Ÿæ•°æ®
        self.contributes_virtual_data = False  # Phase 2ä¸­æ˜¯å¦è´¡çŒ®è™šæ‹Ÿæ•°æ®ï¼ˆè¾¾æ ‡å®¢æˆ·ç«¯=Trueï¼Œæœªè¾¾æ ‡=Falseï¼‰
        
        # Phase 1: Early stopping tracking
        self.accuracy_history = []  # Track accuracy for last N epochs
        self.early_stopped = False  # Flag indicating if client has converged
        self.current_threshold = 0.70  # Dynamic threshold from server (updated each round)
        self.convergence_window = 5  # Check last 5 epochs
        self.convergence_threshold = 0.005  # 0.5% fluctuation threshold
        
        # Phase 2: Shared virtual data storage
        self.shared_virtual_data = []
        
        # Phase 2: Algorithm type (set by server during transition)
        self.phase2_algorithm = 'fedavg'  # Default
        
        # Phase 2: Algorithm-specific states
        self.prev_model = None  # For MOON contrastive learning
        self.c_local = None  # For SCAFFOLD control variates
        self.c_global = None
        self.personalized_model = None  # For Ditto, pFedMe
        self.val_acc = 0.0  # For FedGWO ranking
        
        # For FedPSO (Particle Swarm Optimization)
        self.velocity = None  # PSO velocity
        self.pbest_model = None  # Individual best model
        self.gbest_model = None  # Global best model
        
        # ==================== Personalization Mechanism (Ditto-style) ====================
        # Personalized model for each client (maintained locally)
        self.mu = getattr(args, 'mu', 0.01)  # Regularization weight between global and personalized
        self.plocal_epochs = getattr(args, 'plocal_epochs', 1)  # Personalization training epochs
        
        # Create personalized model (deep copy of global model)
        self.model_per = copy.deepcopy(self.model)
        
        # Personalized optimizer with regularization
        from flcore.optimizers.fedoptimizer import PerturbedGradientDescent
        self.optimizer_per = PerturbedGradientDescent(
            self.model_per.parameters(), 
            lr=self.learning_rate, 
            mu=self.mu
        )
        
        # Learning rate scheduler for personalized model
        self.learning_rate_scheduler_per = torch.optim.lr_scheduler.ExponentialLR(
            optimizer=self.optimizer_per,
            gamma=args.learning_rate_decay_gamma
        )
        print(f"  Client {self.id}: Personalization enabled (mu={self.mu}, plocal_epochs={self.plocal_epochs})")
        self.pso_w = 0.9  # Inertia weight
        self.pso_c1 = 2.0  # Cognitive parameter
        self.pso_c2 = 2.0  # Social parameter
        self.pso_r1 = 0.5  # Random number 1
        self.pso_r2 = 0.5  # Random number 2
        self.pso_v_max = 0.5  # Maximum velocity ratio
        
        # For FedProto
        self.protos = None  # Local prototypes collected during training
        
        # For pFedMe
        self.local_params = None
        self.personalized_params = None
        
        # Global prototypes from server (Phase 1 and FedProto)
        self.global_prototypes = {}
        
        # åŸå‹å¯¹é½å±‚ï¼ˆå·²ç¦ç”¨ - ç®€åŒ–æ¨¡å‹ï¼‰
        # self.proto_align_layer = PrototypeAlignmentLayer(
        #     feature_dim=input_dim,  # ä¸VAEè¾“å…¥ç»´åº¦ä¸€è‡´
        #     alpha=0.3  # åŸå‹å¢å¼ºå¼ºåº¦
        # ).to(self.device).double()
        
        # ä¸ºåŸå‹å¯¹é½å±‚æ·»åŠ ä¼˜åŒ–å™¨ï¼ˆå·²ç¦ç”¨ï¼‰
        # self.proto_align_optimizer = torch.optim.Adam(
        #     self.proto_align_layer.parameters(),
        #     lr=getattr(args, 'fedgpro_proto_align_lr', 0.001)
        # )
    
    def set_phase(self, phase):
        """Switch between Phase 1 and Phase 2"""
        self.current_phase = phase
    
    def get_vae_parameters(self):
        """è¿”å›VAEå‚æ•°ç”¨äºè”é‚¦èšåˆ"""
        return {
            'encoder': self.vae.encoder.state_dict(),
            'fc_mu': self.vae.fc_mu.state_dict(),
            'fc_logvar': self.vae.fc_logvar.state_dict(),
            'decoder': self.vae.decoder.state_dict()
        }
    
    def set_vae_parameters(self, vae_params):
        """è®¾ç½®å…¨å±€VAEå‚æ•°"""
        self.vae.encoder.load_state_dict(vae_params['encoder'])
        self.vae.fc_mu.load_state_dict(vae_params['fc_mu'])
        self.vae.fc_logvar.load_state_dict(vae_params['fc_logvar'])
        self.vae.decoder.load_state_dict(vae_params['decoder'])
    
    def receive_global_prototypes(self, global_prototypes):
        """
        Receive aggregated global prototypes from server
        
        Args:
            global_prototypes: dict {class_id: prototype_tensor}
        
        This allows clients to leverage global feature representations
        to improve local prototype learning and regularization.
        """
        self.global_prototypes = {
            class_id: proto.clone().detach().to(self.device)
            for class_id, proto in global_prototypes.items()
        }
        print(f"  Client {self.id} received {len(self.global_prototypes)} global prototypes")
        
    def train(self):
        """
        Unified training entry point.
        Dispatches to phase-specific training methods.
        """
        if self.current_phase == 1:
            return self.train_phase1()
        else:
            return self.train_phase2()
    
    # ==================== Phase 1: VAE + Prototype Learning ====================
    
    def train_phase1(self):
        """
        Phase 1 Training: Hybrid Strategy (Warm-up + Joint Training)
        
        ä¼˜åŒ–ç­–ç•¥ï¼šæ··åˆè®­ç»ƒ
        - Stage 1 (å‰30%è½®æ¬¡): é¢„è®­ç»ƒåˆ†ç±»å™¨ï¼Œå†»ç»“VAE
        - Stage 2 (å70%è½®æ¬¡): VAE + åˆ†ç±»å™¨è”åˆè®­ç»ƒ
        
        Training flow:
        1. Warm-up Stage (3/10 epochs):
           - Real data â†’ Classifier â†’ Classification loss
           - åªæ›´æ–°åˆ†ç±»å™¨ï¼ŒVAEå†»ç»“
           - ç›®æ ‡ï¼šå»ºç«‹ç¨³å®šçš„åˆ¤åˆ«èƒ½åŠ›
        
        2. Joint Training Stage (7/10 epochs):
           - Real data â†’ VAE â†’ Virtual data
           - Virtual data â†’ Classifier â†’ Classification loss
           - Compute VAE reconstruction + KL losses
           - Compute prototype loss (feature â†’ prototype distance)
           - åŒæ—¶æ›´æ–°VAEå’Œåˆ†ç±»å™¨
        
        Returns:
            accuracy (float): Current validation accuracy
        """
        trainloader = self.load_train_data()
        
        start_time = time.time()
        
        max_local_epochs = self.local_epochs
        if self.train_slow:
            max_local_epochs = np.random.randint(1, max_local_epochs // 2)
        
        # è®¡ç®—warm-upé˜¶æ®µçš„è½®æ¬¡ï¼ˆ30%ï¼‰
        warmup_epochs = max(1, int(max_local_epochs * 0.3))
        joint_epochs_start = warmup_epochs
        
        for epoch in range(max_local_epochs):
            # ====== Stage 1: Warm-up (é¢„è®­ç»ƒåˆ†ç±»å™¨) ======
            if epoch < warmup_epochs:
                self.model.train()
                self.vae.eval()  # å†»ç»“VAE
                
                for i, (x, y) in enumerate(trainloader):
                    if type(x) == type([]):
                        x[0] = x[0].to(self.device).double()
                    else:
                        x = x.to(self.device).double()
                    y = y.to(self.device)
                    
                    if self.train_slow:
                        time.sleep(0.1 * np.abs(np.random.rand()))
                    
                    # åˆ†ç±»å™¨ç›´æ¥åœ¨çœŸå®æ•°æ®ä¸Šè®­ç»ƒ
                    cls_output = self.model(x.double())
                    cls_loss = self.loss(cls_output, y)
                    
                    # åªæ›´æ–°åˆ†ç±»å™¨
                    self.optimizer.zero_grad()
                    cls_loss.backward()
                    self.optimizer.step()
                
                if epoch == 0:
                    print(f"  Client {self.id}: [Warm-up Stage] Pretraining classifier on real data (epochs 1-{warmup_epochs})")
            
            # ====== Stage 2: Joint Training (è”åˆè®­ç»ƒ) ======
            else:
                self.model.train()
                self.vae.train()
                
                if epoch == joint_epochs_start:
                    print(f"  Client {self.id}: [Joint Training Stage] VAE + Classifier joint training (epochs {joint_epochs_start+1}-{max_local_epochs})")
                
                for i, (x, y) in enumerate(trainloader):
                    if type(x) == type([]):
                        x[0] = x[0].to(self.device).double()
                    else:
                        x = x.to(self.device).double()
                    y = y.to(self.device)
                    
                    if self.train_slow:
                        time.sleep(0.1 * np.abs(np.random.rand()))
                    
                    # === VAE Forward Pass (Ablation: can be disabled) ===
                    if self.use_vae_generation:
                        # âœ¨ CVAE: åŠ å…¥ç±»åˆ«æ¡ä»¶
                        if self.use_cvae:
                            virtual_x, mu, logvar = self.vae(x, y)  # æ¡ä»¶è¾“å…¥
                        else:
                            virtual_x, mu, logvar = self.vae(x)  # æ ‡å‡†VAE
                        
                        # === Loss 2: VAE Reconstruction ===
                        recon_loss = F.mse_loss(virtual_x, x, reduction='mean')
                        
                        # === Loss 3: KL Divergence (ä½¿ç”¨åŠ¨æ€Î²) ===
                        kl_div = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
                        kl_loss = (self.current_beta * kl_div).to(torch.float64)  # åŠ¨æ€Î²æƒé‡
                    else:
                        # No VAE: use real data directly
                        virtual_x = x
                        recon_loss = torch.tensor(0.0, device=self.device, dtype=torch.float64)
                        kl_loss = torch.tensor(0.0, device=self.device, dtype=torch.float64)
                    
                    # === åŸå‹å¯¹é½å±‚å·²ç¦ç”¨ - ç›´æ¥ä½¿ç”¨åŸå§‹ç‰¹å¾ ===
                    # if len(self.global_prototypes) > 0 and self.use_prototype_loss:
                    #     # æå–å…¨å±€åŸå‹å¼ é‡
                    #     try:
                    #         prototype_tensor = torch.stack([
                    #             self.global_prototypes[class_id] 
                    #             for class_id in sorted(self.global_prototypes.keys())
                    #         ])  # [num_classes, feature_dim]
                    #         
                    #         # åº”ç”¨åŸå‹å¯¹é½å±‚ï¼ˆæ˜¾å¼å¢å¼ºï¼‰
                    #         virtual_x_enhanced = self.proto_align_layer(virtual_x, prototype_tensor)
                    #     except Exception as e:
                    #         # å¦‚æœå‡ºé”™ï¼Œä½¿ç”¨åŸå§‹ç‰¹å¾
                    #         virtual_x_enhanced = virtual_x
                    # else:
                    #     virtual_x_enhanced = virtual_x
                    
                    # === Classifier Forward Pass (ç›´æ¥ä½¿ç”¨VAEç‰¹å¾) ===
                    cls_output = self.model(virtual_x.double())
                    
                    # === Loss 1: Classification ===
                    cls_loss = self.loss(cls_output, y)
                    
                    # === åŸå‹æŸå¤±å·²ç¦ç”¨ ===
                    # if self.use_prototype_loss:
                    #     proto_loss = self._compute_prototype_loss(virtual_x, y)
                    # else:
                    #     proto_loss = torch.tensor(0.0, device=self.device, dtype=torch.float64)
                    
                    # === Total Weighted Loss (åˆ†ç±» + é‡æ„ + åŠ¨æ€Î²*KL) ===
                    total_loss = (self.lambda_cls * cls_loss.to(torch.float64) +
                                 self.lambda_recon * recon_loss.to(torch.float64) +
                                 kl_loss)  # kl_losså·²åŒ…å«current_betaæƒé‡
                    
                    # === Backward Pass ===
                    self.optimizer.zero_grad()
                    self.vae_optimizer.zero_grad()
                    # self.proto_align_optimizer.zero_grad()  # åŸå‹å¯¹é½å±‚ä¼˜åŒ–å™¨å·²ç¦ç”¨
                    total_loss.backward()
                    self.optimizer.step()
                    self.vae_optimizer.step()
                    # self.proto_align_optimizer.step()  # åŸå‹å¯¹é½å±‚å·²ç¦ç”¨
        
        # Update prototypes after epoch
        # æ‰€æœ‰å®¢æˆ·ç«¯ï¼ˆåŒ…æ‹¬æ—©åœå®¢æˆ·ç«¯ï¼‰éƒ½ç»§ç»­æ›´æ–°å¹¶ä¸Šä¼ åŸå‹
        # æ—©åœå®¢æˆ·ç«¯çš„åŸå‹æƒé‡ä¼šé€šè¿‡è‡ªé€‚åº”è¡°å‡Î±_k(t)è‡ªåŠ¨é™ä½
        self._update_prototypes()
        
        # Compute validation accuracy
        self.accuracy = self._compute_accuracy()
        
        # Track accuracy history for early stopping detection
        self.accuracy_history.append(self.accuracy)
        
        # Check for early stopping and virtual data generation
        # å‰5è½®å¼ºåˆ¶è®­ç»ƒï¼Œä¸æ£€æŸ¥æ—©åœï¼›6è½®åå¼€å§‹æ£€æŸ¥
        current_round = len(self.accuracy_history)  # 1-indexed
        
        if current_round <= 5:
            # Round 1-5: å¼ºåˆ¶è®­ç»ƒï¼Œä¸æ£€æŸ¥æ—©åœ
            pass
        elif not self.early_stopped:
            # Round 6+: æ£€æŸ¥æ—©åœ
            self.early_stopped = self._check_early_stopping()
            if self.early_stopped:
                recent_3 = self.accuracy_history[-3:] if len(self.accuracy_history) >= 3 else self.accuracy_history
                fluctuation = max(recent_3) - min(recent_3) if len(recent_3) > 0 else 0
                print(f"  [Qualified] Client {self.id} reached early stopping criteria (Round {current_round}):")
                print(f"    - Accuracy: {self.accuracy:.4f} (threshold: {self.current_threshold:.4f})")
                print(f"    - Fluctuation: {fluctuation:.4f} (last {len(recent_3)} rounds)")
                print(f"    - History: {[f'{x:.3f}' for x in recent_3]}")
                
                # é¦–æ¬¡è¾¾æ ‡ï¼šç”Ÿæˆå¹¶é”å®šè™šæ‹Ÿæ•°æ®
                if not self.virtual_data_generated:
                    print(f"  [Virtual Data] Generating and locking virtual data for client {self.id}...")
                    # è¿™é‡Œç”Ÿæˆè™šæ‹Ÿæ•°æ®çš„é€»è¾‘ä¼šåœ¨æœåŠ¡å™¨ç«¯è°ƒç”¨ generate_virtual_samples()
                    self.virtual_data_generated = True
                    print(f"  [Mentor Mode] Client {self.id} enters mentor mode:")
                    print(f"    - Continue training model (help weak clients)")
                    print(f"    - Continue uploading prototypes (weight auto-decayed by Î±_k(t))")
                    print(f"    - Virtual data locked (privacy preserved)")
        
        # å³ä½¿è¾¾åˆ°æ—©åœæ ‡å‡†ï¼Œå®¢æˆ·ç«¯ä»ç»§ç»­è®­ç»ƒï¼ˆä½œä¸º"åŠ©æ•™"è§’è‰²ï¼‰
        # ç»§ç»­ä¸Šä¼ åŸå‹ï¼ˆæƒé‡é€šè¿‡Î±_k(t)è‡ªé€‚åº”è¡°å‡ï¼‰ï¼Œè™šæ‹Ÿæ•°æ®å·²é”å®š
        
        if self.learning_rate_decay:
            self.learning_rate_scheduler.step()
        
        self.train_time_cost['num_rounds'] += 1
        self.train_time_cost['total_cost'] += time.time() - start_time
        
        return self.accuracy
    
    def _compute_prototype_loss(self, features, labels):
        """
        Compute distance between features and their class prototypes
        
        Strategy:
        1. Prioritize global prototypes (from server aggregation)
        2. Fallback to local prototypes if global not available
        3. This ensures clients leverage global knowledge
        
        Args:
            features: Virtual features [batch_size, feature_dim]
            labels: Class labels [batch_size]
        
        Returns:
            proto_loss: Average distance to prototypes
        """
        # Use global prototypes if available, otherwise local
        active_prototypes = self.global_prototypes if len(self.global_prototypes) > 0 else self.prototypes
        
        if len(active_prototypes) == 0:
            return torch.tensor(0.0, device=self.device, dtype=torch.float64)
        
        proto_loss = torch.tensor(0.0, device=self.device, dtype=torch.float64)
        count = 0
        
        for i, label in enumerate(labels):
            class_id = label.item()
            if class_id in active_prototypes:
                # MSE distance to prototype (global or local)
                proto_loss += F.mse_loss(features[i], active_prototypes[class_id])
                count += 1
        
        return proto_loss / count if count > 0 else torch.tensor(0.0, device=self.device, dtype=torch.float64)
    
    def _update_prototypes(self):
        """
        Update class prototypes using EMA (Exponential Moving Average)
        
        Prototype update rule:
        proto_new = momentum Ã— proto_old + (1 - momentum) Ã— proto_current
        """
        trainloader = self.load_train_data()
        self.model.eval()
        self.vae.eval()
        
        # Collect features by class
        class_features = defaultdict(list)
        
        with torch.no_grad():
            for x, y in trainloader:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device).double()
                else:
                    x = x.to(self.device).double()
                y = y.to(self.device)
                
                # Generate virtual features (æ”¯æŒCVAEæ¡ä»¶è¾“å…¥)
                if self.use_cvae:
                    virtual_x, _, _ = self.vae(x, y)  # CVAEéœ€è¦ç±»åˆ«æ ‡ç­¾
                else:
                    virtual_x, _, _ = self.vae(x)  # æ ‡å‡†VAE
                
                # Group by class
                for i, label in enumerate(y):
                    class_id = label.item()
                    class_features[class_id].append(virtual_x[i].cpu())
        
        # Compute mean prototype for each class
        for class_id, features in class_features.items():
            if len(features) == 0:
                continue
            
            # Current prototype: mean of features
            current_proto = torch.stack(features).mean(dim=0).to(self.device)
            
            # EMA update with global prototype guidance
            if class_id in self.prototypes:
                # Standard EMA update
                self.prototypes[class_id] = (
                    self.proto_momentum * self.prototypes[class_id] +
                    (1 - self.proto_momentum) * current_proto
                )
            elif class_id in self.global_prototypes:
                # Initialize from global prototype if available
                self.prototypes[class_id] = (
                    0.7 * self.global_prototypes[class_id] +
                    0.3 * current_proto
                )
            else:
                # New class, use current
                self.prototypes[class_id] = current_proto
    
    def _update_beta_schedule(self):
        """
        âš¡ é˜¶æ®µ2: åŠ¨æ€Î²è°ƒåº¦å™¨
        
        ç­–ç•¥ï¼š
        - å‰Nè½® (warmup): Î²ä»miné€æ¸å¢åŠ åˆ°maxï¼Œå­¦ä¹ ä¸°å¯Œè¡¨ç¤º
        - åæœŸ (stable): Î²ä¿æŒmaxå€¼ï¼Œç¨³å®šè®­ç»ƒ
        
        å¥½å¤„ï¼š
        - æ—©æœŸä½Î² â†’ VAEå­¦ä¹ æ›´å¤šæ ·åŒ–çš„ç‰¹å¾è¡¨ç¤º
        - åæœŸé«˜Î² â†’ çº¦æŸzåˆ°æ ‡å‡†åˆ†å¸ƒï¼Œç¨³å®šç”Ÿæˆè´¨é‡
        - æå‡ç”Ÿæˆæ•°æ®å¤šæ ·æ€§ +15~25%
        """
        current_round = len(self.accuracy_history) + 1  # å½“å‰æ˜¯ç¬¬å‡ è½®
        
        if current_round <= self.beta_warmup_epochs:
            # çº¿æ€§å¢é•¿: beta_min â†’ beta_max
            progress = current_round / self.beta_warmup_epochs
            self.current_beta = self.beta_min + (self.beta_max - self.beta_min) * progress
            
            if current_round == 1:
                print(f"  [Î²-Schedule] Client {self.id}: Warmup phase (rounds 1-{self.beta_warmup_epochs})")
                print(f"    Î² range: {self.beta_min:.4f} â†’ {self.beta_max:.4f}")
        else:
            # ç¨³å®šé˜¶æ®µ
            self.current_beta = self.beta_max
        
        # æ›´æ–°VAEçš„betaå‚æ•°ï¼ˆå¦‚æœVAEæ”¯æŒï¼‰
        if hasattr(self.vae, 'beta'):
            self.vae.beta = self.current_beta
    
    def collect_latent_distribution(self):
        """
        ä»çœŸå®è®­ç»ƒæ•°æ®ä¸­æå–éšç©ºé—´åˆ†å¸ƒçš„ç»Ÿè®¡é‡ï¼ˆå‡å€¼å’Œæ ‡å‡†å·®ï¼‰
        
        ç›®çš„ï¼š
        - ä¸å†ä»æ ‡å‡†æ­£æ€åˆ†å¸ƒN(0,1)é‡‡æ ·
        - è€Œæ˜¯ä»è®­ç»ƒæ•°æ®å­¦åˆ°çš„çœŸå®åˆ†å¸ƒé‡‡æ ·
        - æé«˜ç”Ÿæˆè™šæ‹Ÿæ•°æ®çš„è´¨é‡å’ŒçœŸå®æ€§
        
        Returns:
            latent_stats: Dict[class_id -> {'mu': mean_vector, 'std': std_vector}]
        """
        self.vae.eval()
        trainloader = self.load_train_data()
        
        # æŒ‰ç±»åˆ«æ”¶é›†éšå˜é‡
        latent_by_class = {i: [] for i in range(self.num_classes)}
        
        with torch.no_grad():
            for x, y in trainloader:
                if type(x) == type([]):
                    x = x[0]
                x = x.to(self.device).double()
                y = y.to(self.device)
                
                # ç¼–ç åˆ°éšç©ºé—´ (æ”¯æŒCVAEæ¡ä»¶ç¼–ç )
                if self.use_cvae:
                    mu, logvar = self.vae.encode(x, y)  # CVAEæ¡ä»¶ç¼–ç 
                else:
                    h = self.vae.encoder(x)
                    mu = self.vae.fc_mu(h)
                
                # æŒ‰ç±»åˆ«å­˜å‚¨
                for i, label in enumerate(y):
                    latent_by_class[label.item()].append(mu[i].cpu())
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡å€¼å’Œæ ‡å‡†å·®
        latent_stats = {}
        for class_id, latents in latent_by_class.items():
            if len(latents) > 0:
                latents = torch.stack(latents)
                latent_stats[class_id] = {
                    'mu': latents.mean(dim=0),      # [latent_dim]
                    'std': latents.std(dim=0) + 1e-6  # æ·»åŠ å°å€¼é˜²æ­¢é™¤é›¶
                }
        
        return latent_stats
    
    def generate_virtual_data(self, num_samples=None, confidence_threshold=None, 
                             use_real_distribution=True, exploration_ratio=None):
        """
        Generate high-quality virtual data using trained VAE
        
        æ”¹è¿›ç‚¹ï¼š
        1. è´¨é‡ç­›é€‰ï¼šåŸºäºåˆ†ç±»å™¨ç½®ä¿¡åº¦è¿‡æ»¤ä½è´¨é‡æ ·æœ¬
        2. çœŸå®åˆ†å¸ƒé‡‡æ ·ï¼šä»è®­ç»ƒæ•°æ®çš„éšç©ºé—´åˆ†å¸ƒé‡‡æ ·ï¼ˆä¸æ˜¯N(0,1)ï¼‰
        3. æ··åˆé‡‡æ ·ï¼šç»“åˆæ¢ç´¢ï¼ˆéšæœºï¼‰å’Œåˆ©ç”¨ï¼ˆçœŸå®åˆ†å¸ƒï¼‰
        4. ç”Ÿæˆæ•°æ®æ¯”ä¾‹ï¼šæ”¯æŒæŒ‰æ¯”ä¾‹ç”Ÿæˆæ•°æ®ç”¨äºæ¶ˆèå®éªŒ
        5. é’ˆå¯¹Xinwangä¼˜åŒ–ï¼šæ›´ä¸¥æ ¼çš„è´¨é‡æ§åˆ¶
        
        Args:
            num_samples: Number of samples to generate.
                        If None, generates same amount as real training data.
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œåªä¿ç•™åˆ†ç±»å™¨ç½®ä¿¡åº¦>thresholdçš„æ ·æœ¬
                                 Noneæ—¶è‡ªåŠ¨é€‰æ‹©ï¼ˆXinwang=0.8, å…¶ä»–=0.7ï¼‰
            use_real_distribution: æ˜¯å¦ä»çœŸå®æ•°æ®åˆ†å¸ƒé‡‡æ ·ï¼ˆTrueæ¨èï¼‰
            exploration_ratio: éšæœºæ¢ç´¢çš„æ¯”ä¾‹
                              Noneæ—¶è‡ªåŠ¨é€‰æ‹©ï¼ˆXinwang=0.1, å…¶ä»–=0.2ï¼‰
        
        Returns:
            virtual_data: List of (features, label) tuples
        """
        if num_samples is None:
            num_samples = self.train_samples
        
        # åº”ç”¨ç”Ÿæˆæ•°æ®æ¯”ä¾‹ï¼ˆæ¶ˆèå®éªŒç”¨ï¼‰
        num_samples = int(num_samples * self.gen_data_ratio)
        
        # å¦‚æœæ¯”ä¾‹ä¸º0ï¼Œç›´æ¥è¿”å›ç©ºåˆ—è¡¨
        if num_samples == 0 or not self.use_vae_generation:
            self.virtual_data = []
            print(f"  Client {self.id}: Skipped virtual data generation (ratio={self.gen_data_ratio})")
            return []
        
        # ğŸ”¥ ä¸¥æ ¼è´¨é‡æ§åˆ¶ï¼šä¸ä¸­å¿ƒåŒ–è®­ç»ƒæ ‡å‡†å¯¹é½
        # åŸåˆ™ï¼šçœŸå®æ•°æ®èƒ½è¾¾åˆ°çš„æ ‡å‡†ï¼Œè™šæ‹Ÿæ•°æ®ä¹Ÿå¿…é¡»è¾¾åˆ°ï¼Œä¸é™ä½æ ‡å‡†
        is_xinwang = 'Xinwang' in str(self.__class__.__module__)
        if confidence_threshold is None:
            confidence_threshold = 0.96 if is_xinwang else 0.8  # æé«˜åˆ°ä¸­å¿ƒåŒ–æ°´å¹³
        if exploration_ratio is None:
            exploration_ratio = 0.1 if is_xinwang else 0.2
        
        self.vae.eval()
        self.model.eval()
        
        # æ”¶é›†çœŸå®æ•°æ®çš„éšç©ºé—´åˆ†å¸ƒ
        latent_stats = None
        if use_real_distribution:
            print(f"  Client {self.id}: Collecting latent distribution from real data...")
            latent_stats = self.collect_latent_distribution()
        
        virtual_data = []
        samples_per_class = num_samples // self.num_classes
        
        # ç”Ÿæˆæ›´å¤šå€™é€‰æ ·æœ¬ç”¨äºè´¨é‡ç­›é€‰ï¼ˆ2å€ï¼‰
        candidates_per_class = samples_per_class * 2
        
        with torch.no_grad():
            for class_id in range(self.num_classes):
                # ========== æ”¹è¿›1: ä»çœŸå®åˆ†å¸ƒé‡‡æ · ==========
                if use_real_distribution and latent_stats and class_id in latent_stats:
                    # è®¡ç®—æ¢ç´¢å’Œåˆ©ç”¨çš„æ ·æœ¬æ•°
                    exploit_count = int(candidates_per_class * (1 - exploration_ratio))
                    explore_count = candidates_per_class - exploit_count
                    
                    # 80%: ä»çœŸå®åˆ†å¸ƒé‡‡æ ·ï¼ˆåˆ©ç”¨ï¼‰
                    mu = latent_stats[class_id]['mu'].to(self.device)
                    std = latent_stats[class_id]['std'].to(self.device)
                    z_exploit = torch.randn(exploit_count, self.vae.latent_dim).to(self.device)
                    z_exploit = mu + z_exploit * std  # é‡å‚æ•°åŒ–æŠ€å·§
                    
                    # 20%: éšæœºé‡‡æ ·ï¼ˆæ¢ç´¢ï¼‰
                    z_explore = torch.randn(explore_count, self.vae.latent_dim).to(self.device)
                    
                    # åˆå¹¶
                    z = torch.cat([z_exploit, z_explore], dim=0)
                else:
                    # å›é€€åˆ°æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼ˆå¦‚æœæ²¡æœ‰ç»Ÿè®¡ä¿¡æ¯ï¼‰
                    z = torch.randn(candidates_per_class, self.vae.latent_dim).to(self.device)
                
                # âœ¨ è§£ç åˆ°ç‰¹å¾ç©ºé—´ (CVAEæ ¸å¿ƒæ”¹è¿›ï¼šæŒ‡å®šç±»åˆ«ç”Ÿæˆ)
                # ConditionalCreditVAEæ€»æ˜¯éœ€è¦yå‚æ•°
                y_cond = torch.full((z.shape[0],), class_id, dtype=torch.long).to(self.device)
                features = self.vae.decode(z, y_cond)  # æ¡ä»¶è§£ç 
                
                # ========== æ”¹è¿›2: è´¨é‡ç­›é€‰ï¼ˆåŸºäºåˆ†ç±»å™¨ç½®ä¿¡åº¦ï¼‰ ==========
                # ç”¨åˆ†ç±»å™¨é¢„æµ‹è™šæ‹Ÿæ•°æ®
                outputs = self.model(features)
                probs = torch.softmax(outputs, dim=1)
                
                # è·å–ç›®æ ‡ç±»åˆ«çš„ç½®ä¿¡åº¦
                confidences = probs[:, class_id]
                
                # ğŸ”¥ ä¸¥æ ¼ç­›é€‰ï¼šåªä¿ç•™é«˜ç½®ä¿¡åº¦æ ·æœ¬ï¼ˆä¸é™ä½æ ‡å‡†ï¼‰
                # åŸåˆ™ï¼šå®ç¼ºæ¯‹æ»¥ï¼Œä¸è¾¾æ ‡çš„è™šæ‹Ÿæ•°æ®ä¼šæ±¡æŸ“"åˆ†ç±»å™¨å°ºå­"
                high_quality_indices = (confidences >= confidence_threshold).nonzero(as_tuple=True)[0]
                
                # é™åˆ¶æ•°é‡åˆ°ç›®æ ‡å€¼ï¼ˆå¦‚æœé«˜è´¨é‡æ ·æœ¬å……è¶³ï¼‰
                if len(high_quality_indices) > samples_per_class:
                    high_quality_indices = high_quality_indices[:samples_per_class]
                
                # ğŸ“Š è´¨é‡ç»Ÿè®¡
                num_high_quality = len(high_quality_indices)
                if num_high_quality < samples_per_class:
                    print(f"    [WARNING] Class {class_id}: ä»…{num_high_quality}/{samples_per_class}æ ·æœ¬è¾¾æ ‡ "
                          f"(threshold={confidence_threshold:.2f}), å®ç¼ºæ¯‹æ»¥ï¼Œä¸è¡¥å……ä½è´¨é‡æ•°æ®")
                else:
                    print(f"    [OK] Class {class_id}: {num_high_quality}ä¸ªé«˜è´¨é‡æ ·æœ¬è¾¾æ ‡ "
                          f"(threshold={confidence_threshold:.2f})")
                
                # ä¿å­˜ç­›é€‰åçš„è™šæ‹Ÿæ•°æ®
                for idx in high_quality_indices:
                    idx = idx.item()
                    virtual_data.append((
                        features[idx].cpu().numpy(),
                        class_id  # numpyæ ‡é‡
                    ))
                
                # æ‰“å°è´¨é‡ç»Ÿè®¡
                mean_conf = confidences[high_quality_indices].mean().item()
                print(f"    Class {class_id}: {len(high_quality_indices)}/{candidates_per_class} "
                      f"candidates passed filter (avg confidence: {mean_conf:.3f})")
        
        self.virtual_data = virtual_data
        self.threshold_met = True
        
        actual_generated = len(virtual_data)
        quality_rate = (actual_generated / num_samples * 100) if num_samples > 0 else 0
        print(f"  Client {self.id}: Generated {actual_generated}/{num_samples} high-quality samples "
              f"({quality_rate:.1f}% pass rate, strict threshold={confidence_threshold:.2f})")
        
        return virtual_data
    
    def add_adaptive_noise_to_virtual_data(self, strategy='balanced'):
        """
        Add adaptive differential privacy noise to virtual data based on feature importance
        
        Args:
            strategy: Noise allocation strategy
                - 'privacy_first': More noise on important features (protect privacy)
                - 'utility_first': Less noise on important features (preserve utility)
                - 'balanced': Uniform noise (traditional DP)
        
        Noise is added ONLY if:
        - epsilon is not None AND epsilon > 0
        - noise_type is specified
        
        Supports two noise mechanisms:
        - Laplace: scale = Î”f / Îµ
        - Gaussian: Ïƒ = Î”f Ã— sqrt(2 Ã— ln(1.25/Î´)) / Îµ
        
        Modifies self.virtual_data in-place by adding noise to features.
        """
        if len(self.virtual_data) == 0:
            return
        
        # Check if noise should be added
        if self.epsilon is None or self.epsilon <= 0:
            print(f"  Client {self.id}: Skipping noise addition (epsilon={self.epsilon}, privacy disabled)")
            return
        
        if self.noise_type is None or self.noise_type == 'none':
            print(f"  Client {self.id}: Skipping noise addition (noise_type={self.noise_type})")
            return
        
        print(f"  Client {self.id}: Adding {strategy} {self.noise_type} noise (Îµ={self.epsilon})")
        
        # Get feature importance if available
        use_adaptive = (self.feature_importance is not None and strategy != 'balanced')
        
        noisy_data = []
        
        for features, label in self.virtual_data:
            features = np.array(features)
            
            # Sensitivity: assume features are normalized to [0, 1] or [-1, 1]
            sensitivity = 1.0
            
            if use_adaptive:
                # Adaptive noise based on feature importance
                if strategy == 'privacy_first':
                    # More noise on important features
                    noise_scale = self.feature_importance
                elif strategy == 'utility_first':
                    # Less noise on important features
                    noise_scale = 1.0 - self.feature_importance
                else:
                    noise_scale = np.ones_like(self.feature_importance)
                
                # Normalize to maintain total privacy budget
                noise_scale = noise_scale / noise_scale.mean()
            else:
                # Uniform noise
                noise_scale = np.ones(features.shape[0])
            
            if self.noise_type == 'laplace':
                # Laplace mechanism with adaptive scaling
                base_scale = sensitivity / self.epsilon
                noise = np.random.laplace(0, base_scale * noise_scale, size=features.shape)
            else:  # gaussian
                # Gaussian mechanism with adaptive scaling
                base_sigma = sensitivity * np.sqrt(2 * np.log(1.25 / self.delta)) / self.epsilon
                noise = np.random.normal(0, base_sigma * noise_scale, size=features.shape)
            
            noisy_features = features + noise
            noisy_data.append((noisy_features, label))
        
        self.virtual_data = noisy_data
    
    def add_noise_to_virtual_data(self):
        """
        Backward compatibility wrapper - calls add_adaptive_noise_to_virtual_data with balanced strategy
        """
        self.add_adaptive_noise_to_virtual_data(strategy='balanced')
    
    def train_baseline_vae(self):
        """
        è®­ç»ƒçº¯é‡å»ºVAEï¼ˆæœ¬åœ°å¯¹æ¯”å®éªŒï¼Œä¸å‚ä¸è”é‚¦å­¦ä¹ ï¼‰
        
        ç›®çš„ï¼šé€šè¿‡å¯¹æ¯”è¯†åˆ«åˆ†ç±»ç›¸å…³ç‰¹å¾
        ç­–ç•¥ï¼š
        - ä»…ä½¿ç”¨é‡å»ºæŸå¤±å’ŒKLæ•£åº¦ï¼ˆæ— åˆ†ç±»æŸå¤±ã€æ— åŸå‹æŸå¤±ï¼‰
        - å›ºå®šè®­ç»ƒè½®æ•°ï¼ˆä¸éœ€è¦æ—©åœã€ä¸éœ€è¦æœåŠ¡å™¨é€šè®¯ï¼‰
        - å®Œå…¨æœ¬åœ°è®­ç»ƒï¼Œç”¨äºåç»­ç‰¹å¾é‡è¦æ€§è®¡ç®—
        
        Returns:
            float: æœ€ç»ˆå¹³å‡é‡å»ºè¯¯å·®
        """
        print(f"  Client {self.id}: Training baseline VAE (reconstruction-only)...")
        
        # åˆ›å»ºåŸºçº¿VAEï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if self.vae_baseline is None:
            # ä»æ•°æ®è·å–å®é™…ç‰¹å¾ç»´åº¦ï¼ˆä¸æ˜¯ä»encoderç¬¬ä¸€å±‚ï¼Œå› ä¸ºé‚£é‡Œæ˜¯input_dim + class_embedding_dimï¼‰
            trainloader_temp = self.load_train_data()
            sample_x, _ = next(iter(trainloader_temp))
            if type(sample_x) == type([]):
                actual_input_dim = sample_x[0].shape[1]
            else:
                actual_input_dim = sample_x.shape[1]
            
            latent_dim = self.vae.latent_dim
            
            self.vae_baseline = create_credit_vae(
                input_dim=actual_input_dim,
                latent_dim=latent_dim,
                dataset_name=self.dataset
            ).to(self.device).double()
            
            self.vae_baseline_optimizer = torch.optim.Adam(
                self.vae_baseline.parameters(),
                lr=0.001
            )
        
        trainloader = self.load_train_data()
        self.vae_baseline.train()
        
        total_recon_loss = 0.0
        
        # å›ºå®šè®­ç»ƒè½®æ•°
        for epoch in range(self.baseline_epochs):
            epoch_loss = 0.0
            batch_count = 0
            
            for x, y in trainloader:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device).double()
                else:
                    x = x.to(self.device).double()
                y = y.to(self.device).long()
                
                # ä»…ä½¿ç”¨VAEçš„é‡å»ºå’ŒKLæŸå¤±ï¼ˆæ— åˆ†ç±»ã€æ— åŸå‹ï¼‰
                virtual_x, mu, logvar = self.vae_baseline(x, y)
                
                # Loss 1: é‡å»ºæŸå¤±
                recon_loss = F.mse_loss(virtual_x, x, reduction='mean')
                
                # Loss 2: KLæ•£åº¦
                kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
                
                # æ€»æŸå¤±ï¼ˆåªæœ‰é‡å»ºå’ŒKLï¼‰
                total_loss = recon_loss + 0.01 * kl_loss
                
                self.vae_baseline_optimizer.zero_grad()
                total_loss.backward()
                self.vae_baseline_optimizer.step()
                
                epoch_loss += recon_loss.item()
                batch_count += 1
            
            avg_loss = epoch_loss / batch_count
            if (epoch + 1) % 10 == 0:
                print(f"    Baseline VAE Epoch {epoch+1}/{self.baseline_epochs}, Recon Loss: {avg_loss:.4f}")
            
            total_recon_loss = avg_loss
        
        print(f"  Client {self.id}: Baseline VAE training completed. Final recon loss: {total_recon_loss:.4f}")
        return total_recon_loss
    
    def compute_feature_importance(self, num_samples=1000):
        """
        é€šè¿‡å¯¹æ¯”ä¸»VAEå’ŒåŸºçº¿VAEçš„è¾“å‡ºï¼Œè®¡ç®—ç‰¹å¾é‡è¦æ€§
        
        æ–¹æ³•ï¼šå¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Analysisï¼‰
        1. ä¸»VAEï¼ˆæœ‰åˆ†ç±»çº¦æŸï¼‰ï¼šå­¦ä¹ åˆ¤åˆ«æ€§+é‡å»ºæ€§ç‰¹å¾
        2. åŸºçº¿VAEï¼ˆæ— åˆ†ç±»çº¦æŸï¼‰ï¼šä»…å­¦ä¹ é‡å»ºæ€§ç‰¹å¾
        3. å·®å¼‚ = åˆ¤åˆ«æ€§ç‰¹å¾çš„é‡è¦æ€§
        
        Args:
            num_samples: ç”¨äºå¯¹æ¯”çš„æ ·æœ¬æ•°é‡
        
        Returns:
            numpy.ndarray: ç‰¹å¾é‡è¦æ€§å‘é‡ï¼ˆå½’ä¸€åŒ–åˆ°[0,1]ï¼‰
        """
        if self.vae_baseline is None:
            print(f"  Client {self.id}: Baseline VAE not trained. Training now...")
            self.train_baseline_vae()
        
        print(f"  Client {self.id}: Computing feature importance via VAE comparison...")
        
        self.vae.eval()
        self.vae_baseline.eval()
        
        with torch.no_grad():
            # ä½¿ç”¨ç›¸åŒçš„éšæœºéšå˜é‡ç”Ÿæˆç‰¹å¾
            # å…³é”®ä¿®å¤ï¼šç¡®ä¿zçš„dtypeä¸VAEæ¨¡å‹ä¸€è‡´
            model_dtype = next(self.vae.parameters()).dtype
            z = torch.randn(num_samples, self.vae.latent_dim, dtype=model_dtype).to(self.device)
            
            # ä¸ºdecodeç”Ÿæˆç±»åˆ«æ ‡ç­¾ï¼ˆä½¿ç”¨ç±»åˆ«0ä½œä¸ºé»˜è®¤ï¼Œæˆ–è€…å¯ä»¥é‡‡æ ·å¤šä¸ªç±»åˆ«ï¼‰
            y_decode = torch.zeros(num_samples, dtype=torch.long).to(self.device)
            
            # ä¸»VAEè§£ç ï¼ˆåŒ…å«åˆ†ç±»ä¿¡æ¯ï¼‰
            features_main = self.vae.decode(z, y_decode)
            
            # åŸºçº¿VAEè§£ç ï¼ˆä»…é‡å»ºä¿¡æ¯ï¼‰
            features_baseline = self.vae_baseline.decode(z, y_decode)
            
            # è®¡ç®—é€ç‰¹å¾çš„ç»å¯¹å·®å¼‚
            diff = (features_main - features_baseline).abs().mean(dim=0)
            
            # å½’ä¸€åŒ–åˆ°[0, 1]
            diff_min = diff.min()
            diff_max = diff.max()
            
            if diff_max - diff_min > 1e-8:
                importance = (diff - diff_min) / (diff_max - diff_min)
            else:
                # å¦‚æœæ‰€æœ‰ç‰¹å¾å·®å¼‚ç›¸åŒï¼Œè®¾ç½®ä¸ºå‡åŒ€é‡è¦æ€§
                importance = torch.ones_like(diff) * 0.5
        
        self.feature_importance = importance.cpu().numpy()
        
        print(f"  Client {self.id}: Feature importance computed.")
        print(f"    Top 3 important features: {np.argsort(self.feature_importance)[-3:]}")
        print(f"    Importance range: [{self.feature_importance.min():.3f}, {self.feature_importance.max():.3f}]")
        
        return self.feature_importance
    
    def get_phase1_upload(self):
        """
        Prepare Phase 1 upload data for server
        
        Returns:
            dict: {
                'accuracy': float,
                'prototypes': {class_id: prototype_tensor},
                'virtual_data': [(features, label), ...],
                'threshold_met': bool
            }
        """
        return {
            'accuracy': self.accuracy,
            'prototypes': {k: v.cpu() for k, v in self.prototypes.items()},
            'virtual_data': self.virtual_data,
            'threshold_met': self.threshold_met
        }
    
    def _compute_accuracy(self):
        """Compute validation accuracy"""
        testloader = self.load_test_data()
        self.model.eval()
        
        test_acc = 0
        test_num = 0
        
        with torch.no_grad():
            for x, y in testloader:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device).double()
                else:
                    x = x.to(self.device).double()
                y = y.to(self.device)
                
                output = self.model(x)
                test_acc += (torch.sum(torch.argmax(output, dim=1) == y)).item()
                test_num += y.shape[0]
        
        return test_acc / test_num if test_num > 0 else 0.0
    
    # ==================== Personalization Training (Ditto-style) ====================
    
    def ptrain(self):
        """
        Personalized model training (Ditto-style)
        Train personalized model with regularization to global model
        
        Called after global model training in Phase 2
        """
        trainloader = self.load_train_data()
        start_time = time.time()
        
        self.model_per.train()
        
        max_local_epochs = self.plocal_epochs
        if self.train_slow:
            max_local_epochs = np.random.randint(1, max_local_epochs // 2)
        
        for epoch in range(max_local_epochs):
            for x, y in trainloader:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device).double()
                else:
                    x = x.to(self.device).double()
                y = y.to(self.device)
                
                if self.train_slow:
                    time.sleep(0.1 * np.abs(np.random.rand()))
                
                output = self.model_per(x)
                loss = self.loss(output, y)
                
                self.optimizer_per.zero_grad()
                loss.backward()
                # PerturbedGradientDescent adds regularization: mu * (w_per - w_global)
                self.optimizer_per.step(self.model.parameters(), self.device)
        
        self.train_time_cost['total_cost'] += time.time() - start_time
    
    def test_metrics_personalized(self):
        """
        Evaluate personalized model (Ditto-style)
        
        Returns:
            test_acc: Number of correct predictions
            test_num: Total number of test samples
            auc: Area under ROC curve
        """
        if self.model_per is None:
            # Fallback to global model if personalized model not initialized
            return self.test_metrics()
        
        testloaderfull = self.load_test_data()
        self.model_per.eval()
        
        test_acc = 0
        test_num = 0
        y_prob = []
        y_true = []
        
        with torch.no_grad():
            for x, y in testloaderfull:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device).double()
                else:
                    x = x.to(self.device).double()
                y = y.to(self.device)
                
                output = self.model_per(x)
                
                test_acc += (torch.sum(torch.argmax(output, dim=1) == y)).item()
                test_num += y.shape[0]
                
                y_prob.append(F.softmax(output, dim=1).detach().cpu().numpy())
                
                # Handle label_binarize for binary classification
                nc = self.num_classes
                if self.num_classes == 2:
                    nc += 1
                lb = label_binarize(y.detach().cpu().numpy(), classes=np.arange(nc))
                if self.num_classes == 2:
                    lb = lb[:, :2]
                y_true.append(lb)
        
        y_prob = np.concatenate(y_prob, axis=0)
        y_true = np.concatenate(y_true, axis=0)
        
        # Compute AUC
        if self.num_classes == 2:
            auc = metrics.roc_auc_score(y_true[:, 1], y_prob[:, 1])
        else:
            auc = metrics.roc_auc_score(y_true, y_prob, average='micro')
        
        return test_acc, test_num, auc
    
    def train_metrics_personalized(self):
        """
        Compute training metrics on personalized model (Ditto-style)
        
        Includes Ditto regularization term in loss calculation:
        L = L_CE + Î¼/2 * ||w_per - w_global||Â²
        
        Returns:
            train_loss: Average training loss (with regularization)
            train_num: Total number of training samples
        """
        if self.model_per is None:
            # Fallback to global model
            trainloader = self.load_train_data()
            self.model.eval()
            
            train_num = 0
            losses = 0
            with torch.no_grad():
                for x, y in trainloader:
                    if type(x) == type([]):
                        x[0] = x[0].to(self.device).double()
                    else:
                        x = x.to(self.device).double()
                    y = y.to(self.device)
                    output = self.model(x)
                    loss = self.loss(output, y)
                    train_num += y.shape[0]
                    losses += loss.item() * y.shape[0]
            
            return losses, train_num
        
        # Evaluate personalized model with Ditto regularization
        trainloader = self.load_train_data()
        self.model_per.eval()
        
        train_num = 0
        losses = 0
        
        with torch.no_grad():
            for x, y in trainloader:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device).double()
                else:
                    x = x.to(self.device).double()
                y = y.to(self.device)
                
                output = self.model_per(x)
                loss = self.loss(output, y)
                
                # Add Ditto regularization term: Î¼/2 * ||w_per - w_global||Â²
                gm = torch.cat([p.data.view(-1) for p in self.model.parameters()], dim=0)
                pm = torch.cat([p.data.view(-1) for p in self.model_per.parameters()], dim=0)
                loss += 0.5 * self.mu_ditto * torch.norm(gm - pm, p=2)
                
                train_num += y.shape[0]
                losses += loss.item() * y.shape[0]
        
        return losses, train_num
    
    # ==================== Phase 2: Algorithm-Specific Training ====================
    
    def ptrain(self):
        """
        Ditto-style personalized model training (Phase2 only)
        
        Trains the local personalized model with Ditto regularization:
        L_per = L_CE(w_per) + Î¼/2 * ||w_per - w_global||Â²
        
        This is automatically handled by PerturbedGradientDescent optimizer.
        """
        if self.model_per is None:
            print(f"  Client {self.id}: Personalized model not initialized, skipping ptrain")
            return
        
        trainloader = self.load_train_data()
        self.model_per.train()
        
        start_time = time.time()
        
        max_local_epochs = self.plocal_epochs
        if self.train_slow:
            max_local_epochs = np.random.randint(1, max_local_epochs // 2)
        
        for epoch in range(max_local_epochs):
            for x, y in trainloader:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device).double()
                else:
                    x = x.to(self.device).double()
                y = y.to(self.device)
                
                if self.train_slow:
                    time.sleep(0.1 * np.abs(np.random.rand()))
                
                # Forward pass on personalized model
                output = self.model_per(x)
                loss = self.loss(output, y)
                
                # Backward pass
                self.optimizer_per.zero_grad()
                loss.backward()
                
                # Ditto regularization: step() uses global model parameters
                # Automatically adds: grad += Î¼ * (w_per - w_global)
                self.optimizer_per.step(self.model.parameters(), self.device)
        
        self.train_time_cost['total_cost'] += time.time() - start_time
    
    def train_phase2(self):
        """
        Phase 2 Training: Algorithm-specific training on mixed data
        
        Dispatches to appropriate training method based on self.phase2_algorithm
        
        Supported algorithms:
        - fedavg: Standard weighted averaging (with Ditto personalization)
        - fedprox: Proximal term regularization
        - fedscaffold: Variance reduction with control variates
        """
        # Ensure model is double precision for Phase 2 (consistent with Phase 1)
        self.model = self.model.double()
        
        # Initialize personalized model if not already done
        if self.model_per is None:
            self.init_personalized_model()
        
        if self.phase2_algorithm == 'fedavg':
            return self._train_fedavg()
        elif self.phase2_algorithm == 'fedprox':
            return self._train_fedprox()
        elif self.phase2_algorithm == 'fedscaffold':
            return self._train_scaffold()
        else:
            # Default to FedAvg
            print(f"Warning: Unknown algorithm '{self.phase2_algorithm}', using FedAvg")
            return self._train_fedavg()
    
    def _train_fedavg(self):
        """
        FedAvg: Standard training on mixed data
        
        Note: ptrain() is already called by server before this method.
        This method only trains the global model.
        """
        mixed_trainloader = self._create_mixed_dataloader(self.load_train_data())
        self.model.train()
        
        for epoch in range(self.local_epochs):
            for x, y in mixed_trainloader:
                x, y = x.to(self.device).double(), y.to(self.device)
                output = self.model(x)
                loss = self.loss(output, y)
                
                # Check for NaN/Inf in loss
                if torch.isnan(loss) or torch.isinf(loss):
                    print(f"Warning: Client {self.id} detected NaN/Inf loss, skipping batch")
                    continue
                
                self.optimizer.zero_grad()
                loss.backward()
                
                # Gradient clipping for stability
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                
                self.optimizer.step()
    
    def _train_fedprox(self):
        """FedProx: Training with proximal term"""
        global_model = copy.deepcopy(self.model)
        mixed_trainloader = self._create_mixed_dataloader(self.load_train_data())
        self.model.train()
        
        mu = getattr(self, 'mu', 0.01)  # From server args
        
        for epoch in range(self.local_epochs):
            for x, y in mixed_trainloader:
                x, y = x.to(self.device).double(), y.to(self.device)
                output = self.model(x)
                loss = self.loss(output, y)
                
                # Add proximal term: mu/2 * ||w - w_global||^2
                proximal_term = 0.0
                for w, w_g in zip(self.model.parameters(), global_model.parameters()):
                    proximal_term += (w - w_g).norm(2)
                loss += (mu / 2) * proximal_term
                
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
    
    def _train_moon(self):
        """MOON: Model-contrastive training"""
        if self.prev_model is None:
            self.prev_model = copy.deepcopy(self.model)
        
        # Store global model reference (should be set by server before training)
        if not hasattr(self, 'global_model') or self.global_model is None:
            self.global_model = copy.deepcopy(self.model)
        
        mixed_trainloader = self._create_mixed_dataloader(self.load_train_data())
        self.model.train()
        
        mu = getattr(self, 'mu', 0.5)  # Match original MOON naming
        temperature = getattr(self, 'tau', 0.5)  # Match original MOON naming
        
        # Check if model has base-head structure
        has_base_head = hasattr(self.model, 'base') and hasattr(self.model, 'head')
        
        for epoch in range(self.local_epochs):
            for x, y in mixed_trainloader:
                x, y = x.to(self.device).double(), y.to(self.device)
                
                if has_base_head:
                    # Use base features for contrastive learning (correct approach)
                    rep = self.model.base(x)
                    output = self.model.head(rep)
                    
                    with torch.no_grad():
                        rep_global = self.global_model.base(x)
                        rep_prev = self.prev_model.base(x)
                else:
                    # Fallback: use output as features (for models without base-head)
                    output = self.model(x)
                    rep = output
                    
                    with torch.no_grad():
                        rep_global = self.global_model(x)
                        rep_prev = self.prev_model(x)
                
                # Classification loss
                loss_ce = self.loss(output, y)
                
                # MOON contrastive loss (InfoNCE)
                # Positive pair: current vs global, Negative pair: current vs previous
                cos_sim_global = F.cosine_similarity(rep, rep_global)
                cos_sim_prev = F.cosine_similarity(rep, rep_prev)
                
                loss_con = -torch.log(
                    torch.exp(cos_sim_global / temperature) / 
                    (torch.exp(cos_sim_global / temperature) + torch.exp(cos_sim_prev / temperature))
                )
                loss_con = loss_con.mean()
                
                loss = loss_ce + mu * loss_con
                
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
        
        # Update previous model
        self.prev_model = copy.deepcopy(self.model)
    
    def _train_scaffold(self):
        """
        SCAFFOLD: Training with control variates
        å®Œå…¨æŒ‰ç…§åŸæ¡†æ¶clientscaffold.pyå®ç°
        """
        if self.c_local is None:
            self.init_scaffold_controls()
        
        mixed_trainloader = self._create_mixed_dataloader(self.load_train_data())
        self.model.train()
        
        # Import SCAFFOLD optimizer
        from flcore.optimizers.fedoptimizer import SCAFFOLDOptimizer
        scaffold_optimizer = SCAFFOLDOptimizer(self.model.parameters(), lr=self.learning_rate)
        
        # Save number of batches for control variate update
        self.num_batches = len(mixed_trainloader)
        
        for epoch in range(self.local_epochs):
            for x, y in mixed_trainloader:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device).double()
                else:
                    x = x.to(self.device).double()
                y = y.to(self.device)
                
                output = self.model(x)
                loss = self.loss(output, y)
                
                scaffold_optimizer.zero_grad()
                loss.backward()
                # Apply SCAFFOLD correction: grad = grad - c_i + c (ä¸åŸæ¡†æ¶ä¸€è‡´)
                scaffold_optimizer.step(self.c_global, self.c_local)
        
        # Update local control variate using update_yc (ä¸åŸæ¡†æ¶clientscaffold.pyä¸€è‡´)
        self.update_yc(self.local_epochs)
    
    def update_yc(self, max_local_epochs=None):
        """
        SCAFFOLD: Update local control variate
        ä¸åŸæ¡†æ¶clientscaffold.pyçš„update_yc()å®Œå…¨ä¸€è‡´
        
        Formula: c_i+ = c_i - c + (x - y)/(K*eta)
        where K = num_batches * max_local_epochs
        """
        if max_local_epochs is None:
            max_local_epochs = self.local_epochs
        
        for ci, c, x, yi in zip(self.c_local, self.c_global, self.global_model.parameters(), 
                               self.model.parameters()):
            ci.data = ci - c + 1/self.num_batches/max_local_epochs/self.learning_rate * (x - yi)
    
    def _train_perfedavg(self):
        """Per-FedAvg: MAML-based meta-learning"""
        # Use PerAvgOptimizer for proper MAML implementation
        from flcore.optimizers.fedoptimizer import PerAvgOptimizer
        peravg_optimizer = PerAvgOptimizer(self.model.parameters(), lr=self.learning_rate)
        
        # MAML requires batch_size*2 to split for inner/outer loop
        mixed_trainloader = self._create_mixed_dataloader(
            self.load_train_data(batch_size=self.batch_size * 2)
        )
        self.model.train()
        
        beta = getattr(self, 'beta', self.learning_rate)  # Meta learning rate
        
        for epoch in range(self.local_epochs):
            for X, Y in mixed_trainloader:
                # Save model parameters before inner loop update
                temp_model = copy.deepcopy([p.data.clone().double() for p in self.model.parameters()])
                
                # Step 1: Inner loop - first half of batch
                x = X[:self.batch_size].to(self.device)
                y = Y[:self.batch_size].to(self.device)
                output = self.model(x)
                loss = self.loss(output, y)
                peravg_optimizer.zero_grad()
                loss.backward()
                peravg_optimizer.step()  # Inner update with lr
                
                # Step 2: Outer loop - second half of batch (meta gradient)
                x = X[self.batch_size:].to(self.device)
                y = Y[self.batch_size:].to(self.device)
                peravg_optimizer.zero_grad()
                output = self.model(x)
                loss = self.loss(output, y)
                loss.backward()
                
                # Restore model parameters to before inner update
                for old_param, new_param in zip(self.model.parameters(), temp_model):
                    old_param.data = new_param.data.clone()
                
                # Meta update with beta (second-order gradient approximation)
                peravg_optimizer.step(beta=beta)
    
    def _train_ditto(self):
        """Ditto: Train both global and personalized models"""
        if self.personalized_model is None:
            self.init_personalized_model()
        
        mixed_trainloader = self._create_mixed_dataloader(self.load_train_data())
        
        mu = getattr(self, 'mu', 1.0)
        plocal_epochs = getattr(self, 'plocal_epochs', 1)
        
        # Import PerturbedGradientDescent for personalized model
        from flcore.optimizers.fedoptimizer import PerturbedGradientDescent
        pers_optimizer = PerturbedGradientDescent(
            self.personalized_model.parameters(), 
            lr=self.learning_rate, 
            mu=mu
        )
        
        # Step 1: Train personalized model first (with regularization to global)
        self.personalized_model.train()
        for epoch in range(plocal_epochs):
            for x, y in mixed_trainloader:
                x, y = x.to(self.device).double(), y.to(self.device)
                output = self.personalized_model(x)
                loss = self.loss(output, y)
                pers_optimizer.zero_grad()
                loss.backward()
                # PerturbedGradientDescent adds mu*(w_pers - w_global) automatically
                pers_optimizer.step(self.model.parameters(), self.device)
        
        # Step 2: Train global model (standard training)
        self.model.train()
        for epoch in range(self.local_epochs):
            for x, y in mixed_trainloader:
                x, y = x.to(self.device).double(), y.to(self.device)
                output = self.model(x)
                loss = self.loss(output, y)
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
    
    def _train_fedrep(self):
        """FedRep: Train with body-head split"""
        # Check if model has base-head structure
        if not (hasattr(self.model, 'base') and hasattr(self.model, 'head')):
            print(f"Warning: Model doesn't have base-head structure, using standard training")
            self._train_fedavg()
            return
        
        mixed_trainloader = self._create_mixed_dataloader(self.load_train_data())
        self.model.train()
        
        plocal_epochs = getattr(self, 'plocal_epochs', 1)
        
        # Create separate optimizers for base and head
        optimizer_base = torch.optim.SGD(self.model.base.parameters(), lr=self.learning_rate)
        optimizer_head = torch.optim.SGD(self.model.head.parameters(), lr=self.learning_rate)
        
        # Step 1: Train head only (personalization) - Freeze base
        for param in self.model.base.parameters():
            param.requires_grad = False
        for param in self.model.head.parameters():
            param.requires_grad = True
        
        for epoch in range(plocal_epochs):
            for x, y in mixed_trainloader:
                x, y = x.to(self.device).double(), y.to(self.device)
                rep = self.model.base(x)
                output = self.model.head(rep)
                loss = self.loss(output, y)
                optimizer_head.zero_grad()
                loss.backward()
                optimizer_head.step()
        
        # Step 2: Train base only (will be aggregated) - Freeze head
        for param in self.model.base.parameters():
            param.requires_grad = True
        for param in self.model.head.parameters():
            param.requires_grad = False
        
        for epoch in range(self.local_epochs):
            for x, y in mixed_trainloader:
                x, y = x.to(self.device).double(), y.to(self.device)
                rep = self.model.base(x)
                output = self.model.head(rep)
                loss = self.loss(output, y)
                optimizer_base.zero_grad()
                loss.backward()
                optimizer_base.step()
        
        # Restore gradient computation for all parameters
        for param in self.model.parameters():
            param.requires_grad = True
    
    def _train_fedproto(self):
        """FedProto: Prototype-based training"""
        # Check if model has base-head structure
        if not (hasattr(self.model, 'base') and hasattr(self.model, 'head')):
            print(f"Warning: Model doesn't have base-head structure, using standard training")
            self._train_fedavg()
            return
        
        from collections import defaultdict
        
        mixed_trainloader = self._create_mixed_dataloader(self.load_train_data())
        self.model.train()
        
        lamda = getattr(self, 'lamda', 1.0)  # Prototype loss weight
        loss_mse = nn.MSELoss()
        
        # Collect local prototypes during training
        protos = defaultdict(list)
        
        for epoch in range(self.local_epochs):
            for x, y in mixed_trainloader:
                x, y = x.to(self.device).double(), y.to(self.device)
                
                # Extract features from base model
                rep = self.model.base(x)
                output = self.model.head(rep)
                loss = self.loss(output, y)
                
                # Add prototype regularization if global prototypes exist
                if self.global_prototypes is not None and len(self.global_prototypes) > 0:
                    proto_new = copy.deepcopy(rep.detach())
                    for i, yy in enumerate(y):
                        y_c = yy.item()
                        # Use global prototype if exists
                        if y_c in self.global_prototypes and type(self.global_prototypes[y_c]) != type([]):
                            proto_new[i, :] = self.global_prototypes[y_c].data
                    loss += loss_mse(proto_new, rep) * lamda
                
                # Collect local prototypes
                for i, yy in enumerate(y):
                    y_c = yy.item()
                    protos[y_c].append(rep[i, :].detach().data)
                
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
        
        # Aggregate local prototypes (average per class)
        self.protos = {}
        for label, proto_list in protos.items():
            if len(proto_list) > 0:
                self.protos[label] = torch.stack(proto_list).mean(0)
        
        print(f"  Client {self.id}: Collected {len(self.protos)} class prototypes")
    
    def _train_pfedme(self):
        """pFedMe: Moreau envelope personalization"""
        # Import pFedMeOptimizer
        from flcore.optimizers.fedoptimizer import pFedMeOptimizer
        
        mixed_trainloader = self._create_mixed_dataloader(self.load_train_data())
        
        lamda = getattr(self, 'lamda', 15.0)  # Moreau envelope parameter
        K = getattr(self, 'K', 5)  # Number of personalized steps
        p_learning_rate = getattr(self, 'personalized_learning_rate', 0.01)
        
        # Initialize local and personalized parameters if not exists
        if not hasattr(self, 'local_params'):
            self.local_params = copy.deepcopy([p.data.clone().double() for p in self.model.parameters()])
        if not hasattr(self, 'personalized_params'):
            self.personalized_params = copy.deepcopy([p.data.clone().double() for p in self.model.parameters()])
        
        # Create pFedMe optimizer
        pfedme_optimizer = pFedMeOptimizer(
            self.model.parameters(), 
            lr=p_learning_rate, 
            lamda=lamda
        )
        
        self.model.train()
        
        for epoch in range(self.local_epochs):
            for x, y in mixed_trainloader:
                x, y = x.to(self.device).double(), y.to(self.device)
                
                # K personalized steps per batch
                for i in range(K):
                    output = self.model(x)
                    loss = self.loss(output, y)
                    pfedme_optimizer.zero_grad()
                    loss.backward()
                    # Find approximate theta (personalized parameters)
                    self.personalized_params = pfedme_optimizer.step(self.local_params, self.device)
                
                # Update local weights after finding approximate theta
                for new_param, localweight in zip(self.personalized_params, self.local_params):
                    localweight = localweight.to(self.device)
                    localweight.data = localweight.data - lamda * self.learning_rate * (localweight.data - new_param.data)
        
        # Update model with local parameters for aggregation
        for param, local_param in zip(self.model.parameters(), self.local_params):
            param.data = local_param.data.clone()
    
    def _train_fedgwo(self):
        """
        FedGWO: Grey Wolf Optimizer
        å®Œå…¨æŒ‰ç…§åŸæ¡†æ¶clientgwo.pyå®ç°
        """
        # Initialize GWO parameters if not set
        if not hasattr(self, 'alpha_model'):
            self.alpha_model = None
            self.beta_model = None
            self.delta_model = None
            self.a = None
            self.A1 = None
            self.A2 = None
            self.A3 = None
            self.C1 = None
            self.C2 = None
            self.C3 = None
        
        # Use real + virtual data (VPSç‰¹æœ‰)
        mixed_trainloader = self._create_mixed_dataloader(self.load_train_data())
        
        # Phase 0: è¯„ä¼°å½“å‰æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„å‡†ç¡®ç‡
        # æ³¨æ„ï¼šè¿™ä¸ªåœ¨æœåŠ¡å™¨ç«¯_setup_fedgwo_paramsä¸­å·²ç»åšäº†ï¼Œä½†ä¸ºäº†ä¸åŸæ¡†æ¶ä¸€è‡´ï¼Œè¿™é‡Œä¹Ÿä¿ç•™
        self.current_acc = self.get_validation_accuracy()
        
        # Phase 1: Grey Wolf Optimization Update
        # åŸå§‹GWOè®ºæ–‡å…¬å¼:
        # D_Î± = |C1Â·X_Î± - X|, X1 = X_Î± - A1Â·D_Î±
        # D_Î² = |C2Â·X_Î² - X|, X2 = X_Î² - A2Â·D_Î²
        # D_Î´ = |C3Â·X_Î´ - X|, X3 = X_Î´ - A3Â·D_Î´
        # X(t+1) = (X1 + X2 + X3) / 3
        
        if self.alpha_model is not None and self.beta_model is not None and self.delta_model is not None:
            with torch.no_grad():
                for param, alpha_param, beta_param, delta_param in zip(
                    self.model.parameters(),
                    self.alpha_model.parameters(),
                    self.beta_model.parameters(),
                    self.delta_model.parameters()
                ):
                    # è®¡ç®—è·ç¦» D = |C Ã— Î¸_leader - Î¸_k|
                    D_alpha = torch.abs(self.C1 * alpha_param.data - param.data)
                    D_beta = torch.abs(self.C2 * beta_param.data - param.data)
                    D_delta = torch.abs(self.C3 * delta_param.data - param.data)
                    
                    # å‘ä¸‰ä¸ªé¢†å¯¼è€…å­¦ä¹ 
                    # Î¸1 = Î¸_Î± - A1 Ã— D_Î±
                    theta_1 = alpha_param.data - self.A1 * D_alpha
                    # Î¸2 = Î¸_Î² - A2 Ã— D_Î²
                    theta_2 = beta_param.data - self.A2 * D_beta
                    # Î¸3 = Î¸_Î´ - A3 Ã— D_Î´
                    theta_3 = delta_param.data - self.A3 * D_delta
                    
                    # ä¸‰è€…å¹³å‡ä½œä¸ºæ–°ä½ç½®
                    param.data = (theta_1 + theta_2 + theta_3) / 3.0
        
        # Phase 2: Local Training (å®Œæ•´çš„Eè½®æœ¬åœ°è®­ç»ƒ)
        self.model.train()
        
        for epoch in range(self.local_epochs):
            for x, y in mixed_trainloader:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device).double()
                else:
                    x = x.to(self.device).double()
                y = y.to(self.device)
                
                output = self.model(x)
                loss = self.loss(output, y)
                
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
    
    def set_gwo_params(self, alpha_model, beta_model, delta_model, a, A1, A2, A3, C1, C2, C3):
        """
        è®¾ç½®GWOç®—æ³•æ‰€éœ€çš„å‚æ•° (ä¸åŸæ¡†æ¶clientgwo.pyå®Œå…¨ä¸€è‡´)
        
        Args:
            alpha_model: Î¸_Î± - Alpha wolf (æœ€ä¼˜å®¢æˆ·ç«¯æ¨¡å‹)
            beta_model: Î¸_Î² - Beta wolf (æ¬¡ä¼˜å®¢æˆ·ç«¯æ¨¡å‹)
            delta_model: Î¸_Î´ - Delta wolf (ç¬¬ä¸‰ä¼˜å®¢æˆ·ç«¯æ¨¡å‹)
            a: æ”¶æ•›å› å­ï¼Œä»2çº¿æ€§é€’å‡åˆ°0 (åŸå§‹è®ºæ–‡)
            A1, A2, A3: å‘ä¸‰ä¸ªé¢†å¯¼è€…å­¦ä¹ çš„ç³»æ•°ï¼ŒA = 2aÂ·r - a
            C1, C2, C3: ä¸‰ä¸ªé¢†å¯¼è€…çš„æƒé‡ç³»æ•°ï¼ŒC = 2Â·r
        """
        # ç¡®ä¿æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯doubleç±»å‹ï¼ˆé˜²æ­¢dtypeä¸åŒ¹é…ï¼‰
        self.alpha_model = alpha_model.double() if alpha_model is not None else None
        self.beta_model = beta_model.double() if beta_model is not None else None
        self.delta_model = delta_model.double() if delta_model is not None else None
        self.a = a
        self.A1 = A1
        self.A2 = A2
        self.A3 = A3
        self.C1 = C1
        self.C2 = C2
        self.C3 = C3
    
    def _train_fedpso(self):
        """
        FedPSO: Particle Swarm Optimization
        å®Œå…¨å‚ç…§clientpso.pyå®ç°ï¼Œé€‚é…æ··åˆæ•°æ®è®­ç»ƒ
        
        PSOæ ¸å¿ƒæ€æƒ³ï¼š
        - æ¯ä¸ªå®¢æˆ·ç«¯æ˜¯ä¸€ä¸ªç²’å­ï¼Œåœ¨è§£ç©ºé—´ä¸­æœç´¢æœ€ä¼˜æ¨¡å‹å‚æ•°
        - é€Ÿåº¦æ›´æ–°å…¬å¼ï¼šv(t+1) = w*v(t) + c1*r1*(pbest - x(t)) + c2*r2*(gbest - x(t))
        - ä½ç½®æ›´æ–°å…¬å¼ï¼šx(t+1) = x(t) + v(t+1)
        
        Training flow:
        1. PSOä½ç½®æ›´æ–°ï¼ˆåœ¨æ¢¯åº¦ä¸‹é™å‰ï¼‰
        2. æ¢¯åº¦ä¸‹é™å¾®è°ƒ
        """
        # Step 1: PSOä½ç½®æ›´æ–°ï¼ˆåœ¨ä¼ ç»Ÿè®­ç»ƒå‰ï¼‰
        if self.pbest_model is not None and self.gbest_model is not None:
            self._pso_update()
        
        # Step 2: ä¼ ç»Ÿæ¢¯åº¦ä¸‹é™è®­ç»ƒï¼ˆå¾®è°ƒï¼‰
        mixed_trainloader = self._create_mixed_dataloader(self.load_train_data())
        self.model.train()
        
        for epoch in range(self.local_epochs):
            for x, y in mixed_trainloader:
                x, y = x.to(self.device).double(), y.to(self.device)
                output = self.model(x)
                loss = self.loss(output, y)
                
                # Check for NaN/Inf
                if torch.isnan(loss) or torch.isinf(loss):
                    print(f"Warning: Client {self.id} detected NaN/Inf loss, skipping batch")
                    continue
                
                self.optimizer.zero_grad()
                loss.backward()
                
                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=10.0)
                
                self.optimizer.step()
        
        return 0.0  # Return 0 loss for PSO (not needed)
    
    def _pso_update(self):
        """
        PSOæ ¸å¿ƒæ›´æ–°å…¬å¼ï¼ˆå‚ç…§clientpso.pyï¼‰
        
        åŸå§‹è®ºæ–‡å…¬å¼ (Kennedy & Eberhart, 1995)ï¼š
        v_i(t+1) = w*v_i(t) + c1*r1*(pbest_i - x_i(t)) + c2*r2*(gbest - x_i(t))
        x_i(t+1) = x_i(t) + v_i(t+1)
        
        ä¸‰ä¸ªæˆåˆ†ï¼š
        1. æƒ¯æ€§æˆåˆ†: w*v_i(t) - ä¿æŒä¹‹å‰çš„æœç´¢æ–¹å‘
        2. è®¤çŸ¥æˆåˆ†: c1*r1*(pbest_i - x_i(t)) - å‘ä¸ªä½“å†å²æœ€ä¼˜å­¦ä¹ 
        3. ç¤¾ä¼šæˆåˆ†: c2*r2*(gbest - x_i(t)) - å‘ç¾¤ä½“å…¨å±€æœ€ä¼˜å­¦ä¹ 
        """
        with torch.no_grad():
            # éå†æ¨¡å‹çš„æ¯ä¸€å±‚å‚æ•°
            for i, (param, vel, pbest_param, gbest_param) in enumerate(
                zip(self.model.parameters(), self.velocity, self.pbest_model, self.gbest_model)
            ):
                # å½“å‰ä½ç½® x_i(t)
                x_current = param.data
                
                # ä¸ªä½“æœ€ä¼˜ä½ç½® pbest_i
                x_pbest = pbest_param
                
                # å…¨å±€æœ€ä¼˜ä½ç½® gbest
                x_gbest = gbest_param
                
                # è®¡ç®—é€Ÿåº¦æ›´æ–°çš„ä¸‰ä¸ªæˆåˆ†
                # 1. æƒ¯æ€§æˆåˆ†: w * v_i(t)
                inertia = self.pso_w * vel
                
                # 2. è®¤çŸ¥æˆåˆ†ï¼ˆä¸ªä½“å­¦ä¹ ï¼‰: c1 * r1 * (pbest_i - x_i(t))
                cognitive = self.pso_c1 * self.pso_r1 * (x_pbest - x_current)
                
                # 3. ç¤¾ä¼šæˆåˆ†ï¼ˆç¾¤ä½“å­¦ä¹ ï¼‰: c2 * r2 * (gbest - x_i(t))
                social = self.pso_c2 * self.pso_r2 * (x_gbest - x_current)
                
                # é€Ÿåº¦æ›´æ–°ï¼šv_i(t+1) = inertia + cognitive + social
                new_velocity = inertia + cognitive + social
                
                # é€Ÿåº¦é™åˆ¶ï¼ˆé˜²æ­¢é€Ÿåº¦è¿‡å¤§ï¼‰
                param_range = torch.abs(x_current).mean() + 1e-8  # é¿å…é™¤é›¶
                v_max = self.pso_v_max * param_range
                new_velocity = torch.clamp(new_velocity, -v_max, v_max)
                
                # æ›´æ–°é€Ÿåº¦
                vel.data = new_velocity
                
                # ä½ç½®æ›´æ–°ï¼šx_i(t+1) = x_i(t) + v_i(t+1)
                param.data = x_current + new_velocity
            
            # æ›´æ–°é€Ÿåº¦åˆ—è¡¨å¼•ç”¨
            self.velocity = [v.clone() for v in self.velocity]
    
    def set_pso_parameters(self, w, c1, c2, r1, r2, pbest_model, gbest_model, velocity):
        """
        è®¾ç½®PSOå‚æ•°ï¼ˆç”±æœåŠ¡å™¨ä¼ å…¥ï¼‰
        
        Args:
            w: æƒ¯æ€§æƒé‡ï¼ˆinertia weightï¼‰
            c1: ä¸ªä½“å­¦ä¹ å› å­ï¼ˆcognitive parameterï¼‰
            c2: ç¤¾ä¼šå­¦ä¹ å› å­ï¼ˆsocial parameterï¼‰
            r1: éšæœºæ•°1ï¼ŒèŒƒå›´[0, 1]
            r2: éšæœºæ•°2ï¼ŒèŒƒå›´[0, 1]
            pbest_model: ä¸ªä½“æœ€ä¼˜æ¨¡å‹å‚æ•°åˆ—è¡¨
            gbest_model: å…¨å±€æœ€ä¼˜æ¨¡å‹å‚æ•°åˆ—è¡¨
            velocity: å½“å‰é€Ÿåº¦
        """
        self.pso_w = w
        self.pso_c1 = c1
        self.pso_c2 = c2
        self.pso_r1 = r1
        self.pso_r2 = r2
        self.pbest_model = pbest_model
        self.gbest_model = gbest_model
        self.velocity = velocity
    
    def _create_mixed_dataloader(self, real_trainloader):
        """
        Create a DataLoader with mixed real and virtual data
        
        Args:
            real_trainloader: DataLoader for real training data
        
        Returns:
            mixed_trainloader: DataLoader with both real and virtual data
        """
        from torch.utils.data import TensorDataset, DataLoader
        
        # Collect real data
        real_features = []
        real_labels = []
        
        for x, y in real_trainloader:
            if type(x) == type([]):
                x = x[0]
            real_features.append(x)
            real_labels.append(y)
        
        real_features = torch.cat(real_features, dim=0)
        real_labels = torch.cat(real_labels, dim=0)
        
        # Add virtual data if available
        if len(self.shared_virtual_data) > 0:
            virtual_features = []
            virtual_labels = []
            
            for features, label in self.shared_virtual_data:
                virtual_features.append(torch.tensor(features, dtype=torch.float32))
                virtual_labels.append(torch.tensor(label, dtype=torch.long))
            
            virtual_features = torch.stack(virtual_features)
            virtual_labels = torch.stack(virtual_labels)
            
            # Concatenate real and virtual
            mixed_features = torch.cat([real_features, virtual_features], dim=0)
            mixed_labels = torch.cat([real_labels, virtual_labels], dim=0)
        else:
            mixed_features = real_features
            mixed_labels = real_labels
        
        # Create mixed dataset
        mixed_dataset = TensorDataset(mixed_features, mixed_labels)
        mixed_trainloader = DataLoader(
            mixed_dataset,
            batch_size=self.batch_size,
            shuffle=True,
            drop_last=True
        )
        
        return mixed_trainloader
    
    def load_shared_virtual_data(self, virtual_data):
        """
        Load shared virtual data from server
        
        Args:
            virtual_data: List of (features, label) tuples from all clients
        """
        self.shared_virtual_data = virtual_data
    
    def set_phase2_algorithm(self, algorithm):
        """Set Phase 2 algorithm type"""
        self.phase2_algorithm = algorithm.lower()
    
    def init_moon_states(self):
        """Initialize MOON: Save previous model for contrastive learning"""
        self.prev_model = copy.deepcopy(self.model).double()
    
    def init_scaffold_controls(self):
        """Initialize SCAFFOLD: Control variates"""
        self.c_local = [torch.zeros_like(p.data).double() for p in self.model.parameters()]
        self.c_global = [torch.zeros_like(p.data).double() for p in self.model.parameters()]
        # Save global model parameters for control variate update (needed by SCAFFOLD)
        self.global_model_params = [p.data.clone().double() for p in self.model.parameters()]
        self.global_model = copy.deepcopy(self.model).double()  # Keep reference
    
    def set_parameters(self, model, global_c=None):
        """
        Set model parameters (for SCAFFOLD compatibility)
        ä¸åŸæ¡†æ¶clientscaffold.pyå®Œå…¨ä¸€è‡´
        
        Args:
            model: Global model
            global_c: Global control variates (for SCAFFOLD)
        """
        for new_param, old_param in zip(model.parameters(), self.model.parameters()):
            old_param.data = new_param.data.clone().double()
        
        if global_c is not None:
            # SCAFFOLD: Also set global control and model
            self.c_global = global_c
            self.global_model = model
    
    def delta_yc(self, max_local_epochs=None):
        """
        SCAFFOLD: Compute delta_y and delta_c
        ä¸åŸæ¡†æ¶clientscaffold.pyçš„delta_yc()å®Œå…¨ä¸€è‡´
        
        Returns:
            delta_y: Model parameter update
            delta_c: Control variate update
        """
        if max_local_epochs is None:
            max_local_epochs = self.local_epochs
        
        # Compute number of batches
        if not hasattr(self, 'num_batches'):
            self.num_batches = len(self.load_train_data())
        
        delta_y = []
        delta_c = []
        for c, x, yi in zip(self.c_global, self.global_model.parameters(), self.model.parameters()):
            delta_y.append(yi - x)
            delta_c.append(- c + 1/self.num_batches/max_local_epochs/self.learning_rate * (x - yi))
        
        return delta_y, delta_c
    
    def init_personalized_model(self):
        """
        Initialize Ditto-style personalized model for Phase2
        Called when transitioning from Phase1 to Phase2
        """
        if self.model_per is None:
            import copy
            self.model_per = copy.deepcopy(self.model).double()
            
            from flcore.optimizers.fedoptimizer import PerturbedGradientDescent
            self.optimizer_per = PerturbedGradientDescent(
                self.model_per.parameters(),
                lr=self.learning_rate,
                mu=self.mu_ditto
            )
            print(f"  Client {self.id}: Initialized personalized model for Ditto-style training (Î¼={self.mu_ditto})")
    
    def get_validation_accuracy(self):
        """
        For Phase 2 compatibility with server aggregation algorithms
        (e.g., FedCS needs client ranking)
        Returns current validation accuracy for server-side ranking.
        """
        return self._compute_accuracy()
    
    def _check_early_stopping(self):
        """
        Check if client should stop Phase 1 training (simplified to 3 conditions)
        
        Three Conditions (ALL must be met):
        1. è®­ç»ƒè‡³å°‘10è½® (forced training)
        2. æœ€è¿‘3è½®å‡†ç¡®ç‡å‡ â‰¥ ACC(t) - 0.02 (ç¨³å®šåœ¨é˜ˆå€¼é™„è¿‘)
        3. æœ€è¿‘3è½®æ³¢åŠ¨ â‰¤ 0.02 (æ”¶æ•›ç¨³å®š)
        
        Note: å‰5è½®åœ¨train_phase1()ä¸­å·²è¢«è·³è¿‡æ£€æŸ¥
        
        Returns:
            bool: True if all conditions met
        """
        # === å‚æ•°é…ç½® ===
        min_training_rounds = 10   # è‡³å°‘10è½®è®­ç»ƒï¼ˆä½†å‰5è½®å·²è¢«è·³è¿‡æ£€æŸ¥ï¼‰
        min_stable_rounds = 3      # æ¡ä»¶(2)(3): æ£€æŸ¥æœ€è¿‘3è½®
        max_fluctuation = 0.02     # æ¡ä»¶(3): æœ€å¤§æ³¢åŠ¨ç‡2%
        threshold_tolerance = 0.02  # æ¡ä»¶(2): é˜ˆå€¼å®¹å¿åº¦2%
        
        print(f"\n  [Client {self.id}] æ—©åœæ£€æŸ¥ (å½“å‰å‡†ç¡®ç‡: {self.accuracy:.4f})")
        
        # === æ¡ä»¶(1): å‰10è½®å¼ºåˆ¶è®­ç»ƒï¼Œä¸æ£€æŸ¥æ—©åœ ===
        if len(self.accuracy_history) < min_training_rounds:
            print(f"    [-] æ¡ä»¶(1): è®­ç»ƒè½®æ•°ä¸è¶³ ({len(self.accuracy_history)}/{min_training_rounds}è½®) - å¼ºåˆ¶è®­ç»ƒ")
            return False
        else:
            print(f"    [+] æ¡ä»¶(1): è®­ç»ƒè½®æ•°å……è¶³ ({len(self.accuracy_history)}è½®)")
        
        # === æ¡ä»¶(2): æœ€è¿‘3è½®æ¯ä¸€è½®éƒ½â‰¥ACC(t)-0.02ï¼ˆæ€§èƒ½è¾¾æ ‡ï¼‰ ===
        recent = self.accuracy_history[-min_stable_rounds:]
        tolerance_threshold = self.current_threshold - threshold_tolerance
        failed_rounds = []
        for i, acc in enumerate(recent):
            if acc < tolerance_threshold:
                failed_rounds.append((i, acc))
        
        if failed_rounds:
            print(f"    [-] æ¡ä»¶(2): å­˜åœ¨ä½äºå®¹å¿é˜ˆå€¼çš„è½®æ¬¡")
            print(f"       å®¹å¿é˜ˆå€¼: {tolerance_threshold:.4f} (ACC(t)={self.current_threshold:.4f} - 0.02)")
            for idx, acc in failed_rounds:
                print(f"       ç¬¬{len(self.accuracy_history)-min_stable_rounds+idx+1}è½®: {acc:.4f} < {tolerance_threshold:.4f} [FAIL]")
            return False
        else:
            print(f"    [+] æ¡ä»¶(2): æ‰€æœ‰è½®æ¬¡éƒ½æŒç»­è¾¾æ ‡")
            print(f"       å®¹å¿é˜ˆå€¼: {tolerance_threshold:.4f}")
            for i, acc in enumerate(recent):
                print(f"       ç¬¬{len(self.accuracy_history)-min_stable_rounds+i+1}è½®: {acc:.4f} >= {tolerance_threshold:.4f} [+]")
        
        # === æ¡ä»¶(3): æœ€è¿‘3è½®æ³¢åŠ¨ç‡â‰¤0.02ï¼ˆç¨³å®šä¸éœ‡è¡ï¼‰ ===
        fluctuation = max(recent) - min(recent)
        if fluctuation > max_fluctuation:
            print(f"    [-] æ¡ä»¶(3): æ³¢åŠ¨ç‡è¿‡å¤§ ({fluctuation:.4f} > {max_fluctuation:.4f})")
            print(f"       æœ€è¿‘3è½®: {[f'{x:.4f}' for x in recent]} (æœ€å¤§-æœ€å°={fluctuation:.4f})")
            return False
        else:
            print(f"    [+] æ¡ä»¶(3): æ³¢åŠ¨ç‡ç¨³å®š ({fluctuation:.4f} <= {max_fluctuation:.4f})")
            print(f"       æœ€è¿‘3è½®: {[f'{x:.4f}' for x in recent]}")
        
        # æ‰€æœ‰3ä¸ªæ¡ä»¶éƒ½æ»¡è¶³ï¼Œåˆ¤å®šä¸ºçœŸæ­£ç¨³å®šæ”¶æ•›
        print(f"    [OK] æ‰€æœ‰æ¡ä»¶æ»¡è¶³ - å®¢æˆ·ç«¯è¾¾æ ‡ï¼")
        return True
        tolerance_threshold = self.current_threshold - threshold_tolerance
        failed_rounds = []
        for i, acc in enumerate(recent):
            if acc < tolerance_threshold:
                failed_rounds.append((i, acc))
        
        if failed_rounds:
            print(f"    [-] æ¡ä»¶(4): å­˜åœ¨ä½äºå®¹å¿é˜ˆå€¼çš„è½®æ¬¡")
            print(f"       å®¹å¿é˜ˆå€¼: {tolerance_threshold:.4f} (é˜ˆå€¼{self.current_threshold:.4f} - å®¹å¿åº¦{threshold_tolerance:.4f})")
            for idx, acc in failed_rounds:
                print(f"       ç¬¬{len(self.accuracy_history)-min_stable_rounds+idx+1}è½®: {acc:.4f} < {tolerance_threshold:.4f} [-]")
            return False
        else:
            print(f"    [+] æ¡ä»¶(4): æ‰€æœ‰è½®æ¬¡éƒ½æŒç»­è¾¾æ ‡")
            print(f"       å®¹å¿é˜ˆå€¼: {tolerance_threshold:.4f}")
            for i, acc in enumerate(recent):
                print(f"       ç¬¬{len(self.accuracy_history)-min_stable_rounds+i+1}è½®: {acc:.4f} >= {tolerance_threshold:.4f} [+]")
        
        # æ‰€æœ‰4ä¸ªæ¡ä»¶éƒ½æ»¡è¶³ï¼Œåˆ¤å®šä¸ºçœŸæ­£ç¨³å®šæ”¶æ•›
        print(f"    [OK] æ‰€æœ‰æ¡ä»¶æ»¡è¶³ - å®¢æˆ·ç«¯è¾¾æ ‡ï¼")
        return True
    
    def update_threshold(self, threshold):
        """
        æ¥æ”¶æœåŠ¡å™¨ä¼ æ¥çš„åŠ¨æ€é˜ˆå€¼
        
        Args:
            threshold: å½“å‰è½®çš„åŠ¨æ€é˜ˆå€¼
        """
        self.current_threshold = threshold
    
    def test_metrics(self):
        """
        Override base class test_metrics to ensure float64 compatibility
        """
        from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score
        from sklearn.preprocessing import label_binarize
        
        testloaderfull = self.load_test_data()
        self.model.eval()

        test_acc = 0
        test_num = 0
        y_prob = []
        y_true = []
        y_pred = []
        
        with torch.no_grad():
            for x, y in testloaderfull:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device).double()
                else:
                    x = x.to(self.device).double()
                y = y.to(self.device)
                output = self.model(x)
                
                # Check for NaN in model output
                if torch.isnan(output).any() or torch.isinf(output).any():
                    print(f"Warning: Client {self.id} detected NaN/Inf in model output")
                    self.enable_grad_clip = True
                    self.nan_detected_count += 1
                    output = torch.nan_to_num(output, nan=0.0, posinf=50.0, neginf=-50.0)
                    output = torch.clamp(output, min=-50, max=50)
                
                # Convert logits to probabilities
                output_prob = torch.nn.functional.softmax(output, dim=1)

                pred = torch.argmax(output, dim=1)
                test_acc += (torch.sum(pred == y)).item()
                test_num += y.shape[0]

                y_prob.append(output_prob.detach().cpu().numpy())
                y_pred.append(pred.detach().cpu().numpy())
                nc = self.num_classes
                if self.num_classes == 2:
                    nc += 1
                lb = label_binarize(y.detach().cpu().numpy(), classes=np.arange(nc))
                if self.num_classes == 2:
                    lb = lb[:, :2]
                y_true.append(lb)

        y_prob = np.concatenate(y_prob, axis=0)
        y_pred = np.concatenate(y_pred, axis=0)
        y_true = np.concatenate(y_true, axis=0)
        
        # Final NaN check
        if np.isnan(y_prob).any():
            print(f"Warning: NaN found in y_prob for client {self.id}")
            nan_mask = np.isnan(y_prob)
            y_prob[nan_mask] = 1.0 / self.num_classes
        
        # Calculate AUC - special handling for binary classification
        if self.num_classes == 2:
            auc = roc_auc_score(y_true[:, 1], y_prob[:, 1])
        else:
            auc = roc_auc_score(y_true, y_prob, average='micro')
        
        # Calculate Precision, Recall, F1 - convert one-hot to labels
        y_true_labels = np.argmax(y_true, axis=1)
        precision = precision_score(y_true_labels, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_true_labels, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_true_labels, y_pred, average='weighted', zero_division=0)

        return test_acc, test_num, auc, precision, recall, f1
    
    def train_metrics(self):
        """
        Override base class train_metrics to ensure float64 compatibility
        """
        trainloader = self.load_train_data()
        self.model.eval()

        train_num = 0
        losses = 0
        with torch.no_grad():
            for x, y in trainloader:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device).double()
                else:
                    x = x.to(self.device).double()
                y = y.to(self.device)
                output = self.model(x)
                loss = self.loss(output, y)
                train_num += y.shape[0]
                losses += loss.item() * y.shape[0]

        return losses, train_num
